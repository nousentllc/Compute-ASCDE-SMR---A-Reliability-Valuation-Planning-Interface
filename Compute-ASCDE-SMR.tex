\documentclass[11pt,letterpaper]{article}

% =========================================================
% Engine / Fonts (XeLaTeX or LuaLaTeX recommended)
% =========================================================
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{lmodern}
\else
  \usepackage{fontspec}
  \defaultfontfeatures{Ligatures=TeX}
  \setmainfont{TeX Gyre Termes}
  \setsansfont{TeX Gyre Heros}
  \setmonofont{TeX Gyre Cursor}
\fi

% =========================================================
% Layout / Typography
% =========================================================
\usepackage[margin=0.75in]{geometry}
\usepackage{microtype}
\usepackage{setspace}
\setstretch{1.05}

% =========================================================
% Math / Theorems
% =========================================================
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools} % \coloneqq, \DeclarePairedDelimiter, etc.

% Equation numbering within sections
\numberwithin{equation}{section}

% Theorem stack (section-numbered, consistent counters)
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% =========================================================
% Figures / Tables
% =========================================================
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}

% --- LONGTABLE & formatting (for variable tables / appendices) ---
\usepackage{longtable}
\usepackage{calc}
\usepackage{threeparttablex}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\setlength{\LTcapwidth}{\linewidth}
\renewcommand{\arraystretch}{1.25}

% =========================================================
% Algorithms / Code listings (PROMELA, Python)
% =========================================================
\usepackage{float} % load BEFORE algorithm environments
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}

% =========================================================
% Colors (single load; dvipsnames enabled)
% =========================================================
\usepackage[dvipsnames]{xcolor}
\definecolor{DocBlue}{named}{MidnightBlue}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  breakatwhitespace=false,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space}
}
\lstset{style=mystyle}

% =========================================================
% Lists
% =========================================================
\usepackage{enumitem}
\setlist[itemize]{leftmargin=*,itemsep=0.25em,topsep=0.25em}
\setlist[enumerate]{leftmargin=*,itemsep=0.25em,topsep=0.25em}

% =========================================================
% Sections (spacing + optional blue headings)
% =========================================================
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.1em}{0.6em}
\titlespacing*{\subsection}{0pt}{0.9em}{0.5em}
\titlespacing*{\subsubsection}{0pt}{0.7em}{0.4em}

\titleformat{\section}
  {\Large\bfseries\color{DocBlue}}
  {\thesection}{0.75em}{}
\titleformat{\subsection}
  {\large\bfseries\color{DocBlue}}
  {\thesubsection}{0.75em}{}
\titleformat{\subsubsection}
  {\normalsize\bfseries\color{DocBlue}}
  {\thesubsubsection}{0.75em}{}

% =========================================================
% Quotes
% =========================================================
\usepackage{csquotes}

% =========================================================
% Headers / Footers + TOC styling (blue)
% =========================================================
\usepackage{fancyhdr}
\usepackage{tocloft}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\fancyhead[L]{\small\textsf{Compute-ASCDE-SMR}}
\fancyhead[R]{\small\textsf{\today}}
\fancyfoot[C]{\small\textsf{\thepage}}
\setlength{\headheight}{14pt}

% Ensure "plain" pages (title/TOC) match
\fancypagestyle{plain}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0.4pt}%
  \fancyhead[L]{\small\textsf{Compute-ASCDE-SMR}}%
  \fancyhead[R]{\small\textsf{\today}}%
  \fancyfoot[C]{\small\textsf{\thepage}}%
}

% --- TOC styling (blue entries + blue title) ---
\renewcommand{\cfttoctitlefont}{\Large\bfseries\color{DocBlue}}
\renewcommand{\cftsecfont}{\color{DocBlue}}
\renewcommand{\cftsubsecfont}{\color{DocBlue}}
\renewcommand{\cftsubsubsecfont}{\color{DocBlue}}
\renewcommand{\cftsecpagefont}{\color{DocBlue}}
\renewcommand{\cftsubsecpagefont}{\color{DocBlue}}
\renewcommand{\cftsubsubsecpagefont}{\color{DocBlue}}
\setlength{\cftbeforesecskip}{2pt}

% =========================================================
% Hyperlinks / Refs
% =========================================================
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=DocBlue,
  citecolor=DocBlue,
  urlcolor=DocBlue,
  linktoc=all,
  pdftitle={Compute-ASCDE-SMR},
  pdfauthor={Justin Candler}
}

% Ensure macros don't break PDF bookmarks
\pdfstringdefDisableCommands{%
  \def\ASCDE{ASCDE}%
  \def\VOLL{VOLL}%
  \def\EUE{EUE}%
  \def\RubinVec{RubinVec}%
  \def\GridVec{GridVec}%
  \def\SMRVec{SMRVec}%
  \def\tau{tau}%
  \def\sigma{sigma}%
  \def\delta{delta}%
  \def\epsilon{epsilon}%
}

\usepackage[capitalize,nameinlink]{cleveref}

% =========================================================
% Bibliography (biblatex + natbib-compatible \citep/\citet)
% =========================================================
\usepackage[
  backend=biber,
  style=authoryear,
  natbib=true,
  maxcitenames=2,
  maxbibnames=99,
  doi=false,
  url=false,
  isbn=false
]{biblatex}
\addbibresource{compute-ascde-smr.bib}

% =========================================================
% Footnotes (cleaner)
% =========================================================
\usepackage[bottom]{footmisc}

% =========================================================
% Notation infrastructure (symbols list)
% =========================================================
\usepackage[intoc]{nomencl} % adds "Nomenclature" to TOC
\makenomenclature

% Optional: slightly tighter nomenclature formatting
\renewcommand{\nomname}{Notation}
\setlength{\nomlabelwidth}{2.2cm}

% =========================================================
% Macros (Strictly encapsulated to prevent subscript errors)
% =========================================================
\newcommand{\ASCDE}{\mathrm{ASCDE}}
\newcommand{\EUE}{\mathrm{EUE}}
\newcommand{\VOLL}{\mathrm{VOLL}}
\newcommand{\ELCC}{\mathrm{ELCC}}
\newcommand{\PV}{\mathrm{PV}}

% Avoid double-subscript failures:
% Use superscripts for family labels, subscripts only for time/indices.
\newcommand{\RubinVec}{\vec{\theta}^{\mathrm{R}}}
\newcommand{\GridVec}{\vec{\theta}^{\mathrm{G}}}
\newcommand{\SMRVec}{\vec{\phi}^{\mathrm{SMR}}}

% Common notational macros (safe wrappers)
\newcommand{\POI}{\mathrm{POI}}
\newcommand{\EUEt}{\EUE_t} % single subscript only
\newcommand{\MRV}{\mathrm{MRV}}
\newcommand{\eMRV}{\mathrm{eMRV}}
\newcommand{\DeepONet}{\mathrm{DeepONet}}

% =========================================================
% Title Block
% =========================================================
\title{\textbf{Compute-ASCDE-SMR: A Reliability-Complete Valuation and Planning Interface for Nuclear-Coupled AI Campuses}}
\author{Justin Candler \\ \textit{Nous Enterprises LLC}}
\date{January 15, 2026}

% =========================================================
% Front matter controls
% =========================================================
\setcounter{tocdepth}{2} % sections + subsections in TOC (raise to 3 if desired)

\begin{document}
\maketitle

\begin{abstract}
\noindent \textbf{Context:} The deployment of Rubin-class AI architectures invalidates traditional MW-block utility planning because the state variables governing delivered intelligence are not well-approximated by average load factors. The relevant primitives are instead (i) architecture-aware goodput conversion (tokens per facility joule), (ii) workload stiffness (the marginal economic and reliability penalty of interruption), and (iii) temporal densification (sprint capacity). 

\vspace{0.5em}
\noindent \textbf{Methodology:} We extend the \textbf{Compute-ASCDE} framework—present value of total system cost divided by survival-weighted reliable intelligence—into a nuclear-coupled setting by introducing an explicit SMR boundary-condition vector $\SMRVec$ and elevating the intertemporal mismatch $\tau \coloneqq t_{\text{queue}} / t_{\text{silicon}}$ to a first-order planning variable. Crucially, we integrate Idaho National Laboratory (INL) research to parameterize the physical interface, introducing a novel thermodynamic constraint that links \textbf{AI hallucination entropy} to reactor heat-rejection limits ($Q^{\max}_{\text{heat}}$). 

\vspace{0.5em}
\noindent \textbf{Key Innovations:}
\begin{itemize}
    \item \textbf{Thermodynamic Coupling:} We demonstrate that high-entropy inference (hallucination) is thermodynamically distinct from convergent reasoning. By monitoring the \textit{Running Spectral Dimension} of the compute graph, we derive a \textbf{DeepONet control law} that curtails divergent search paths before they saturate the SMR's thermal loop $\Delta T_{\text{loop}}$.
    \item \textbf{Zero-Trust Bifurcation:} Utilizing the \textbf{HIPMoS} framework, we bifurcate the campus workload into \emph{stiff} (safety-critical/non-interruptible) and \emph{flexible} (entropy-elastic) tranches. This allows the SMR to prioritize "Always-On" cybersecurity and radiological sensing tasks during grid-level "Dunkelflaute" events.
    \item \textbf{Trustless Verification:} We introduce a Zero-Knowledge Proof (zk-SNARK) protocol that allows the utility to audit the curtailment of flexible tranches without inspecting the proprietary weights of the stiff, safety-critical models.
\end{itemize}

\vspace{0.5em}
\noindent \textbf{Conclusion:} In this interface, an SMR is not treated as "green baseload," but as a dynamic constraint set that modifies the feasible region of time-coupled controls. The paper provides a planner-facing API for stochastic evaluation over $(\RubinVec, \GridVec, \SMRVec)$, deriving regime conditions under which nuclear-coupled compute decreases grid stress, is neutral, or amplifies peak coincidence.
\end{abstract}

% -------------------------
% Front-matter: TOC + Notation
% -------------------------
\newpage
\tableofcontents
\newpage


\section*{Executive Summary and How to Use This Paper}
\addcontentsline{toc}{section}{Executive Summary and How to Use This Paper}

\subsection*{Executive Summary}
\addcontentsline{toc}{subsection}{Executive Summary (One Page)}

This paper defines a planner-facing valuation interface for integrating Rubin-class AI loads into power systems where \emph{reliability} is the binding constraint rather than average efficiency. The core claim is that ``AI efficiency'' must be modeled as a \emph{multi-physics, market-coupled functional} whose grid externalities are driven by (i) \emph{temporal densification} (peak and ramp stress), (ii) \emph{stiffness} (the cost of curtailment via state-switching penalties), and (iii) \emph{deliverability/power-quality constraints} (harmonics, slew limits, and thermal coincidence effects).

We formalize a system valuation metric---\textbf{Compute-ASCDE}---that internalizes:
\begin{itemize}
  \item stochastic energy and transmission costs under nodal prices (including coincidence exposure),
  \item reliability externalities via $\mathrm{VOLL}\cdot\Delta\mathrm{EUE}$,
  \item deliverability derates $D(\theta)$ induced by harmonic, ramp, and local thermal constraints,
  \item the distinction between \emph{dispatch-flexible inference} and \emph{state-stiff training} as separate resource classes from a grid perspective.
\end{itemize}

The planning output is therefore a \emph{regime map} rather than a point forecast: under realistic uncertainty in queue latency, market volatility, and load flexibility, the same nameplate MW can be either (a) a \emph{grid-accretive asset} (VPP-like behavior and negative effective Opex via reserve monetization) or (b) a \emph{parasitic stressor} (peak coincidence risk plus forced run-through scarcity due to switching costs).

\textbf{Connection to the companion paper (\emph{Contractible AI Control}):} The Compute-ASCDE interface depends on \emph{verifiable operational primitives}---measured curtailability, admissible ramp behavior, power quality, and \emph{attested goodput}. The control paper supplies the telemetry, gating, and attestation machinery that makes $D(\theta)$, $\Delta\mathrm{EUE}$, and ``flexibility claims'' contractible.

\subsection*{How to Use This Paper (Planner / Operator Workflow)}
\addcontentsline{toc}{subsection}{How to Use This Paper (Planner / Operator Workflow)}

\textbf{Inputs required}
\begin{enumerate}
  \item \textbf{Load shape and operating mode:} baseline hourly profile and intended dispatch policy (training vs.\ inference mix), including the sprint factor $\sigma$ (peak/average).
  \item \textbf{Market data:} DAM/RT hub prices (and ancillary products if claiming VPP value), plus tariff constructs relevant to coincidence exposure (e.g., 4CP-like mechanisms).
  \item \textbf{Reliability institution parameters:} VOLL assumption, scarcity/adder mechanics (ORDC-style or regional analog), and local deliverability/power-quality limits (THD, ramp constraints, substation/transformer derates).
  \item \textbf{Flexibility evidence (from \emph{Contractible AI Control}):} demonstrated curtailment response, restart time distribution, switching penalty model, and telemetry/attestation quality.
\end{enumerate}

\textbf{Procedure}
\begin{enumerate}
  \item \textbf{Classify the load:} compute stiffness $k_{\text{stiff}}$ and demand elasticity $\varepsilon$ (or bounded scenarios) to separate flexible inference from stiff training.
  \item \textbf{Compute private economics:} estimate LCRT (operator breakeven cost of reliable tokens) under stochastic prices and switching costs.
  \item \textbf{Compute system economics:} compute Compute-ASCDE including $\mathrm{VOLL}\cdot\Delta\mathrm{EUE}$ and deliverability derates $D(\theta)$.
  \item \textbf{Run scenario / Monte Carlo:} sweep $\delta$ (efficiency gain), $\sigma$ (sprint), $k_{\text{stiff}}$ (stiffness), queue latency $\tau$, and temperature-linked covariance.
  \item \textbf{Output:} report P50/P95 Compute-ASCDE, regime classification, and a mitigation list (BTM storage, harmonic filters, ramp governors, and telemetry+attestation requirements).
\end{enumerate}

\textbf{Decision rule}
\begin{itemize}
  \item \textbf{Approve / incentivize} if $\text{Compute-ASCDE} \le$ system benchmark $+$ strategic premium \emph{and} flexibility claims are \emph{attested} (see companion paper).
  \item \textbf{Require mitigation or deny} if tail risk is dominated by coincidence peaks, non-curtailability, or power-quality derates.
\end{itemize}

\newpage

% =========================================================
% 1. Problem Statement
% =========================================================
\section{Problem Statement}
\label{sec:problem}

\subsection{Planner objective: from device efficiency to delivered goodput under reliability constraints}
The planning objective for large AI campuses has migrated from \textbf{\emph{device}} efficiency (e.g., FLOPs/W at the chip) to \textbf{\textit{delivered system goodput per fully-loaded facility joule}} under binding integration and reliability constraints \citep{candler2026efficiencyparadox}. Let $t\in\{0,1,\dots,H\}$ index discrete planning periods (hours, days, or representative time slices) over horizon $H$, with discount factor $\delta\in(0,1]$.

\paragraph{Facility-energy denominator.}
Define total facility power as
\begin{equation}
P_{\text{tot}}(t) \;:=\; P_{\text{IT}}(t) + P_{\text{nonIT}}(t),
\end{equation}
where $P_{\text{nonIT}}$ aggregates all parasitics required to produce delivered compute (power conversion and distribution losses, cooling/heat rejection, water handling where relevant, networking fabrics, synchronization/coordination overhead energy, and auxiliary systems).\footnote{This is the literal meaning of ``facility joule'': the denominator is \emph{not} IT energy alone. A convenient but imperfect scalar proxy used in industry is PUE, $\mathrm{PUE}(t)=P_{\text{tot}}(t)/P_{\text{IT}}(t)$. In this paper, we avoid collapsing overhead into a constant PUE because Rubin-class regimes make $P_{\text{nonIT}}(t)$ state-dependent (e.g., thermal limits, network congestion, and control policies shift the overhead map) \citep{candler2026efficiencyparadox}.}
Define facility energy in period $t$ (for unit-length periods) as
\begin{equation}
E_{\text{fac}}(t) \;:=\; \int_{t}^{t+1} P_{\text{tot}}(s)\,ds.
\end{equation}

\paragraph{Goodput numerator.}
Let $\text{tokens}(t)$ denote raw token generation in $t$. Delivered goodput must discount tokens that fail quality or latency requirements. We therefore define a planner-facing goodput functional
\begin{equation}
T_g(t) \;:=\; \Phi\!\Big(\text{tokens}(t),\, \text{quality}(t),\, \text{SLA}(t)\Big),
\end{equation}
and, for concreteness, one admissible instantiation is
\begin{equation}
T_g(t) \;=\; \text{tokens}(t)\cdot q(t)\cdot \mathbf{1}\{\text{SLA}(t)\ \text{met}\},
\end{equation}
where $q(t)\in[0,1]$ is a quality/utility weight and $\mathbf{1}\{\cdot\}$ is an indicator for SLA compliance.\footnote{This is intentionally agnostic to whether ``quality'' means accuracy, safety constraints, calibration, latency, or contract-specific performance. The core point is that planners must measure \emph{delivered} intelligence, not raw compute.}

\paragraph{System efficiency.}
The central ratio is therefore
\begin{equation}
\eta_{\text{sys}}(t) \;:=\; \frac{T_g(t)}{E_{\text{fac}}(t)} \qquad \text{(tokens per facility joule)}.
\end{equation}
In Rubin-class regimes, $\eta_{\text{sys}}$ is governed by architecture-aware bottlenecks (memory bandwidth/capacity, interconnect collectives, parallelism overhead, synchronization) rather than by chip FLOPs/W alone \citep{candler2026efficiencyparadox}. A canonical public abstraction of this phenomenon is the roofline discipline: realized throughput is bounded by a minimum of peak compute and bandwidth-limited ceilings \citep{williams2009roofline}. In other words, ``more efficient silicon'' does not guarantee proportional gains in $T_g(t)$ because the conversion from IT work to delivered goodput is bottlenecked by system constraints.

\subsection{Two structural breaks in MW-block planning}
Traditional MW-block planning abstracts large loads as quasi-stationary blocks characterized by an average MW and a load factor. The Rubin-class planning problem breaks this abstraction in two ways: (i) \emph{endogenous volatility} (temporal densification/sprint capacity) and (ii) \emph{intertemporal mismatch} (queue lead time versus silicon economic life) \citep{candler2026efficiencyparadox}.

\subsubsection{Break 1: Endogenous volatility via temporal densification (sprint capacity)}
Let $P_{\text{campus}}(t)$ denote campus real power draw (net of on-site supply) and define the temporal intensity ratio
\begin{equation}
I(t) \;:=\; \frac{P_{\text{campus}}(t)}{\overline{P}_{\text{campus}}},
\qquad
\overline{P}_{\text{campus}} \;:=\; \frac{1}{H}\sum_{t=0}^{H} P_{\text{campus}}(t).
\end{equation}
MW-block planning implicitly treats the distribution of $I(t)$ as exogenous and narrow. Rubin-class control turns $I(t)$ into a decision-linked process: the campus can densify work into short windows (``sprints'') to chase throughput, cost, or performance targets \citep{candler2026efficiencyparadox}. Integration cost, however, is sized to peaks.

\paragraph{Peak-sized integration is structurally nonlinear.}
A planner-relevant integration cost can be represented as a monotone function of peak loading and local deliverability limits, e.g.
\begin{equation}
C_{\text{Int}} \;\approx\; f\!\left(\max_{t\le H} P_{\text{campus}}(t),\, D,\, \pi_{\text{tariff}}\right),
\end{equation}
where $D$ captures deliverability (e.g., constrained import capability) and $\pi_{\text{tariff}}$ captures rule-bound allocations of upgrade responsibility.\footnote{Even when upgrades are ``lumpy'' rather than smooth, the economic implication is stronger: lumpy thresholds make $f$ \emph{more} nonlinear in peak load, increasing the penalty for volatility.}

\paragraph{Reliability exposure is tail-driven.}
Let $\mathcal{S}$ denote the set of scarcity periods (or, more generally, a random event of tight reserve margin). Adequacy risk is typically concentrated in a small set of scarcity hours; thus, reliability exposure depends far more on the \emph{coincidence} of load with scarcity than on annual MWh.\footnote{This is the classic tail dominance of expected unserved energy (EUE): a small number of hours can dominate $\mathbb{E}[\text{EUE}]$. Reliability assessments such as NERC seasonal and long-term assessments provide the institutional context for why tails matter operationally (and why planners focus on stress windows), even when the exact scarcity-hour definition differs by market \citep{nerc2024era,nerc2024ltra}.}
A minimal reduced-form reliability price is therefore a convex penalty applied to scarcity-period net load, e.g.
\begin{equation}
C_{\text{Rel}} \;=\; \sum_{t\in\mathcal{S}} \rho\!\left(P_{\text{net}}(t)\right),
\qquad
\rho'(\cdot) >0,\ \rho''(\cdot)\ge 0,
\end{equation}
where $P_{\text{net}}(t)$ is the system-relevant net load contribution (campus load adjusted for any contracted curtailment and deliverability constraints).\footnote{Convexity is not an arbitrary modeling choice: scarcity costs rise superlinearly as reserves collapse; the marginal system harm of an incremental MW is higher near the adequacy boundary. This is exactly the regime in which a coincidence-pricing construct (EUE/VOLL or scarcity price proxies) becomes the correct interface \citep{candler2026efficiencyparadox}.}

\paragraph{A variance penalty theorem (why ``average MW'' is insufficient).}
The core failure mode of MW-block planning can be stated as a simple inequality.

\begin{proposition}[Volatility increases expected scarcity cost under convex scarcity pricing]
\label{prop:volatility}
Fix any scarcity set $\mathcal{S}$ and any mean $\mathbb{E}[P_{\text{net}}(t)]=\bar{P}$ for each $t\in\mathcal{S}$. If $\rho$ is convex, then
\begin{equation}
\mathbb{E}\!\left[\rho\!\left(P_{\text{net}}(t)\right)\right] \;\ge\; \rho\!\left(\mathbb{E}[P_{\text{net}}(t)]\right) \;=\; \rho(\bar{P}),
\qquad \forall t\in\mathcal{S}.
\end{equation}

Moreover, for mean-preserving spreads of $P_{\text{net}}(t)$ (i.e., increased volatility holding the mean fixed), the expected penalty weakly increases.
\end{proposition}

\begin{proof}
This is an immediate consequence of Jensen's inequality: for convex $\rho$,
$\mathbb{E}[\rho(X)]\ge \rho(\mathbb{E}[X])$ for any integrable random variable $X$.
A mean-preserving spread increases risk in convex order, which weakly increases expectations under all convex functions, including $\rho$.
\end{proof}

Proposition \ref{prop:volatility} formalizes the intuition: even holding \emph{average} MW constant, sprint-like volatility increases expected reliability cost when scarcity pricing is convex. Combined with peak-sized integration, this creates a structural mismatch with MW-block planning: the relevant statistics are higher moments and joint coincidence with scarcity, not the mean load alone \citep{candler2026efficiencyparadox}.

\subsubsection{Break 2: Intertemporal mismatch between energization lead times and silicon life}
The second break is intertemporal mismatch: energization lead times can be long relative to compute hardware upgrade cycles, creating a stranded-asset risk for installed silicon \citep{candler2026efficiencyparadox}. We formalize mismatch via
\begin{equation}
\tau \;:=\; \frac{t_{\text{queue}}}{t_{\text{silicon}}},
\end{equation}
where $t_{\text{queue}}$ is the effective time to deliver firm energization at the required capacity (studies $\rightarrow$ upgrades $\rightarrow$ construction $\rightarrow$ commissioning), and $t_{\text{silicon}}$ is the effective economic life of the compute generation.

\paragraph{A survival-weighted delivered-goodput loss.}
Let $Q$ be a random energization time (queue realization), with CDF $F_Q(t)=\Pr(Q\le t)$. Let $T_g^{\star}(t)$ denote the counterfactual goodput trajectory if power were available from $t=0$. Then the energization-constrained expected delivered goodput is
\begin{equation}
\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\, \mathbf{1}\{t\ge Q\}\,T_g^{\star}(t)\right]
\;=\;
\sum_{t=0}^{H}\delta^t\, \Pr(Q\le t)\, T_g^{\star}(t)
\;=\;
\sum_{t=0}^{H}\delta^t\, F_Q(t)\, T_g^{\star}(t).
\label{eq:queue_survival}
\end{equation}
Equation \eqref{eq:queue_survival} shows the mechanism by which queue delay directly suppresses present-valued delivered intelligence even if nameplate MW is eventually obtained. As $\tau$ increases, $F_Q(t)$ shifts right relative to the hardware economic window, reducing the survival-weighted numerator that the campus can monetize.\footnote{Empirically, queue timelines have lengthened across multiple regions; LBNL summarizes queue volumes and timelines in the \emph{Queued Up} series \citep{lbnl2024queuedup}. This paper uses $\tau$ as a portable mismatch statistic rather than tying results to any single ISO or tariff.}
When $\tau\gtrsim 1$, a nontrivial share of the compute generation is at risk of becoming economically obsolete (or materially suboptimal) before full energization, which is precisely the stranded-asset channel emphasized in \citep{candler2026efficiencyparadox}.

\subsection{Why SMRs belong in this paper: SMR coupling as a boundary-condition technology}
SMRs enter this framework neither as an ideological label (``green baseload'') nor as a generic capacity add. They function as a \emph{boundary-condition technology} that can reshape the feasible set in two planner-relevant ways:

\paragraph{(i) Effective $\tau$ modification via alternative delivery paths.}
SMR coupling can change the energization pathway and therefore the effective mismatch. In the simplest reduced-form, coupling introduces a second energization channel with its own realization time $Q_{\text{SMR}}$ and capacity availability profile, yielding an effective energization indicator
\begin{equation}
\mathbf{1}\{t\ge Q_{\text{eff}}\}
\quad \text{with} \quad
Q_{\text{eff}} := \min\{Q_{\text{grid}},\, Q_{\text{SMR}}\},
\end{equation}
so the survival factor $F_{Q_{\text{eff}}}(t)$ can dominate the numerator of \eqref{eq:queue_survival} even when grid queues are long.\footnote{This is not a claim that SMRs are faster in all cases; it is a statement that coupling introduces \emph{another} stochastic path whose distribution can be compared in the same survival-weighted objective.}

\paragraph{(ii) Operational/governance constraints as feasibility restrictions.}
Coupling also imposes operational constraints (availability patterns, minimum stable generation, ramp limits, islanding rules) and governance constraints (licensing/cyber segmentation requirements) that affect whether the campus reduces grid stress or amplifies it. The key is that coupling can cause the campus to behave as either:
\begin{enumerate}[label=(\alph*), leftmargin=1.25em]
\item a \emph{reliability liability} (if a large stiff tranche must run through scarcity windows), or
\item a \emph{reliability resource} (if a large flexible tranche is contractually curtailable during scarcity and coupling enables genuine decoupling from system peaks),
\end{enumerate}
depending on the joint regime of (workload stiffness, sprint capacity), (deliverability and scarcity structure), and (coupling constraints) \citep{candler2026efficiencyparadox}.
This is the core reason SMRs belong inside the same objective: coupling is a timing-and-feasibility operator on delivered compute, not merely a low-carbon energy label.
\newpage

% =========================================================
% 2. Core Objective: Compute-ASCDE
% =========================================================
\section{Core Objective: Compute-ASCDE}

\subsection{Stochastic, survival-weighted ratio objective (risk-neutral baseline)}
We adopt \emph{Compute-ASCDE}: the present value (PV) of total system cost divided by the PV of \emph{survival-weighted reliable intelligence delivered} \citep{candler2026efficiencyparadox}. Let $(\Omega,\mathcal{F},\mathbb{P})$ represent uncertainty in (i) queue and energization outcomes, (ii) tariff and scarcity states, (iii) forced outage processes, and (iv) technology/campus survival. Let $t\in\{0,1,\dots,H\}$ index discrete planning periods, and let $\delta\in(0,1]$ be the discount factor.

Let the decision object be a \emph{joint design--control} choice
\[
x := (\text{campus design},\ \text{interconnection/contract structure},\ \pi),
\]
where $\pi$ is a (possibly state-feedback) operating policy over the horizon.\footnote{Treating \(\pi\) explicitly is essential: the same nameplate MW can be a reliability liability or asset depending on whether it becomes controllable in scarcity states. Hiding \(\pi\) in narrative language is exactly how MW-block planning loses the sign of the externality.}

Define the (discounted) \emph{random} PV cost and PV delivered-goodput:
\begin{align}
N(x,\omega) &:= \sum_{t=0}^{H}\delta^t\Big(C_{\mathrm{Res}}(t,x,\omega)+C_{\mathrm{Int}}(t,x,\omega)+C_{\mathrm{Rel}}(t,x,\omega)\Big),\\
D(x,\omega) &:= \sum_{t=0}^{H}\delta^t\, S(t,x,\omega)\,T_g(t,x,\omega),
\end{align}
where $S(t,x,\omega)\in[0,1]$ is an energization/survival weight and $T_g$ is delivered goodput (tokens that satisfy quality/SLA filters).\footnote{If you want a single planner-visible denominator, interpret \(S(\cdot)\) as the survival of the \emph{compute service} rather than the physical site alone; i.e., include energization probability, regulatory commissioning probability (where applicable), and effective technology survival under obsolescence. This is the point at which \(\tau=t_{\text{queue}}/t_{\text{silicon}}\) naturally enters the denominator rather than as an ad hoc penalty.}

The risk-neutral baseline objective is the ratio of expectations:
\begin{equation}
\label{eq:ascde_ratio_expectation}
\ASCDE_{AI}(x)
:= \frac{\mathbb{E}[N(x,\omega)]}{\mathbb{E}[D(x,\omega)]},
\qquad\text{with }\ \mathbb{E}[D(x,\omega)]>0.
\end{equation}

\paragraph{Remark (risk aversion).}
For institutions that cannot tolerate tail risk, replace \(\mathbb{E}[N]\) with a coherent risk functional (e.g., \(\mathrm{CVaR}_\alpha(N)\)) or add a penalty \(\rho\,\mathrm{CVaR}_\alpha(\Delta\EUE)\).\footnote{This is a policy choice. The dissertation point is simply: (a) \(\Delta\EUE\) is tail-driven, so risk-neutral valuation can be normatively wrong even when it is mathematically convenient; and (b) the externality mapping below still applies---only the aggregation changes.}


\subsection{Fractional programming: Dinkelbach transform for Compute-ASCDE}
The ratio form in \eqref{eq:ascde_ratio_expectation} is a \emph{fractional program}. Define
\[
f(x):=\mathbb{E}[N(x,\omega)],\qquad g(x):=\mathbb{E}[D(x,\omega)].
\]
Assume \(g(x)>0\) on the feasible set \(\mathcal{X}\) and \(f(x)\) is bounded below.\footnote{Positivity of \(g\) is a feasibility condition: if survival-weighted delivered goodput can be driven to \(0\), the ratio becomes ill-posed and the model should treat the design as infeasible (or assign an explicit “failure cost” rather than allowing division by near-zero).}

\begin{theorem}[Dinkelbach equivalence]\label{thm:dinkelbachequ}
Let \(\mathcal{X}\) be nonempty and \(g(x)>0\) for all \(x\in\mathcal{X}\). Define the parametric auxiliary function
\[
\varphi(\lambda):=\min_{x\in\mathcal{X}} \big(f(x)-\lambda g(x)\big).
\]
Then \(x^\star\in\arg\min_{x\in\mathcal{X}} f(x)/g(x)\) with optimal value \(\lambda^\star=f(x^\star)/g(x^\star)\) if and only if \(\varphi(\lambda^\star)=0\).
\end{theorem}

\begin{proof}[Proof sketch]
(\(\Rightarrow\)) For any \(x\in\mathcal{X}\),
\[
\frac{f(x)}{g(x)}\ge \frac{f(x^\star)}{g(x^\star)}=\lambda^\star
\ \Longrightarrow\
f(x)-\lambda^\star g(x)\ge 0.
\]
Thus the minimum over \(x\) is \(0\), achieved at \(x^\star\).  
(\(\Leftarrow\)) If \(\varphi(\lambda^\star)=0\), then \(f(x)-\lambda^\star g(x)\ge 0\) for all feasible \(x\), i.e. \(f(x)/g(x)\ge \lambda^\star\), so any minimizer of the auxiliary problem is ratio-optimal. Formal treatments and convergence results are standard \citep{dinkelbach1967nonlinear,schaible1983fractional}.
\end{proof}

\paragraph{Operational meaning.}
The transform states: instead of “minimize cost per reliable token,” solve a sequence of \emph{difference} problems
\[
\min_{x\in\mathcal{X}}\ \big(f(x)-\lambda_k g(x)\big),
\]
and update \(\lambda_{k+1}=f(x_k)/g(x_k)\). Under mild regularity conditions, \(\lambda_k\) converges monotonically to \(\lambda^\star\) \citep{dinkelbach1967nonlinear}.\footnote{If the inner problem is nonconvex (likely, because dispatch/control policies and upgrade lags induce nonconvexities), the Dinkelbach transform does not “make it convex”; it makes the ratio well-behaved and gives a clean stopping condition (\(\varphi(\lambda)\approx 0\)). You still need global methods or careful approximations to certify global optimality.}


\subsection{Reliability completeness: from net-load shape to \texorpdfstring{$\Delta\EUE$}{ΔEUE} via scarcity coincidence}
A reliability-complete interface must map campus controls to an adequacy impact metric. Let \(L(t,x,\omega)\) be the campus \emph{net} contribution to system load (positive if importing from grid, negative if exporting), and let \(X(t,\omega)\) be a system adequacy state (e.g., operating reserve margin, LOLP proxy, or scarcity price state).

Define a \emph{scarcity weight} process \(W(t,\omega)\ge 0\) that encodes “how expensive one more MW is” in adequacy terms:
\begin{equation}
\label{eq:scarcity_weight_def}
W(t,\omega) := \frac{\partial \EUE(t,\omega)}{\partial L(t)}\Bigg|_{\text{baseline}}.
\end{equation}
This derivative is the local marginal sensitivity of expected unserved energy to incremental load in period \(t\).\footnote{Equation \eqref{eq:scarcity_weight_def} is an \emph{interface definition}: the planner can estimate \(W\) from probabilistic adequacy models (LOLP/LOLE/EUE), from scarcity pricing states, or from simulation-derived marginal reliability value (MRV) curves. The paper does not require a specific adequacy model; it requires that the institution provide an internally consistent \(W\).}

Under a first-order functional expansion around the baseline system (no-campus) trajectory,
\begin{equation}
\label{eq:delta_eue_linearization}
\Delta \EUE(x)
\;\approx\;
\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\, W(t,\omega)\,L(t,x,\omega)\right].
\end{equation}
The key is that \(W(t,\omega)\) is \emph{state-dependent} and concentrates weight on scarcity hours.

To make “sprint coincidence” explicit, define the normalized \emph{coincidence functional}
\begin{equation}
\label{eq:gamma_def}
\Gamma(x)
:=
\frac{
\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\, W(t,\omega)\,L(t,x,\omega)\right]
}{
\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\, L(t,x,\omega)\right]
}
\quad \text{(when the denominator is positive)}.
\end{equation}
\(\Gamma\) is a planner-visible statistic: it is “how aligned the campus net load is with scarcity-weighted risk,” normalized by total net energy/usage.\footnote{If the campus can sometimes export (negative \(L\)), use \(\Gamma\) tranche-by-tranche with signed contributions, or replace the denominator with \(\mathbb{E}[\sum \delta^t |L|]\). The normalization is not sacred; the point is to expose coincidence as a separate axis from total energy.}

Given \(\Delta\EUE(x)\), the canonical monetization is
\begin{equation}
\label{eq:crel_voll}
C_{\mathrm{Rel}}(t,x,\omega) := \VOLL(t)\cdot \Delta\EUE_t(x,\omega),
\qquad
C_{\mathrm{Rel}}(x) := \mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t C_{\mathrm{Rel}}(t,x,\omega)\right],
\end{equation}
where \(\VOLL\) is the institution’s value of lost load (policy lever) or a scarcity proxy.\footnote{Empirical VOLL estimates vary by customer class and context; the dissertation relevance is not the “right number,” but that \(\VOLL\) converts adequacy impacts into dollar space so the campus optimization cannot externalize reliability by construction. ERCOT provides a canonical survey-and-macroeconomic review format \citep{ercot2013voll}.}


\subsection{Tranche decomposition as an admissible control set (policy space)}
We now formalize the tranche split as an \emph{admissible control set} rather than a definition. Let the campus be decomposed into stiff and flexible nameplates \((P_s,P_f)\) and define utilization controls \(u_s(t)\in[0,1]\), \(u_f(t)\in[0,1]\). Net campus import can be written generically as
\begin{equation}
\label{eq:campus_netload_controls}
L(t,x,\omega)
=
P_s\,u_s(t,\omega)+P_f\,u_f(t,\omega)
\;-\;P_{\text{onsite}}(t,x,\omega)
\;+\;P_{\text{aux}}(t,x,\omega),
\end{equation}
where onsite supply terms (including SMR coupling, storage, etc.) enter through \(x\), and \(P_{\text{aux}}\) captures parasitics tied to operating state.\footnote{You can enrich \eqref{eq:campus_netload_controls} with nonlinear parasitic structure (cooling curves, network overhead that scales with \(\sigma\), etc.) without changing the control logic. What matters is: (i) stiff and flexible actions appear separately, and (ii) the reliability mapping sees their time structure.}

Let \(\mathcal{S}_t\) be the information state available at time \(t\) (e.g., price/scarcity state, onsite availability, thermal constraints). Define a policy \(\pi\) as a measurable mapping from \(\mathcal{S}_t\) to controls \((u_s,u_f)\). The admissible policy class is
\begin{equation}
\label{eq:admissible_policy_set}
\Pi :=
\left\{
\pi:\ \mathcal{S}_t \mapsto (u_s(t),u_f(t))
\ \middle|\
\begin{array}{l}
0\le u_s(t)\le 1,\ 0\le u_f(t)\le 1,\\
u_s(t)\ge \underline{u}_s\ \text{(continuity / stiffness floor)},\\
|u_s(t)-u_s(t-1)|\le r_s\Delta t\ \text{(ramp/interrupt limits)},\\
u_f(t)=0\ \text{on contracted scarcity events (if called)},\\
\text{other feasibility constraints in }x
\end{array}
\right\}.
\end{equation}
The stiffness economics enter through switching costs: let \(C_{\text{switch}}(t,x,\omega)\) be the penalty of changing \(u_s\) (checkpoint/restart/SLA loss). Then include
\begin{equation}
\label{eq:switch_cost_term}
C_{\mathrm{Res}}(t,x,\omega)
\leftarrow
C_{\mathrm{Res}}(t,x,\omega)
+
C_{\text{switch}}(t,x,\omega)\cdot \big|u_s(t,\omega)-u_s(t-1,\omega)\big|.
\end{equation}

\begin{proposition}[Sign of reliability impact under monotone scarcity curtailment]\label{prop:reliability_sign}
Assume the scarcity weight \(W(t,\omega)\ge 0\) and the flexible control satisfies \(u_f(t,\omega)\le u_f^{\text{base}}(t,\omega)\) whenever \(W(t,\omega)\) exceeds a scarcity threshold (i.e., the flexible tranche curtails in high-scarcity states). Holding all else equal, the first-order approximation \eqref{eq:delta_eue_linearization} implies
\[
\Delta\EUE(x)\ \le\ \Delta\EUE(x_{\text{base}}),
\]
with strict inequality if curtailment is nontrivial on a set of positive probability.
\end{proposition}

\begin{proof}
Under \eqref{eq:delta_eue_linearization}, \(\Delta\EUE\) is an expectation of a nonnegative weight \(W\) times net load \(L\). If the only change is that \(u_f\) decreases in high-\(W\) states, then \(L\) decreases exactly where the integrand weight is largest; the weighted sum therefore weakly decreases. Strict decrease follows if \(W>0\) and \(u_f\) decreases on a set of positive measure. \end{proof}

\paragraph{Interpretation.}
Proposition \ref{prop:reliability_sign} formalizes the thesis: the tranche split is not rhetorical---it is the minimal control structure required to make the reliability externality sign-discernible. In Compute-ASCDE, “flexible load” is a mathematically admissible control action with explicit penalties, not a marketing adjective \citep{candler2026efficiencyparadox}.

\subsection{Compute-ASCDE as a well-posed optimization problem}
Combining the above, the planning problem can be stated as
\begin{equation}
\label{eq:ascde_full_problem}
\min_{x\in\mathcal{X},\ \pi\in\Pi}
\frac{\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\left(C_{\mathrm{Res}}(t,x,\omega)+C_{\mathrm{Int}}(t,x,\omega)+C_{\mathrm{Rel}}(t,x,\omega)\right)\right]}
{\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\, S(t,x,\omega)\,T_g(t,x,\omega)\right]},
\end{equation}
with reliability monetization anchored by \eqref{eq:delta_eue_linearization}--\eqref{eq:crel_voll} and coincidence exposed by \eqref{eq:gamma_def}. This is the minimal “planner-facing” definition that (i) respects survival under \(\tau\), (ii) prices time-structured reliability impacts, and (iii) keeps flexibility as an explicit control rather than an implicit assumption.

\newpage


% =========================================================
% 3. Interface Primitives (Planner-facing API)
% =========================================================
\section{Interface Primitives (Planner-facing API)}
\label{sec:interface_primitives}

We define a planner-facing interface as a compact set of primitives grouped into (i) endogenous Rubin-class levers, (ii) exogenous grid/process conditions, and (iii) SMR coupling boundary conditions. The goal is not a narrative parameter list; it is a \emph{measurable, partially observed control system} that can be (a) estimated from telemetry and market data, (b) calibrated to probabilistic adequacy simulations, and (c) evaluated under Monte Carlo in a reliability-complete way \citep{candler2026efficiencyparadox}.

\subsection{Why an ``API'' is mathematically justified}
Let $\Theta$ denote the full parameter space describing: (i) hardware and stack design, (ii) campus control and workload mix, (iii) local network/interconnection conditions, and (iv) market and reliability institutions. Let the full stochastic data-generating process be
\begin{equation}
\mathcal{M}_\Theta:\quad \theta \mapsto \left\{P_{\text{campus}}(t,\omega),\; T_g(t,\omega),\; C_{\mathrm{Res}}(t,\omega),\; C_{\mathrm{Int}}(t,\omega),\; \Delta\EUE(t,\omega)\right\}_{t=0}^{H},
\end{equation}
on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ supporting queue outcomes, scarcity processes, outage events, tariff realizations, and technology survival.

Define an \emph{interface map} $g:\Theta\to\mathbb{R}^d$ such that
\begin{equation}
X := g(\theta) = \big(\RubinVec,\GridVec,\SMRVec\big),
\end{equation}
and suppose the institutionally-defined planning functional (Compute-ASCDE) satisfies an invariance property
\begin{equation}
\ASCDE_{AI}(\theta) = \ASCDE_{AI}(g(\theta))\quad \text{for all }\theta\in\Theta,
\end{equation}
i.e., the objective depends on $\theta$ only through $X$.

\begin{proposition}[Planner-sufficient interface under peak-sizing and tail-dominance]
\label{prop:sufficient_interface}
Assume (A1) \emph{goodput separability}: $T_g(t,\omega)=\Psi\!\left(\eta_{\text{sys}}(t,\omega),u(t,\omega)\right)$ where $\eta_{\text{sys}}$ is a system-efficiency term and $u$ is a control policy; (A2) \emph{peak-sized integration}: $C_{\mathrm{Int}}$ is dominated by upper quantiles of $P_{\text{campus}}$ (peak-driven reinforcement); and (A3) \emph{tail-dominant reliability}: $\Delta\EUE$ is dominated by a small subset of scarcity hours and depends primarily on the coincidence structure between $P_{\text{campus}}$ and scarcity states.
Then there exists a low-dimensional vector $X$ consisting of (i) a system-efficiency primitive and bottleneck descriptors, (ii) a control-feasibility (stiffness) primitive, (iii) a sprint/temporal-densification primitive controlling peak/coincidence statistics, (iv) a queue mismatch primitive $\tau$, (v) scarcity and deliverability primitives, and (vi) coupling boundary conditions, such that $\ASCDE_{AI}$ is invariant to all variations in $\theta$ that leave $X$ unchanged.
\end{proposition}

\begin{proof}[Sketch]
Under (A1), micro-architectural and facility details matter only insofar as they map into realized $\eta_{\text{sys}}$ and the control-response surface $u\mapsto T_g$; under (A2), network reinforcement depends primarily on upper-tail behavior of $P_{\text{campus}}$, governed by temporal densification (sprint) and deliverability; under (A3), reliability externalities are dominated by tail scarcity intervals and depend on (scarcity states) $\times$ (load intensity states) and on whether curtailment is feasible (stiffness). Queue mismatch enters via survival/energization weighting and obsolescence before delivery \citep{lbnl2024queuedup}. SMR coupling affects the feasible set by imposing boundary conditions on net load and controllability. Therefore any two $\theta$ values inducing the same efficiency, stiffness, sprint/tail statistics, queue mismatch, scarcity/deliverability mapping, and coupling constraints yield the same Compute-ASCDE. \qedhere
\end{proof}

\paragraph{Interpretation.}
The API is a claim about \emph{invariance classes}: we compress details that do not move the objective once peak-sizing and tail-reliability are acknowledged as binding mechanisms.

% =========================================================
% 3.0 Formal object: POMDP / state-space
% =========================================================
\subsection{A formal object: partially observed controlled stochastic process}
Let $t\in\{0,1,\dots,H\}$ index planning intervals. Let $\mathcal{I}_t$ be the planner’s information filtration (telemetry, market states, outage flags, contractual calls, study milestones, licensing/cyber flags, etc.). Define:

\begin{itemize}
  \item \textbf{Latent interface state:} $z_t := (\RubinVec_t,\GridVec_t,\SMRVec_t)\in\mathcal{Z}$,
  \item \textbf{Controls:} $u_t := (u_{s,t},u_{f,t})\in\mathcal{U}(z_t)$ (stiff/flexible utilization),
  \item \textbf{Observations:} $y_t\in\mathcal{Y}$ (power/energy, tokens, quality/SLA counters, profiler metrics, scarcity proxy, curtailment call logs),
  \item \textbf{Shocks:} $\xi_t$ (weather, forced outages, queue milestones, tariff changes, licensing state changes).
\end{itemize}

We model the interface as a nonlinear state-space system:
\begin{align}
z_{t+1} &= f(z_t,u_t,\xi_t) + \varepsilon_t, \label{eq:ssm_state}\\
y_t &= h(z_t,u_t,\xi_t) + \eta_t, \label{eq:ssm_obs}
\end{align}
with process noise $\varepsilon_t$ and measurement noise $\eta_t$.

\begin{remark}[Why state-space is the right abstraction]
The sign of the reliability externality is determined by \emph{conditional behavior}: how the flexible tranche responds when the system is in high-scarcity states. A static MW nameplate collapses the relevant conditional law. This is the same reason the fractional objective in Section~2 must treat policy explicitly.
\end{remark}

\paragraph{Filtering (epistemic discipline).}
Inference is
\[
p(z_t\mid y_{0:t}) \propto p(y_t\mid z_t)\int p(z_t\mid z_{t-1},u_{t-1})p(z_{t-1}\mid y_{0:t-1})\,dz_{t-1}.
\]
Linear-Gaussian approximations admit Kalman recursion \citep{kalman1960new}; otherwise particle filtering is appropriate when nonlinearities or regime-switching dominate.\footnote{You do not have to implement a particle filter to use the interface; it is included to force the epistemic point: some primitives are latent and should be carried with uncertainty bands.}

% =========================================================
% 3.1 Rubin vector
% =========================================================
\subsection{Rubin Vector (endogenous): \texorpdfstring{$\RubinVec_t$}{RubinVec} as measurable primitives}
\label{subsec:rubinvec}

\begin{equation}
\RubinVec_t := \{\delta_{\text{sys},t},\; \kappa_{\text{stiff},t},\; \sigma_t,\; \mu_{\text{mem},t},\; \kappa_{\text{net},t}\}.
\end{equation}

\subsubsection{System efficiency gain \texorpdfstring{$\delta_{\text{sys}}$}{δsys}: estimator and boundedness}
Recall $\eta_{\text{sys}}(t)=T_g(t)/E_{\text{fac}}(t)$ (tokens per facility joule). Define baseline and Rubin-class regimes $\eta_{\text{sys}}^{(0)}$ and $\eta_{\text{sys}}^{(1)}$:
\begin{equation}
\delta_{\text{sys}}(t) := \frac{\eta_{\text{sys}}^{(1)}(t)}{\eta_{\text{sys}}^{(0)}(t)}.
\end{equation}
A windowed estimator is
\begin{equation}
\widehat{\eta}_{\text{sys}}(t;W)=\frac{\sum_{k=t-W+1}^t T_g(k)}{\sum_{k=t-W+1}^t E_{\text{fac}}(k)}.
\end{equation}
\footnote{Mixing fundamentally different regimes (training vs inference vs maintenance) turns $\widehat{\eta}_{\text{sys}}$ into a mixture statistic and destroys causal interpretability. Tranche telemetry is not optional if you want identification rather than mere accounting.}

\paragraph{Roofline-style constraint.}
Even if chip-level FLOPs/W improves, realized system goodput is bounded by memory and communication constraints. A roofline-style inequality implies
\begin{equation}
\dot T_g(t)\;\le\;\min\left\{\dot T_{\text{compute}}(t),\ \mathcal{I}(t)\,B_{\text{eff}}(t)\right\},
\end{equation}
so $\delta_{\text{sys}}$ is bounded and regime-dependent \citep{williams2009roofline}. We treat $\mu_{\text{mem}}$ and $\kappa_{\text{net}}$ as planner-visible bottleneck primitives rather than HPC trivia.

\subsubsection{Stiffness \texorpdfstring{$\kappa_{\text{stiff}}$}{κstiff}: an estimable economic ratio}
Define stiffness relative to the value of curtailment during scarcity:
\begin{equation}
\kappa_{\text{stiff}}(t,\omega):=\frac{C_{\text{switch}}(t,\omega)}{\VOLL(t)\,P_s\,\Delta t}.
\end{equation}
A minimal measurable switching-cost estimator is
\begin{equation}
\widehat{C}_{\text{switch}}(t):= p_{\text{token}}(t)\,\Delta T_g(t) + C_{\text{SLA}}(t) + C_{\text{restart}}(t).
\end{equation}
\footnote{If $p_{\text{token}}$ is uncertain, relative stiffness across workloads is still identifiable via paired curtailment experiments under the same scarcity state; absolute monetization is introduced via a chosen $p_{\text{token}}$ prior.}

\subsubsection{Sprint factor \texorpdfstring{$\sigma$}{σ}: temporal densification}
Let $I(t):=P_{\text{campus}}(t)/\overline{P}_{\text{campus}}$. Define regime-conditional sprint factor
\begin{equation}
\sigma(\mathcal{T}) := \frac{\max_{t\in\mathcal{T}} I(t)}{\mathbb{E}[I(t)\mid t\in\mathcal{T}]},
\end{equation}
for a regime set $\mathcal{T}$ (e.g., inference-only weeks).
\footnote{Computing $\sigma$ over a full year confounds maintenance outages with “sprintiness.” The correct object is regime-conditional $\sigma$ and its correlation with scarcity weights $W_t$.}

\subsubsection{Memory and interconnect primitives}
Let $B_{\text{mem}}(t)$ be observed memory BW utilization and $\mathcal{I}(t)$ arithmetic intensity. A roofline-consistent proxy for memory boundedness is
\begin{equation}
\mu_{\text{mem}}(t):=\frac{\text{achieved throughput}(t)}{B_{\text{mem}}(t)\,\mathcal{I}(t)}\in(0,1].
\end{equation}
Let $T_{\text{step}}(t)$ be step time and $T_{\text{comm}}(t)$ time spent in collectives; define
\begin{equation}
\kappa_{\text{net}}(t):=\frac{T_{\text{comm}}(t)}{T_{\text{step}}(t)}\in[0,1).
\end{equation}
\footnote{Planner translation: high $\kappa_{\text{net}}$ is a stiffness amplifier because throttling induces straggler/rollback nonlinearities, increasing $C_{\text{switch}}$ and reducing the effectiveness of partial curtailment.}
Public standards provide an anchor for why memory evolution is first-order without vendor roadmaps \citep{jedec2025hbm4}.

% =========================================================
% 3.4 Grid Vector (exogenous) + Reliability Translation Layer
% (replacement block: seasonal tails, policy-conditional coincidence, ES-weighting,
%  locational constraint operator with dual shadow prices, and MRV/eMRV in Dinkelbach)
% =========================================================

\subsection{Grid Vector (exogenous): \texorpdfstring{$\GridVec_t$}{GridVec} and a reliability translation layer}
\label{subsec:gridvec}

We separate (i) exogenous grid/scarcity processes and network feasibility, and (ii) a \emph{reliability translation layer} that maps campus actions into $\Delta\EUE$ and its marginal value. Adequacy is seasonal and tail-dominant; therefore all coincidence statistics are defined \emph{season-conditionally} to prevent winter/summer mixing from laundering coincidence.

\begin{equation}
\GridVec_t := \{\tau_t,\; \epsilon,\; W_t,\; \mathcal{K}_{t}(\cdot),\; \pi_{\text{tariff}}\}.
\end{equation}

% -----------------------------------------
% Seasonality / Tail events
% -----------------------------------------
\subsubsection{Seasonality and tail events (no ``laundered coincidence'')}
Let $\mathcal{S}$ denote seasons (e.g., ISO accreditation seasons) and let $s(t)\in\mathcal{S}$ map each interval $t$ to its season.
Let $W_t(\omega)\ge 0$ be a scarcity weight process (an adequacy shadow-price proxy, scarcity price proxy, or any calibrated tail-risk weight).

\begin{definition}[Seasonal tail event]\label{def:seasonal_tail_event}
Fix a tail probability level $q_s\in(0,1)$ for each season $s\in\mathcal{S}$. Define the season-$s$ threshold
\[
Q_{s,q_s} \;:=\; \mathrm{Quantile}_{q_s}\!\left(\,W_{t'}:\; s(t')=s\,\right),
\]
and define the seasonal tail event
\[
\mathcal{E}^{(s)}_{t,q_s}\;:=\;\{\,W_t \ge Q_{s(t),q_{s(t)}}\,\}.
\]
\end{definition}

\paragraph{Operational choice of $q_s$ (mass capture).}
A non-arbitrary choice is to select $q_s$ so that the tail event captures most reliability impact in that season:
\begin{equation}\label{eq:qs_mass_capture}
\frac{\mathbb{E}\!\left[\Delta\EUE_t\,\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\mid s(t)=s\right]}
{\mathbb{E}\!\left[\Delta\EUE_t\mid s(t)=s\right]}
\;\ge\;\rho,
\qquad \rho\in[0.8,0.95].
\end{equation}
\footnote{This calibrates the tail definition to the adequacy model rather than an arbitrary quantile. It also aligns with the empirical fact that a small set of hours dominate adequacy risk in each season.}

% -----------------------------------------
% Queue mismatch / rebound
% -----------------------------------------
\subsubsection{Intertemporal mismatch \texorpdfstring{$\tau$}{τ}: censoring-aware queue modeling}
Recall $\tau=t_{\text{queue}}/t_{\text{silicon}}$. Planning requires treating $t_{\text{queue}}$ as a censored random variable (projects not yet energized). Otherwise the survival weight $S(t)$ in Compute-ASCDE is miscalibrated \citep{lbnl2024queuedup}.
\footnote{Treating queue time as deterministic introduces systematic optimism bias. The correct object is a distribution with right-censoring.}

\subsubsection{Rebound elasticity \texorpdfstring{$\epsilon$}{ε}: totals vs.\ coincidence}
We retain $\epsilon$ as a structural sensitivity parameter capturing Jevons-style rebound (lower marginal cost per token induces demand expansion) \citep{sorrell2009jevons}. In this interface, $\epsilon$ changes totals; coincidence statistics below change \emph{alignment with scarcity tails}.

% -----------------------------------------
% Upgrade (H2 optional): deliverability operator + dual prices
% -----------------------------------------
\subsubsection{Upgrade (H2 optional): deliverability as a locational constraint operator \texorpdfstring{$\mathcal{K}_t(\cdot)$}{Kt(.)}}
Instead of a scalar deliverability factor $D_\ell(t)$, we represent deliverability as a binding feasible-set operator induced by network/interface constraints. Let the campus be located at bus (or interface) $\ell$. Under a DC approximation,
\begin{equation}
f_t = H_t\,p_t,
\end{equation}
where $p_t$ is the vector of net injections/withdrawals by bus and $H_t$ is a PTDF-like mapping.\footnote{This formalizes that deliverability is induced by binding constraints on flows/interfaces, not merely a scalar de-rate \citep{wood2012power,cain2012history}.}

Let $\bar f_t$ denote thermal/interface limits. Define the constraint polytope
\begin{equation}
\mathcal{P}_t := \Big\{p_t:\ -\bar f_t \le H_t p_t \le \bar f_t\ \text{(plus interface/voltage/contingency surrogates as applicable)}\Big\}.
\end{equation}
Let $L_t(u_t)$ be campus net load (withdrawal), define $\Delta p_t(u_t):=-L_t(u_t)\,e_\ell$, and let $p_t^{(0)}$ be the baseline net injection vector. Then define
\begin{equation}
\mathcal{K}_t\!\big(L_t(u_t)\big) := \mathbf{1}\left\{p^{(0)}_t + \Delta p_t(u_t)\in \mathcal{P}_t\right\}.
\end{equation}

\paragraph{Scalar summary as a projection statistic (optional).}
If a scalar $D_\ell(t)$ is desired for communication, define it as the largest feasible fraction of a reference withdrawal $L_{\max}$:
\begin{equation}\label{eq:D_projection}
D_\ell(t) := \sup\left\{d\in[0,1]:\ p^{(0)}_t - d\,L_{\max} e_\ell \in \mathcal{P}_t\right\}.
\end{equation}
\footnote{$\mathcal{K}_t$ is the actual constraint object; $D_\ell(t)$ is a lossy scalar projection.}

\paragraph{Constraint shadow prices (dual multipliers).}
For marginal analysis (and for embedding deliverability into optimization), introduce dual multipliers. Consider the linear constraints defining $\mathcal{P}_t$:
\[
-\bar f_t \le H_t p_t \le \bar f_t.
\]
Let $\nu_t^+\ge 0$ and $\nu_t^-\ge 0$ be dual multipliers on the upper/lower bounds, respectively. Define the net dual vector $\nu_t := \nu_t^+ - \nu_t^-$ and the induced locational constraint shadow price
\begin{equation}\label{eq:lambdaK}
\lambda^{\mathcal{K}}_{\ell,t} := \nu_t^\top H_t e_\ell.
\end{equation}
\footnote{This term prices the marginal tightening of binding network constraints per additional MW withdrawal at location $\ell$. It upgrades deliverability from feasibility-only to a priced marginal object.}

% -----------------------------------------
% Coincidence as a policy-conditional statistic
% -----------------------------------------
\subsubsection{Coincidence as a seasonal, policy-conditional statistic \texorpdfstring{$\Gamma_{s,q_s}(\pi)$}{Gamma}}
Let $I_t^\pi:=P_{\text{campus}}^\pi(t)/\overline{P}_{\text{campus}}$ denote normalized campus intensity under an admissible policy $\pi$ (including tranche controls and any call-response logic). Coincidence must be defined conditional on the tail event in the relevant season.

\begin{definition}[Seasonal tail coincidence (policy-conditional)]\label{def:Gamma_tail}
For season $s$ and tail level $q_s$, define
\[
\Gamma_{s,q_s}(\pi)
:=\mathbb{E}\!\left[I_t^\pi \mid \mathcal{E}^{(s)}_{t,q_s},\, s(t)=s\right]
-\mathbb{E}\!\left[I_t^\pi \mid s(t)=s\right].
\]
\end{definition}
\footnote{This statistic is explicitly \emph{policy-dependent}. Two campuses with identical annual MWh can have radically different $\Gamma_{s,q_s}(\pi)$ if one concentrates load in scarcity-tail windows.}

\begin{definition}[Severity-weighted tail coincidence (ES-weighting)]\label{def:Gamma_ES}
Define the seasonal threshold $Q_{s,q_s}$ as in \cref{def:seasonal_tail_event} and the excess-scarcity weight
\[
\widetilde{W}_t^{(s)} := (W_t - Q_{s(t),q_{s(t)}})_+.
\]
Then define the severity-weighted (expected-shortfall) coincidence functional
\[
\Gamma^{\mathrm{ES}}_{s,q_s}(\pi)
:=\frac{\mathbb{E}\!\left[I_t^\pi\,\widetilde{W}_t^{(s)} \mid s(t)=s\right]}
{\mathbb{E}\!\left[\widetilde{W}_t^{(s)} \mid s(t)=s\right]}
-\mathbb{E}\!\left[I_t^\pi \mid s(t)=s\right].
\]
\end{definition}
\footnote{Quantile exceedance captures \emph{whether} a tail state occurs; ES-weighting captures \emph{how severe} the tail state is. Adequacy costs are typically severity-dominated.}

% -----------------------------------------
% Reliability translation: Delta EUE, MRV/eMRV, and Dinkelbach embedding
% -----------------------------------------
\subsubsection{Reliability translation: \texorpdfstring{$\Delta\EUE$}{ΔEUE}, MRV/eMRV, and embedding into Dinkelbach}
Define incremental expected unserved energy relative to an agreed baseline:
\begin{equation}
\Delta \EUE_t := \EUE_t^{(\mathrm{with\ campus})}-\EUE_t^{(\mathrm{baseline})}.
\end{equation}
A canonical monetization is
\begin{equation}
C_{\mathrm{Rel}}(t,\omega)=\VOLL(t)\,\Delta\EUE_t(\omega).
\end{equation}

\paragraph{MRV (marginal reliability value).}
Let $\mathrm{Cap}_{\ell,t}$ denote deliverable firm capacity at location $\ell$. Define
\begin{equation}
\mathrm{MRV}_{\ell,t}:=-\frac{\partial \EUE_{\ell,t}}{\partial \mathrm{Cap}_{\ell,t}}\cdot \VOLL_z \;\;\ge 0.
\end{equation}
\footnote{This is the standard adequacy planning construct: marginal capacity cost is compared against marginal reliability benefit (monetized via VOLL).}

\paragraph{Effective MRV under binding constraints (eMRV).}
If using the scalar projection $D_\ell(t)$, define
\begin{equation}
\mathrm{eMRV}_{\ell,t} := \mathrm{MRV}_{\ell,t}\cdot D_\ell(t).
\end{equation}
More generally, interpret MRV as being computed conditional on $\mathcal{P}_t$ and thus consistent with $\mathcal{K}_t(\cdot)$.

\begin{proposition}[Finite-difference MRV estimation with variance reduction]\label{prop:mrv_fd_seasonal}
A production estimator for $\partial \EUE_{\ell,t}/\partial \mathrm{Cap}_{\ell,t}$ is the finite difference
\[
\frac{\partial \EUE_{\ell,t}}{\partial \mathrm{Cap}_{\ell,t}}
\approx
\frac{\EUE_{\ell,t}(\mathrm{Cap}_{\ell,t}+\Delta)-\EUE_{\ell,t}(\mathrm{Cap}_{\ell,t})}{\Delta},
\]
computed by rerunning the \emph{same} probabilistic adequacy simulation under a small capacity perturbation $\Delta$ using common random numbers across baseline and perturbed runs (same weather years, outage seeds, etc.).
\end{proposition}

\paragraph{First-order campus externality with seasonal tails and coincidence.}
Let $L_t^\pi:=L_t(u_t^\pi)$ denote net campus load under policy $\pi$ and baseline $L_t^{(0)}$. A tail-focused first-order approximation is
\begin{equation}\label{eq:deltaeue_tail_firstorder}
\Delta \EUE_t(\omega)\;\approx\;
\beta_{\ell,t}(\omega)\,\big(L_t^\pi-L_t^{(0)}\big)\,\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\},
\qquad \beta_{\ell,t}(\omega)\ge 0,
\end{equation}
where $\beta_{\ell,t}$ is calibrated to the underlying adequacy model (and may be season-dependent). One convenient decomposition is
\begin{equation}\label{eq:beta_decomp}
\beta_{\ell,t}(\omega)
=\underbrace{\frac{\mathrm{MRV}_{\ell,t}}{\VOLL_z}}_{\text{adequacy sensitivity}}
\times
\underbrace{\Gamma_{s,q_s}(\pi)\ \text{or}\ \Gamma^{\mathrm{ES}}_{s,q_s}(\pi)}_{\text{policy coincidence}}
\times
\underbrace{\mathbf{1}\{\mathcal{K}_t(L_t^\pi)=1\}}_{\text{binding feasibility}},
\end{equation}
so that coincidence (policy) and deliverability (network feasibility) explicitly modulate adequacy impact.

\paragraph{Embedding MRV/eMRV as a reliability shadow-price in the Dinkelbach subproblem.}
Let Section~2 define the ratio objective
\[
\min_{\pi\in\Pi}\ \frac{\mathbb{E}\!\left[C_{\mathrm{Cap}}(\pi)+C_{\mathrm{Res}}(\pi)+C_{\mathrm{Int}}(\pi)+C_{\mathrm{Rel}}(\pi)\right]}
{\mathbb{E}\!\left[G(\pi)\right]},
\]
and let $\lambda$ denote the Dinkelbach parameter. The auxiliary problem is
\[
\min_{\pi\in\Pi}\ \mathbb{E}\!\left[C_{\mathrm{Cap}}+C_{\mathrm{Res}}+C_{\mathrm{Int}}+C_{\mathrm{Rel}} - \lambda\,G\right].
\]
Under the first-order tail approximation, the reliability term admits a \emph{shadow-price form}:
\begin{equation}\label{eq:rel_shadow_price_form}
\mathbb{E}[C_{\mathrm{Rel}}(\pi)]
\approx
\mathbb{E}\!\left[\mathrm{eMRV}_{\ell,t}\,\big(L_t^\pi-L_t^{(0)}\big)\,\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\right],
\end{equation}
(or replace $\mathrm{eMRV}_{\ell,t}$ by an operator-consistent marginal value conditional on $\mathcal{P}_t$).
If constraint shadow prices are tracked, a composite (adequacy + deliverability) marginal penalty may be formed via
\begin{equation}\label{eq:composite_shadow_price}
\widetilde{\mathrm{MRV}}_{\ell,t}
:= \mathrm{eMRV}_{\ell,t} + \lambda^{\mathcal{K}}_{\ell,t},
\end{equation}
so that the Dinkelbach subproblem internalizes both adequacy externality and binding network stress in a single planner-facing marginal term.\footnote{This is optional but conceptually clean: $\mathrm{eMRV}$ prices adequacy (EUE) while $\lambda^\mathcal{K}$ prices binding deliverability constraints. In constrained systems, both can matter at the margin.}

% =========================================================
% 3.3 SMR Vector (boundary conditions)
% =========================================================
\subsection{SMR Vector (boundary conditions): \texorpdfstring{$\SMRVec_t$}{SMRVec} as constrained availability}
\label{subsec:smrvec}

The SMR coupling enters the planner interface as a \emph{boundary-condition state} that restricts feasible campus power trajectories and therefore (i) alters the achievable coincidence statistics in seasonal tail events and (ii) reshapes the admissible-control set $\mathcal{U}(z_t)$ through minimum-generation, ramping, islanding, heat-rejection, and governance constraints. The SMR vector is not an asset catalog; it is the minimal set of variables required to (a) write auditable feasibility constraints and (b) propagate availability and implementability uncertainty into Monte Carlo evaluation.

\paragraph{Notation standardization.}
We adopt the convention $(\cdot)_{\mathrm{SMR}}$ for reactor-coupled quantities and superscripts $(\cdot)^{\max}$ for nameplate/limits. The islanding indicator is denoted by $\mathcal{I}_{\mathrm{island}}\in\{0,1\}$, while governance/cyber/licensing constraints are encoded by an operator $\pi_{\mathrm{lic/cyber}}$ (a constraint object, not a scalar). Time is indexed by $t\in\{0,1,\dots,H\}$ with control interval $\Delta t$ (hours).

\subsubsection{Definition of the SMR vector}
\label{subsubsec:smrvec_def}

\begin{equation}\label{eq:smrvec_def}
\SMRVec_t \coloneqq
\left\{
P_{\mathrm{SMR}}^{\max},\;
a_{\mathrm{SMR},t},\;
u_{\mathrm{SMR}}^{\min},\;
r_{\mathrm{SMR}},\;
\mathcal{I}_{\mathrm{island}},\;
Q_{\mathrm{rej}}^{\max},\;
\pi_{\mathrm{lic/cyber}}
\right\}.
\end{equation}

\paragraph{Interpretation of primitives.}
$P_{\mathrm{SMR}}^{\max}$ is electrical nameplate available to the campus/microgrid (gross or net, as specified below). $a_{\mathrm{SMR},t}\in[0,1]$ is a \emph{time-structured availability/derate} factor; the binary special case $a_{\mathrm{SMR},t}\in\{0,1\}$ is recovered immediately. $u_{\mathrm{SMR}}^{\min}\in[0,1]$ is minimum stable generation as a fraction of nameplate. $r_{\mathrm{SMR}}$ is the admissible ramp rate (MW per hour). $\mathcal{I}_{\mathrm{island}}$ indicates whether islanded operation is feasible in principle. $Q_{\mathrm{rej}}^{\max}$ is an upper bound on heat rejection (site/thermodynamic constraint). $\pi_{\mathrm{lic/cyber}}$ encodes licensing, cyber, segmentation, and operational-governance restrictions as \emph{admissibility constraints} on policies and control actions.

\subsubsection{Availability as a stochastic derate process}
\label{subsubsec:smr_availability}

We treat SMR availability as a derate factor $a_{\mathrm{SMR},t}\in[0,1]$ to avoid overstating firmness during seasonal tail events. A minimal reliability prior is a two-state Markov chain for the \emph{binary} case, with immediate extension to derates.

\paragraph{Binary special case (Markov chain).}
If $a_{\mathrm{SMR},t}\in\{0,1\}$, a minimal model is:
\begin{equation}\label{eq:smr_markov}
\mathbb{P}\!\left(a_{\mathrm{SMR},t+1}=1 \mid a_{\mathrm{SMR},t}=1\right)=1-p_{\mathrm{out}},
\qquad
\mathbb{P}\!\left(a_{\mathrm{SMR},t+1}=1 \mid a_{\mathrm{SMR},t}=0\right)=p_{\mathrm{rec}}.
\end{equation}

\paragraph{Scheduled maintenance decomposition (optional).}
A convenient separation of scheduled and stochastic components is:
\begin{equation}\label{eq:smr_maint_decomp}
a_{\mathrm{SMR},t}=\mathbf{1}\{t\notin\mathcal{M}\}\cdot \tilde a_{\mathrm{SMR},t},
\end{equation}
where $\mathcal{M}$ is a known (or scenario-set) maintenance/refueling window set and $\tilde a_{\mathrm{SMR},t}$ is a forced-outage/derate process (binary or fractional).

\paragraph{Tail-conditioning (adequacy-consistent evaluation).}
Because adequacy is seasonal and tail-dominant, planner-relevant feasibility and coincidence statistics are evaluated conditional on the seasonal tail event sets $\mathcal{E}^{(s)}_{t,q_s}$ defined in \cref{subsec:gridvec}. In particular, the probability of SMR feasibility and the induced grid-facing withdrawal distribution should be analyzed under $\mathcal{E}^{(s)}_{t,q_s}$ rather than under an unconditional annual mixture.
\footnote{This prevents winter/summer mixing from laundering coincidence: the externality is dominated by seasonal tail states, hence the relevant statistics must be conditional on those states.}

\subsubsection{Coupling topology and power balance}
\label{subsubsec:smr_topology}

Let $P_{\mathrm{SMR},t}$ denote gross SMR electrical output at time $t$. Let $P^{\mathrm{aux}}_{\mathrm{SMR},t}\ge 0$ denote auxiliary/house loads (optional but auditable). Define net deliverable SMR electrical output:
\begin{equation}\label{eq:smr_net_output}
P^{\mathrm{net}}_{\mathrm{SMR},t}\coloneqq P_{\mathrm{SMR},t}-P^{\mathrm{aux}}_{\mathrm{SMR},t},
\qquad
0\le P^{\mathrm{SMR}\rightarrow\mathrm{camp}}_t \le P^{\mathrm{net}}_{\mathrm{SMR},t}.
\end{equation}
Let $P^{\mathrm{grid}}_t$ denote grid import at the POI (grid-facing withdrawal). Let tranche controls be $u_t=(u_{s,t},u_{f,t})$ and define campus net load (withdrawal) using the tranche-resolved model:
\begin{equation}\label{eq:campus_netload_tranche}
L_t(u_t)\coloneqq L_{s,t}(u_{s,t})+L_{f,t}(u_{f,t})-G_t,
\end{equation}
where $G_t$ captures behind-the-meter generation (if any).

\paragraph{Instantaneous power balance.}
Ignoring storage for notational clarity (storage can be appended additively), impose:
\begin{equation}\label{eq:campus_balance_smr}
L_t(u_t)=P^{\mathrm{SMR}\rightarrow\mathrm{camp}}_t + P^{\mathrm{grid}}_t.
\end{equation}
\footnote{Reliability externalities and deliverability constraints operate on the \emph{system-facing} withdrawal $P^{\mathrm{grid}}_t$, not on total campus demand. SMR coupling is planner-relevant because it reshapes the distribution of $P^{\mathrm{grid}}_t$ in tail events even when $L_t(u_t)$ is held fixed.}

\subsubsection{SMR feasibility constraints as a time-dependent feasible set}
\label{subsubsec:smr_feasible_set}

The SMR variables restrict admissible power trajectories through a time-dependent feasibility set $\mathcal{F}^{\mathrm{SMR}}_t$. The feasibility constraints below are written so they can be inserted directly into the admissible-control set definition $\mathcal{U}(z_t)$.

\paragraph{Electrical output limits (availability-gated).}
\begin{align}
0 \le P_{\mathrm{SMR},t} &\le a_{\mathrm{SMR},t}\,P_{\mathrm{SMR}}^{\max}, \label{eq:smr_cap}\\
a_{\mathrm{SMR},t}>0\ \Rightarrow\ 
u_{\mathrm{SMR}}^{\min}\,P_{\mathrm{SMR}}^{\max} \le P_{\mathrm{SMR},t} &\le a_{\mathrm{SMR},t}\,P_{\mathrm{SMR}}^{\max}. \label{eq:smr_mingen}
\end{align}
\footnote{Minimum stable generation can bind precisely when the campus attempts deep curtailment in low-demand hours. In the absence of export paths, storage, or controllable thermal loads, SMR coupling can \emph{reduce} flexibility by enforcing a nonzero generation floor.}

\paragraph{Ramping / cycling constraint.}
Impose an intertemporal ramp constraint:
\begin{equation}\label{eq:smr_ramp}
\left|P_{\mathrm{SMR},t}-P_{\mathrm{SMR},t-1}\right|\le r_{\mathrm{SMR}}\,\Delta t.
\end{equation}
\footnote{This bounds the speed with which SMR output can respond to scarcity calls or abrupt changes in flexible-tranche utilization. If $u_{f,t}$ changes faster than \cref{eq:smr_ramp} permits, the residual must be absorbed by $P^{\mathrm{grid}}_t$ and/or storage (if modeled), which directly affects tail withdrawal and therefore $\Delta \EUE$.}

\paragraph{Heat rejection constraint (site/ambient coupling).}
Let $Q_{\mathrm{rej},t}$ denote required heat rejection. Impose:
\begin{equation}\label{eq:smr_heat_reject}
0 \le Q_{\mathrm{rej},t} \le Q_{\mathrm{rej}}^{\max}.
\end{equation}
If desired, relate heat rejection to electrical output via an abstract efficiency map:
\begin{equation}\label{eq:smr_heat_map}
Q_{\mathrm{rej},t}=\mathcal{H}\!\left(P_{\mathrm{SMR},t},\vartheta_t\right),
\end{equation}
where $\vartheta_t$ includes ambient conditions and cooling configuration.
\footnote{This makes it possible for hot-weather scarcity seasons to bind SMR feasible output through $Q_{\mathrm{rej}}^{\max}$ without committing to a detailed thermodynamic model in the planner interface.}

\subsubsection{Islanding as a topology control with transition feasibility}
\label{subsubsec:smr_islanding}

If $\mathcal{I}_{\mathrm{island}}=1$, islanding is admissible subject to binary topology logic and transition feasibility; if $\mathcal{I}_{\mathrm{island}}=0$, islanding is infeasible. Introduce an islanding indicator $b_t\in\{0,1\}$:
\begin{equation}\label{eq:island_logic}
b_t \le \mathcal{I}_{\mathrm{island}},
\qquad
b_t=1 \Rightarrow P^{\mathrm{grid}}_t=0.
\end{equation}
\footnote{Islanding is a topology change, not a continuous control. Treating it as binary prevents the modeling error of assuming costless instantaneous transitions.}

\paragraph{Transition energy sufficiency (minimal dynamic honesty).}
Let $E^{\mathrm{buf}}_t$ be available fast buffer energy (UPS/storage/ride-through) at time $t$, and let $\Delta t_{\mathrm{tr}}$ be a transition window (seconds-to-minutes). Require:
\begin{equation}\label{eq:island_buffer}
E^{\mathrm{buf}}_t \ge L_t(u_t)\,\Delta t_{\mathrm{tr}}
\quad \text{whenever } |b_t-b_{t-1}|=1.
\end{equation}
\footnote{This blocks an unphysical artifact: instantaneous topology switching without sufficient ride-through capability to maintain power quality during synchronization/islanding events.}

\subsubsection{Governance as an admissibility operator on policies and actions}
\label{subsubsec:smr_governance}

We model licensing/cyber/segmentation constraints as an operator restricting admissible policies:
\begin{equation}\label{eq:pi_lic_cyber}
\pi_{\mathrm{lic/cyber}}:\ \Pi \to \{0,1\},
\qquad
\Pi_{\mathrm{adm}} \coloneqq \{\pi\in\Pi:\ \pi_{\mathrm{lic/cyber}}(\pi)=1\}.
\end{equation}
Under a policy $\pi\in\Pi_{\mathrm{adm}}$, admissible controls satisfy:
\[
u_t^\pi \in \mathcal{U}(z_t)\quad\text{and}\quad (P_{\mathrm{SMR},t},b_t,P^{\mathrm{grid}}_t)\in \mathcal{F}^{\mathrm{SMR}}_t
\quad \text{a.s.}
\]

\paragraph{Control-latency constraint (governance $\rightarrow$ feasibility).}
Let $\ell_{\mathrm{ctrl}}(\pi)$ denote the effective end-to-end latency (measurement $\rightarrow$ authorization $\rightarrow$ actuation) under policy $\pi$. Feasibility in dispatch interval $\Delta t$ requires:
\begin{equation}\label{eq:ctrl_latency}
\ell_{\mathrm{ctrl}}(\pi)\le \Delta t.
\end{equation}
\footnote{This prevents ``paper'' flexibility: if the governance stack cannot actuate within the planning interval, the action is not admissible and must not be credited in tail-event response.}

\paragraph{Concrete constraint classes (examples).}
Typical restrictions induced by $\pi_{\mathrm{lic/cyber}}$ include: (i) human-in-the-loop requirements on setpoint changes; (ii) constraints on data-plane/controls-plane connectivity between campus and nuclear control domains; (iii) restrictions on workload placement or telemetry aggregation during islanded modes; and (iv) response-time limitations due to authentication/approval steps. Encoding these as admissibility constraints prevents feasibility from being buried in qualitative prose.

\subsubsection{Security/contingency wrapper (optional but planner-faithful)}
\label{subsubsec:smr_security_wrapper}

If a contingency criterion is required (e.g., N-1), define a contingency set $\mathcal{C}$ and a conservative secure-feasible set:
\begin{equation}\label{eq:smr_secure_set}
\mathcal{F}^{\mathrm{SMR,sec}}_t \coloneqq \bigcap_{c\in\mathcal{C}} \mathcal{F}^{\mathrm{SMR},(c)}_t,
\end{equation}
and require $(P_{\mathrm{SMR},t},b_t,P^{\mathrm{grid}}_t)\in \mathcal{F}^{\mathrm{SMR,sec}}_t$.
\footnote{This expresses the planner-grade idea—feasibility under contingencies—without committing to a full OPF formulation in the interface section.}

\subsubsection{Planner translation: how \texorpdfstring{$\SMRVec_t$}{SMRVec} binds coincidence and reliability}
\label{subsubsec:smr_translation}

The SMR vector affects adequacy externalities through two channels:

\begin{enumerate}
  \item \textbf{Grid-facing withdrawal reshaping.} By \cref{eq:campus_balance_smr}, SMR output reduces the grid-facing withdrawal $P^{\mathrm{grid}}_t$ (the object that enters deliverability feasibility $\mathcal{K}_t(\cdot)$ and the reliability mapping $\Delta\EUE$) in seasonal tail events $\mathcal{E}^{(s)}_{t,q_s}$.
  \item \textbf{Control-feasibility reshaping.} Minimum generation \cref{eq:smr_mingen}, ramping \cref{eq:smr_ramp}, islanding logic \cref{eq:island_logic}--\cref{eq:island_buffer}, heat rejection \cref{eq:smr_heat_reject}--\cref{eq:smr_heat_map}, and governance admissibility \cref{eq:pi_lic_cyber}--\cref{eq:ctrl_latency} jointly determine which policies $\pi$ are implementable and therefore constrain attainable seasonal coincidence statistics $\Gamma_{s,q_s}(\pi)$ and the sign/magnitude of the reliability externality.
\end{enumerate}
\footnote{This is why the SMR vector belongs in the planner interface rather than in an engineering appendix: it directly constrains the admissible policy set that determines tail coincidence and thus $\Delta\EUE$ and the corresponding shadow-price terms used downstream (e.g., MRV/eMRV in the Dinkelbach subproblem).}

% =========================================================
% 3.6 Admissible controls (ties to tariff table)
% =========================================================
\subsection{Tranche decomposition as an explicit admissible control set}
\label{sec:admissible_controls}

We elevate tranche decomposition from a definition into the admissible control set used in optimization and Monte Carlo.

\begin{definition}[Tranche-resolved load model]
Let $L_{s,t}$ and $L_{f,t}$ be tranche loads induced by controls $(u_{s,t},u_{f,t})$. The campus net load is
\[
L_t(u_t)=L_{s,t}(u_{s,t})+L_{f,t}(u_{f,t})-G_t,
\]
where $G_t$ includes behind-the-meter generation (if any).
\end{definition}

\begin{assumption}[Basic feasibility, boundedness, and POI constraints]
For each $t$,
\[
0\le u_{s,t}\le \bar{u}_{s,t},\qquad 0\le u_{f,t}\le \bar{u}_{f,t},
\]
and the induced net load respects POI and coupling limits:
\[
0\le L_t(u_t)\le L_{\mathrm{POI},t}(z_t).
\]
\end{assumption}

\paragraph{Ramp / cycling constraints.}
To avoid degenerate solutions that “teleport” flexible load into vanishing-measure windows, impose a ramp bound:
\[
|L_t(u_t)-L_{t-1}(u_{t-1})|\le R_{\max}(z_t),
\]
or a tranche-resolved variant.

\paragraph{Curtailment-call compatibility.}
Let $c_t\in\{0,1\}$ denote an external curtailment call. Then admissible controls must satisfy
\begin{equation}
c_t=1\ \Rightarrow\ u_{f,t}\le \bar{u}_{f,t}^{(\mathrm{call})},
\end{equation}
with compensation/penalties encoded by $\pi_{\text{tariff}}$.

% =========================================================
% 3.7 Upgrade (2): standardized estimation protocol
% =========================================================
\subsection{Upgrade: a standardized interface calibration protocol (audit-ready)}
\label{sec:interface_calibration}

To prevent parameter drift and silent miscalibration, we standardize estimation as an explicit protocol.

\vspace{0.5em}
\noindent\begin{center}
\fbox{\begin{minipage}{0.95\linewidth}
\textbf{Interface Calibration Algorithm (planner-facing, audit-ready)}

\textbf{Inputs:}
(i) telemetry: $\{P_{\text{campus}}(t),E_{\text{fac}}(t),T_g(t),\text{SLA/quality flags}\}$;
(ii) profiler metrics: $\{B_{\text{mem}}(t),T_{\text{comm}}(t),T_{\text{step}}(t)\}$;
(iii) scarcity proxy or adequacy weights: $\{W_t\}$;
(iv) network constraints: $\{H_t,\bar f_t\}$ (or interface limits) to define $\mathcal{K}_t(\cdot)$;
(v) curtailment call logs: $\{c_t\}$ and achieved response;
(vi) queue/study milestones for $\tau$; (vii) tariff/program rule object $\pi_{\text{tariff}}$.

\textbf{Step 1 (Tranche partition):}
Partition telemetry into regimes (training/inference/maintenance) and tranches (stiff/flexible). Validate tranche metering consistency.

\textbf{Step 2 (Estimator suite):}
Compute $\widehat{\eta}_{\text{sys}}(t;W)$, $\widehat{\delta}_{\text{sys}}$, $\widehat{\sigma}(\mathcal{T})$, $\widehat{\mu}_{\text{mem}}$, $\widehat{\kappa}_{\text{net}}$.
Estimate $\widehat{C}_{\text{switch}}$ from curtailment events and compute $\widehat{\kappa}_{\text{stiff}}$.

\textbf{Step 3 (Uncertainty bands):}
Produce quantiles $(P10,P50,P90)$ for each primitive using block bootstrap over time windows or hierarchical priors.\footnotesize{(Block bootstrap avoids underestimating uncertainty under autocorrelation.)}\normalsize

\textbf{Step 4 (MRV calibration):}
Estimate MRV/eMRV via finite-difference perturbations in the adequacy model (common random numbers) and enforce deliverability feasibility with $\mathcal{K}_t(\cdot)$.

\textbf{Step 5 (Monte Carlo integration):}
Sample $(\RubinVec,\GridVec,\SMRVec)$ with their uncertainty bands and simulate policy $\pi$ to obtain distributions for $\ASCDE_{AI}$ and each cost component.

\textbf{Outputs:}
(i) calibrated primitives with uncertainty bands; (ii) MRV/eMRV curves by location/season; (iii) policy-feasible control set $\mathcal{U}(z_t)$; (iv) Monte Carlo distributions for decision metrics (P10/P50/P90).
\end{minipage}}
\end{center}
\vspace{0.5em}

\footnote{System identification principle: without designed excitation (variation in controls), stiffness is weakly identified and confounded with operator conservatism. See standard identification treatments \citep{ljung1999system}.}

% =========================================================
% 3.8 Upgrade (3): contract/program mapping table
% =========================================================
\subsection{Contract / program encoding: \texorpdfstring{$\pi_{\text{tariff}}$}{πtariff} as a rule-map (baseline, calls, settlement, penalties, feasibility)}
\label{sec:tariff_mapping}

We treat $\pi_{\text{tariff}}$ as an auditable rule object, not a scalar price:
\[
\pi_{\text{tariff}}:\ (t,\mathcal{I}_t,u_t,L_t,c_t)\mapsto
\big(\mathrm{cashflow}_t,\ \mathrm{penalty}_t,\ \mathrm{constraints}_t\big).
\]
The planner-relevant point is that the contract/program \emph{defines admissible controls} by imposing baseline logic, event triggers, performance requirements, and measurement constraints.

\paragraph{Baseline (counterfactual) definition.}
Let $B_t(\cdot)$ denote the settlement baseline (e.g., agreed schedule, meter baseline, CBP/10-in-10, etc.), computed from information $\mathcal{I}_t$ and a baseline rulebook:
\[
B_t = B_t(\mathcal{I}_t;\ \pi_{\text{tariff}}).
\]
Define realized net load $L_t(u_t)$ and deviation
\[
\Delta_t := B_t - L_t(u_t).
\]
This $\Delta_t$ is the fundamental settlement quantity. If $B_t$ is ill-defined or unauditable, $\pi_{\text{tariff}}$ is not operationally well-posed.\footnote{This is where “\$ / MWh” summaries typically hide the ball. Baseline choice changes the effective objective and the incentive-compatibility of any policy $\pi$.}

\paragraph{Event/call definition.}
Let $c_t\in\{0,1\}$ be the curtailment call indicator with trigger rule
\[
c_t = \tau_c(\mathcal{I}_t;\ \pi_{\text{tariff}}),
\]
e.g., scarcity state, emergency declaration, price threshold, or reliability controller call. Calls bind feasibility:
\[
c_t=1 \ \Rightarrow\ u_{f,t}\le \bar u^{(\mathrm{call})}_{f,t},
\]
(and $u_{s,t}$ only under explicitly-defined emergency clauses).

\paragraph{Obligation and compliance metric.}
Let $R_t$ be the required response (MW or MWh) and $\Pi_t(\cdot)$ the compliance metric (average MW, response time, duration, ramp, etc.). A canonical obligation form is
\[
c_t=1\ \Rightarrow\ \Delta_t \ge R_t,
\]
with compliance evaluated as
\[
\Pi_t = \Pi_t(\Delta_{t:t+\Delta T},\ \dot L_{t:t+\Delta T},\ \text{latency};\ \pi_{\text{tariff}}).
\]

\paragraph{Payments and penalties.}
Write settlement as the sum of a payment schedule and a penalty schedule:
\[
\mathrm{cashflow}_t = \phi_t^{+}(\Pi_t;\ \pi_{\text{tariff}}),\qquad
\mathrm{penalty}_t  = \phi_t^{-}(\Pi_t;\ \pi_{\text{tariff}}).
\]
This makes explicit what the table was trying to say: the economics are conditional on the rule-map, not an average energy price.

\paragraph{Measurement \& verification (M\&V) as a feasibility gate.}
Let $\mathcal{MV}$ encode telemetry requirements (meter placement, sampling interval, audit rights, data retention). We model M\&V as a \emph{domain constraint}:
\[
(u_t, L_t, B_t)\ \text{is admissible only if}\ (u_t,L_t,B_t)\in\mathrm{Dom}(\mathcal{MV}).
\]
Without tranche-level telemetry, stiffness and compliance become weakly identified.

\paragraph{Network feasibility / deliverability filter.}
If deliverability is encoded via the locational feasibility operator $\mathcal{K}_t(\cdot)$ (Section~\ref{subsec:gridvec}), then only actions that are feasible at the binding constraint set count for settlement or reliability credit:
\[
\text{credited response at }t:\quad \Delta_t^{\mathrm{cred}} := \Delta_t\cdot \mathbf{1}\{\mathcal{K}_t(L_t(u_t))=1\}.
\]
\footnote{This prevents “paper flexibility”: a campus may curtail, but if the binding constraint is elsewhere (or the action is not deliverable to the constrained interface), the adequacy benefit is near-zero.}

\paragraph{Summary: $\pi_{\text{tariff}}$ binds the admissible control set.}
Collecting the above, the admissible control set becomes
\[
\mathcal{U}(z_t;\pi_{\text{tariff}})=
\Big\{u_t:\ \text{box/ramp constraints hold, call constraints hold, M\&V holds, and (if required) }\mathcal{K}_t \text{ holds}\Big\}.
\]

% =========================================================
% 3.9 Identifiability tiers (kept; tightened)
% =========================================================
\subsection{Identifiability: what can be learned vs. what must be assumed}
\label{sec:identifiability}

\paragraph{Tier 1 (directly observable or nearly so).}
$\sigma$ (power telemetry), $\eta_{\text{sys}}$ and $\delta_{\text{sys}}$ (tokens + facility energy), and parts of $\kappa_{\text{net}},\mu_{\text{mem}}$ (profiler counters).

\paragraph{Tier 2 (identifiable with designed excitation).}
$\kappa_{\text{stiff}}$ requires deliberate variation (curtailment experiments or contractual calls) that create observable shifts in $u_{f,t}$ under known scarcity states.
\footnote{No excitation, no identification: without variation in controls, you cannot distinguish “inflexible workload” from “policy never attempts flexibility.” This is standard in system identification \citep{ljung1999system}.}

\paragraph{Tier 3 (structural priors + external data).}
$\tau$ from censoring-aware queue evidence \citep{lbnl2024queuedup}; $\mathcal{K}_t$ from study/interface models; $a_{\text{SMR},t}$ from priors unless operational history exists.

\paragraph{Minimum data hooks (audit-ready).}
(i) interval power/energy by tranche; (ii) delivered tokens + quality/SLA flags; (iii) profiler counters for comm/memory proxies; (iv) scarcity proxy $W_t$; (v) curtailment call logs and compliance; (vi) queue/study milestone timestamps; (vii) network constraint snapshot for $\mathcal{K}_t$.
\footnote{Without tranche telemetry, $\sigma$ and $\eta_{\text{sys}}$ remain estimable, but $\kappa_{\text{stiff}}$ becomes weakly identified and the externality sign can become indeterminate. In that regime, the correct output is not a confident recommendation; it is an uncertainty statement plus a data acquisition plan.}

\subsection{Summary: why the interface is sufficient}
This API is sufficient (not maximal) because it preserves three orthogonal axes required by Compute-ASCDE:
\begin{enumerate}
  \item \textbf{Efficiency/throughput axis:} $\delta_{\text{sys}}$ with bottleneck structure $(\mu_{\text{mem}},\kappa_{\text{net}})$,
  \item \textbf{Time-structure axis:} $\sigma$ and scarcity alignment via $W_t$ and $\Gamma_t$,
  \item \textbf{Control feasibility axis:} $\kappa_{\text{stiff}}$ and the admissible set $\mathcal{U}(z_t)$ as constrained by $\pi_{\text{tariff}}$ and $\mathcal{K}_t(\cdot)$.
\end{enumerate}
MW-block planning collapses (2) and (3). Compute-ASCDE requires them to remain explicit.


\newpage

% =========================================================
% 4. Regime Analysis
% =========================================================
\section{Regime Analysis: When SMR Coupling Reduces Grid Stress}

We characterize regimes in the joint space $(\RubinVec,\GridVec,\SMRVec)$. The result is not a single ``SMR good/bad'' conclusion but a map of admissible outcomes.

\subsection{Formalization: campus controls and scarcity process}
Let $u_s(t)\in[0,1]$ and $u_f(t)\in[0,1]$ denote stiff and flexible utilization controls, with tranche nameplates $P_s,P_f>0$ so that
\begin{equation}
P_{\text{campus}}(t)=P_s u_s(t)+P_f u_f(t).
\end{equation}
Let $\mathcal{S}(t,\omega)\in\{0,1\}$ indicate scarcity hours (or a continuous scarcity price process). A curtailable contract is a policy constraint that induces $u_f(t)\approx 0$ when $\mathcal{S}=1$ up to penalty terms captured in $C_{\text{switch}}$.

\subsection{Regime A: Stress-reduction (SMR as reliability boundary-condition)}
\textbf{Sufficient conditions (operational).}
Stress reduction is feasible when: (i) flexible tranche share is large and economically curtailable ($\kappa_{\text{stiff}}$ small for the flexible tranche), (ii) sprint factor is bounded or actively controlled during scarcity, and (iii) coupling allows decoupling from system peaks (via islanding and/or dispatchable exchange).
A sufficient condition family is:
\begin{equation}
\Pr\!\left(\kappa_{\text{stiff},f}(t,\omega)\ll 1\right)\ \text{high},\quad
\sigma \le \bar{\sigma},\quad
\mathcal{I}_{\text{island}}=1\ \text{or}\ P_{\text{grid}}(t)\ \text{dispatchable},\quad
r_{\text{SMR}}\ \text{adequate}.
\end{equation}

\textbf{Mechanism.}
If $u_f(t)$ is contracted to curtail during scarcity, then $\Delta\EUE(t)$ decreases relative to a non-curtailable baseline, potentially making $C_{\mathrm{Rel}}(t)<0$ (net system benefit). SMR coupling can stabilize delivered compute and reduce peak coincidence with the grid scarcity process \citep{candler2026efficiencyparadox}.

\subsection{Regime B: Neutral coupling (SMR as energy supply, not a timing fix)}
\textbf{Condition.}
Neutrality obtains when $\tau$ remains large and/or governance and tariff rules prevent meaningful dispatch so the campus behaves approximately as a static block once energized:
\begin{equation}
\tau \text{ large} \quad \text{and} \quad
\pi_{\text{tariff}},\pi_{\text{license/cyber}} \Rightarrow u_f(t)\ \text{not dispatchable}.
\end{equation}

\textbf{Mechanism.}
Rebound and growth in demand for tokens can dominate device-level efficiency improvements, leaving absolute grid stress ambiguous even if energy per token falls \citep{sorrell2009jevons,candler2026efficiencyparadox}.

\subsection{Regime C: Sprint coincidence (SMR enables peak stress)}
\textbf{Condition.}
Sprint coincidence arises when a large stiff tranche must operate through scarcity and/or minimum stable generation forces output during peaks, combined with high $\sigma$:
\begin{equation}
\kappa_{\text{stiff},s}\gg 1,\quad \sigma \text{ high},\quad u^{\min}_{\text{SMR}} \text{ high (forcing must-run)}, \quad \mathcal{I}_{\text{island}}=0\ \text{(or constrained)}.
\end{equation}

\textbf{Mechanism.}
Temporal densification increases $\Delta C_{\mathrm{Int}}>0$ (peak-driven upgrades) while stiff tranches increase scarcity coincidence and raise $C_{\mathrm{Rel}}(t)$ \citep{candler2026efficiencyparadox}. In this regime, SMR coupling can increase grid stress even if average energy per token improves.

\subsection{A proposition linking curtailment policy to reliability externality (planner-side)}
The framework supports formal claims once $\Delta\EUE$ is instantiated by a system model (or proxy). The following is an abstract proposition that becomes testable once the reliability functional is specified.

\begin{proposition}[Curtailable flexibility weakly reduces reliability externality under monotone scarcity impact]
Assume the incremental reliability impact functional satisfies monotonicity: for any two campus net load profiles $P^{(1)}_{\text{campus}}(t)\le P^{(2)}_{\text{campus}}(t)$ for all $t$ in scarcity hours, we have
\(
\Delta\EUE^{(1)}(t,\omega)\le \Delta\EUE^{(2)}(t,\omega)
\)
for all scarcity hours. If a contract/control policy enforces $u_f(t)=0$ on scarcity hours (up to bounded switching penalties) while leaving the stiff tranche unchanged, then the induced reliability cost component $C_{\mathrm{Rel}}$ is weakly lower than the non-curtailable baseline in expectation:
\[
\mathbb{E}\!\left[\sum_t \delta^t C_{\mathrm{Rel}}^{\text{curt}}(t,\omega)\right]
\le
\mathbb{E}\!\left[\sum_t \delta^t C_{\mathrm{Rel}}^{\text{base}}(t,\omega)\right].
\]
\end{proposition}

\begin{proof}[Proof sketch]
Curtailment reduces campus load on scarcity hours by construction. By monotonicity, $\Delta\EUE$ weakly decreases on those hours, so the VOLL-weighted cost weakly decreases. The bound is robust to stochasticity because expectation preserves order under almost-sure inequalities. The only caveat is that some systems can exhibit non-monotone effects if curtailment destabilizes operations elsewhere; such effects must be made explicit in the chosen $\Delta\EUE$ mapping.
\end{proof}

\newpage

% =========================================================
% 5. Implementation: Dispatch/Contract Primitive
% =========================================================
\section{Implementation: ``Stiff vs Flexible'' as the Dispatch/Contract Primitive}

\subsection{Control variables}
Let $u_f(t)\in[0,1]$ denote flexible utilization and $u_s(t)\in[0,1]$ stiff utilization. Campus power is
\begin{equation}
P_{\text{campus}}(t)=P_s u_s(t)+P_f u_f(t).
\end{equation}

\subsection{Feasible set under SMR coupling (microgrid exchange form)}
Let $P_{\text{SMR}}(t)$ be SMR electrical output and $P_{\text{grid}}(t)$ be net import from the bulk grid (positive import, negative export if allowed). Then
\begin{align}
P_{\text{campus}}(t) &\le P_{\text{SMR}}(t) + P_{\text{grid}}(t), \\
P_{\text{SMR}}(t) &\in [u^{\min}_{\text{SMR}}P_{\text{SMR}},\, P_{\text{SMR}}], \\
\dot P_{\text{SMR}}(t) &\le r_{\text{SMR}}, \\
u_s(t) &\ge \underline{u}_s \quad \text{(continuity / stiffness feasibility)}, \\
u_f(t) &\approx 0 \quad \text{during scarcity windows if contracted and if } \kappa_{\text{stiff},f}\ll 1, \\
P_{\text{grid}}(t) &\in \mathcal{P}_{\text{grid}}(t;\,D,\pi_{\text{tariff}}) \quad \text{(deliverability/tariff feasibility)}.
\end{align}
The set $\mathcal{P}_{\text{grid}}$ encodes deliverability constraints and tariff rules (e.g., must-take obligations, export prohibitions, curtailable compensation rules).

\subsection{Planner-side optimization}
The planner minimizes $\ASCDE_{AI}$ over contract and control policies (and possibly capacity sizing choices) subject to the feasibility set and the institution's reliability pricing functional.\footnote{Institutions can implement $C_{\mathrm{Rel}}(t)$ via EUE/VOLL, scarcity pricing, capacity charges, or procurement rules that compensate curtailable loads. The interface does not assume one market design; it requires an explicit mapping from scarcity exposure to cost.}

\subsection{Stress Scenario S4: The Cyber-Physical ``Double Whammy''}

To validate the robustness of the $\SMRVec$ boundary conditions, we subject the campus to a coincident failure mode: a 72-hour Dunkelflaute event overlapping with an adversarial malware injection targeting the stiff HIPMoS tranche.



\begin{enumerate}
    \item \textbf{Physical Stress:} $P_{\text{grid}}^{\max} \to 0$ due to VRE drought, forcing the campus into ``Island Mode'' ($\mathcal{I}_{\text{island}}=1$).
    \item \textbf{Cyber Stress:} An injection attack forces the HIPMoS compute load ($P_s$) to spike by 40\% to perform deep-packet inspection.
    \item \textbf{Operational Result:} The planner must demonstrate that the Flexible Tranche ($P_f$) is curtailed with zero latency ($\tau_{\text{shed}} \to 0$) to accommodate the stiff load spike without violating the SMR thermal ramp $r_{\text{SMR}}$.
    \item \textbf{Failure Condition:} If $\pi_{\text{license/cyber}}$ drops below 0.9 during the ramp, the SMR scrams, leading to total campus blackout. This defines the \textit{Unit Criticality} of the Zero-Trust integration.
\end{enumerate}

\newpage

% =========================================================
% 6. INL Integration: Parameterizing the Nuclear-Compute Interface
% =========================================================
\section{INL Integration: Parameterizing the Nuclear-Compute Interface}
\label{sec:inl_integration}

This section specifies an explicit translation layer from INL-style nuclear operations research to the planner interface in Section~3. The translation has three objectives:
(i) classify nuclear-adjacent compute workloads into \emph{stiff} vs \emph{flexible} tranches with auditable switching penalties;
(ii) represent licensing/cyber posture as an \emph{admissibility operator} on control policies (not an ex-post narrative constraint); and
(iii) enforce SMR thermal and ramp feasibility as \emph{binding constraints} that cap compute sprinting and shape seasonal tail coincidence.

\subsection{Interface objects and the mapping problem}
Let $u(t)$ denote the tranche control at time $t$ (Section~3), and let $P_{\mathrm{grid}}(t)$ be grid-facing withdrawal at the POI. The nuclear-compute coupling enters through the interface state
\[
z(t) \coloneqq \big((\RubinVec)_t,(\GridVec)_t,(\SMRVec)_t\big),
\]
and through an admissible policy set $\Pi_{\mathrm{adm}}$ induced by $\pi_{\mathrm{lic/cyber}}$ (Appendix~\ref{app:smr_vector}).
We write the core translation as a workload-to-interface map:
\[
\mathcal{T}_{\mathrm{INL}}:\ \{\text{workloads, procedures, constraints}\}\ \mapsto\ 
\left\{ \kappa_{\mathrm{stiff}}(t),\ C_{\mathrm{switch}}(t),\ \Pi_{\mathrm{adm}},\ \sigma_{\max}(t),\ \mathcal{F}^{\mathrm{SMR}}_t \right\}.
\]
\footnote{This is the clean division of labor: INL-style domain models populate the interface primitives; the planner then optimizes over admissible policies and computes tail-coincidence penalties via Appendix~\ref{app:grid_vector}.}

\subsection{Always-on cyber as a maximally stiff tranche (HIPMoS as an operational-zone load)}
HIPMoS-like host-based intrusion prevention for nuclear operational technology is not a generic ``IT load'': it participates in an operational risk budget where missed detection or delayed detection can force conservative operating modes (and, in the limit, trigger protective actions) \citep{talukder2023zerotrustnpp}. We therefore model the HIPMoS tranche as stiff in the precise sense that curtailment is \emph{inadmissible} (hard constraint) over normal dispatch horizons.

\paragraph{Hard constraint form (preferred).}
Let $P_{\mathrm{hip}}(t)$ be required cyber workload power. Impose
\begin{equation}\label{eq:hipmos_hard}
P_{\mathrm{hip}}(t)\ \ge\ \underline{P}_{\mathrm{hip}}\quad \forall t,
\end{equation}
and treat any violation as infeasible. This corresponds to $\kappa_{\mathrm{stiff}}\to\infty$ in the sense that the implied switching cost dominates any plausible scarcity payment.

\paragraph{Soft constraint form (if you need a continuous penalty).}
If you need differentiability, let $P_D(t)$ be a detection probability proxy and penalize curtailment through a risk functional:
\begin{equation}\label{eq:hipmos_soft}
C_{\mathrm{cyber}}(t) \coloneqq \chi\!\left(1-P_D(t)\right),\qquad
P_D(t)=\mathcal{D}\!\left(P_{\mathrm{hip}}(t),\ \text{telemetry quality},\ \text{threat model}\right),
\end{equation}
with $\chi(\cdot)$ convex and rapidly increasing near the operating threshold.
\footnote{The hard-constraint representation \eqref{eq:hipmos_hard} is typically the correct planner abstraction: many nuclear security controls are treated as non-dispatchable requirements. The soft form \eqref{eq:hipmos_soft} is useful only if you are explicitly modeling graded degradation under supervisory approval.}

\paragraph{Governance/segmentation linkage (admissibility, not ``best practice'').}
These workloads also constrain \emph{which policies} are legal: segmentation rules restrict coupling between safety/security telemetry and high-variance compute sprinting. Encode this as $\pi_{\mathrm{lic/cyber}}$ excluding policies that co-schedule or co-control HIPMoS and sprintable training workloads in ways that violate segmentation and audit requirements \citep{talukder2023zerotrustnpp}.
\footnote{This makes governance machine-checkable: if a policy requires control-plane connectivity or automated setpoint updates that are prohibited, it is excluded from $\Pi_{\mathrm{adm}}$ by definition.}

\subsection{Radiological sensing as explicit tranche bifurcation (real-time vs post-event)}
Hybrid neural models for NaI gamma spectroscopy (radioisotope identification) provide a canonical bifurcation: a safety-monitoring pathway with high switching penalties and a post-event analytics pathway with substantial elasticity \citep{galib2021nai_ml_radioisotopes}.

\paragraph{Two-tranche decomposition.}
Write the radiological workload power as
\[
P_{\mathrm{rad}}(t)=P_{\mathrm{rad}}^{\mathrm{stiff}}(t)+P_{\mathrm{rad}}^{\mathrm{flex}}(t).
\]
The stiff component supports real-time monitoring (missed detections and calibration drift dominate), while the flexible component supports batch reprocessing (precision ratios, localization, retrospective inference).

\paragraph{Switching penalty as a planner-visible statistic.}
Let the flexible utilization control be $u_f(t)\in[0,1]$ (Section~3). A minimal switching-loss model is
\begin{equation}\label{eq:rad_switch_cost}
C_{\mathrm{switch}}(t) \coloneqq c_{\mathrm{sw}}\cdot \mathbf{1}\{u_f(t)<u_f(t{-}1)\}\ +\ c_{\mathrm{re}\text{-}\mathrm{sync}}\cdot \mathbf{1}\{\text{mode change}\},
\end{equation}
where $c_{\mathrm{re}\text{-}\mathrm{sync}}$ captures calibration/validation overhead after throttling.
\footnote{This is exactly the interface role of $\kappa_{\mathrm{stiff}}$: it is a normalized representation of switching penalty relative to scarcity value (Section~3). Nuclear-relevant compute often has large $c_{\mathrm{re}\text{-}\mathrm{sync}}$ due to audit and validation requirements, even when raw FLOPs are elastic.}

\subsection{DeepONet as a physical oracle for sprint feasibility (operator-learning view)}
The core technical hazard is time-scale mismatch: Rubin-class compute can change power rapidly, while the SMR thermal-hydraulic state evolves with transport lags and safety margins. The interface therefore requires a \emph{real-time feasibility oracle} that maps control histories and load trajectories to thermal-state predictions.

\paragraph{Operator formulation.}
Let $u_{\mathrm{rod}}(\tau)$ denote rod/control input history and let $P_{\mathrm{AI}}(\tau)$ denote compute load history. Define the (unknown) operator
\[
\mathcal{G}:\ (u_{\mathrm{rod}},P_{\mathrm{AI}})\ \mapsto\ T_{\mathrm{out}}(\cdot),
\]
mapping histories to the outlet temperature trajectory. A Deep Operator Network approximates $\mathcal{G}$ via a branch/trunk decomposition (Appendix formalism is appropriate if you keep it):
\[
T_{\mathrm{out}}(t)\approx \sum_{k=1}^{p} b_k\!\left(u_{\mathrm{rod}}(t_1{:}t_m),P_{\mathrm{AI}}(t_1{:}t_m)\right)\,\tau_k(t).
\]
\footnote{Planner interpretation: this is not ``ML for its own sake''; it is a surrogate for the feasibility boundary of $\mathcal{F}^{\mathrm{SMR}}_t$ that can be queried at dispatch cadence.}

\paragraph{Sprint cap as a state-dependent constraint.}
Let the sprint factor $\sigma(t)\ge 1$ scale a baseline compute profile $P_{\mathrm{base}}(t)$, so that $P_{\mathrm{AI}}(t)=\sigma(t)P_{\mathrm{base}}(t)$ on sprint windows. Define thermal headroom
\[
\Delta T_{\mathrm{safe}}(t)\coloneqq T_{\mathrm{scram}}-\widehat{T}_{\mathrm{out}}(t),
\]
where $\widehat{T}_{\mathrm{out}}(t)$ is the oracle prediction. Then define a conservative sprint cap:
\begin{equation}\label{eq:sprint_cap}
\sigma(t)\ \le\ \sigma_{\max}(t)\ \coloneqq\ 
\sup\Big\{\sigma\in[1,\sigma_{\mathrm{peak}}]:\ \widehat{T}_{\mathrm{out}}^{\,(\sigma)}(t{+}\tau)\le T_{\mathrm{scram}}-\epsilon,\ \forall \tau\in[0,\tau_{\mathrm{lag}}]\Big\},
\end{equation}
where $\widehat{T}_{\mathrm{out}}^{\,(\sigma)}$ denotes the oracle prediction under sprint factor $\sigma$ and $\tau_{\mathrm{lag}}$ is a transport/response horizon.
\footnote{The lag horizon is what makes this nontrivial: safety depends on near-future thermal evolution, not only instantaneous $T_{\mathrm{out}}(t)$. $\epsilon>0$ enforces a safety buffer and absorbs oracle error (you can tune it from calibration bands).}

\subsubsection{Thermal-lag inequality (energy-form constraint)}
A convenient energetic form that binds integrated sprints is:
\begin{equation}\label{eq:sprint_lag_ineq}
\int_{t}^{t+\Delta t_{\mathrm{sprint}}} \dot{P}_{\mathrm{AI}}(\tau)\,d\tau
\ \le\
C_{\mathrm{th}}\cdot \Big(T_{\mathrm{scram}}-\widehat{T}_{\mathrm{out}}(t)\Big),
\end{equation}
where $C_{\mathrm{th}}$ is an effective thermal capacitance proxy and $\Delta t_{\mathrm{sprint}}$ is the sprint duration.
\footnote{This inequality is the correct control primitive for ``sub-second'' sprinting: it constrains the energy impulse delivered into the thermal system, not merely the instantaneous MW level. In the planner, \eqref{eq:sprint_lag_ineq} becomes part of $\mathcal{F}^{\mathrm{SMR}}_t$ and therefore restricts admissible policies and attainable coincidence statistics.}

\subsection{Heat rejection coupling: a conservative planner-safe interpretation}
The heat-rejection limit $Q_{\mathrm{rej}}^{\max}$ in $(\SMRVec)_t$ (Appendix~\ref{app:smr_vector}) bounds feasible sustained output in hot-weather seasons. The correct planner-level statement is:

\begin{quote}
\emph{When $Q_{\mathrm{rej}}^{\max}$ binds (or cooling efficiency deteriorates), the feasible set for sustained compute-goodput shrinks, and the optimal policy shifts toward lower-variance control trajectories that reduce $P_{\mathrm{grid}}(t)$ inside seasonal tail events.}
\end{quote}

If you choose to keep the entropy/``high-temperature search'' narrative, the technically safe way to write it is as a \emph{modeling hypothesis}:
\[
\textbf{Hypothesis (optional):}\quad
\text{higher-variance inference/control trajectories induce higher energy per useful token,}
\]
so the planner may prefer lower-variance modes under binding heat constraints.
\footnote{Keep this as an explicit hypothesis unless you are prepared to empirically calibrate ``energy per useful token'' against decoding/search settings on the actual stack. The interface can support the hypothesis (as a policy feature), but it should not be asserted as a physical theorem without measurement.}

\subsection{How this feeds Section~3: stiffness, admissibility, and seasonal coincidence}
The INL-to-interface mapping supplies three planner-visible channels:
\begin{enumerate}
\item \textbf{Stiffness channel:} HIPMoS and real-time sensing raise $\kappa_{\mathrm{stiff}}(t)$ by making curtailment infeasible or expensive (via hard constraints or $C_{\mathrm{switch}}$).
\item \textbf{Admissibility channel:} $\pi_{\mathrm{lic/cyber}}$ excludes unsafe or noncompliant co-control policies, shrinking $\Pi$ to $\Pi_{\mathrm{adm}}$.
\item \textbf{Feasibility channel:} DeepONet-style oracles and heat/ramp constraints define $\mathcal{F}^{\mathrm{SMR}}_t$ and cap $\sigma(t)$ via \eqref{eq:sprint_cap}--\eqref{eq:sprint_lag_ineq}.
\end{enumerate}
Together these channels determine the attainable seasonal tail amplification $\Gamma_{s,q_s}(\pi)$ (Appendix~\ref{app:grid_vector}) and therefore the sign/magnitude of the adequacy externality in the Compute-ASCDE numerator.

\newpage

% =========================================================
% 7. Stakeholder Deliverables (INL Instantiation)
% =========================================================
\section{What INL Gets: The Reliability-Complete Interface}
\label{sec:inl_deliverables}

The INL instantiation of Compute-ASCDE-SMR is not a narrative about ``AI loads''; it is a \emph{planner-facing interface contract}.
The deliverable is a set of auditable objects that let INL (and counterparties) compute, explain, and govern the sign and magnitude
of the campus reliability externality under policy, cyber, and physics constraints. Concretely, the interface yields a closed loop:

\[
(\RubinVec_t,\GridVec_t,\SMRVec_t,\pi_{\mathrm{tariff}})\ \longrightarrow\ 
\Pi_{\mathrm{adm}}\ \longrightarrow\ 
\{P_{\mathrm{grid}}^{\pi}(t),T_g^{\pi}(t)\}\ \longrightarrow\
\{\Delta C_{\mathrm{Int}},\Delta C_{\mathrm{Rel}},\ASCDE_{\mathrm{AI}}\},
\]
where admissibility $\Pi_{\mathrm{adm}}$ enforces licensing/cyber constraints and $\Delta C_{\mathrm{Rel}}$ is computed via the MRV/eMRV
translation in Appendix~\ref{app:grid_vector}. This section lists what INL ``gets'' as \emph{deliverable artifacts} rather than as aspirations.

% ---------------------------------------------------------
\subsection{Deliverable A: Reliability Translation Layer (EUE $\rightarrow$ shadow price $\rightarrow$ policy penalty)}
\label{subsec:deliverable_reliability_layer}

\paragraph{Object.}
A standardized translation layer that maps campus policies into a reliability shadow-price penalty inside the planning objective:
\[
\VOLL(t)\,\Delta\EUE^{\pi}_t
\approx
\mathrm{eMRV}_{\ell,t}\,\mathbf{1}\!\left\{\mathcal{E}^{(s)}_{t,q_s}\right\}
\Big(P_{\mathrm{grid}}^{\pi}(t)-P_{\mathrm{grid}}^{\pi^{(0)}}(t)\Big),
\]
with seasonal tails $\mathcal{E}^{(s)}_{t,q_s}$, tail-amplification diagnostics $\Gamma_{s,q_s}(\pi)$, and deliverability semantics
encoded by the active constraint geometry (Appendix~\ref{app:grid_vector}).\footnote{This replaces the common but non-auditable move
of treating ``deliverability'' as a free scalar multiplier and treating ``coincidence'' as an annual statistic. Here, both are
conditioned on the adequacy season and the binding constraint set.}

\paragraph{Why this matters.}
INL can answer, in the same mathematical language used by planners and regulators, the question:
\emph{“Does this campus reduce scarcity-hour stress or amplify it?”}
The answer is expressed as (i) a tail-amplification statistic $\Gamma_{s,q_s}(\pi)$, and (ii) a reliability shadow price
$\mathrm{eMRV}_{\ell,t}$ that penalizes the policy’s tail withdrawals.

\paragraph{Audit outputs.}
For any candidate policy family $\pi\in\Pi_{\mathrm{adm}}$, the interface emits:
(i) seasonal tail definitions and quantiles $\{q_s\}$,
(ii) estimated $\Gamma_{s,q_s}(\pi)$ with uncertainty bands,
(iii) MRV/eMRV estimates with variance-reduction metadata (CRN finite differences),
and (iv) the induced reliability penalty contribution to the Dinkelbach auxiliary objective.\footnote{In practice, this is the
minimum set needed to survive an ``expert witness'' level challenge: define the tail; show the coincidence statistic; show how it
enters the objective; show how deliverability changes the penalty.}

% ---------------------------------------------------------
\subsection{Deliverable B: Monetized Cyber-Risk Ledger (HIPMoS as a binding feasibility and risk constraint)}
\label{subsec:deliverable_cyber_ledger}

\paragraph{Object.}
A planner-usable cyber ledger that (i) places always-on HIPMoS inside the \emph{stiff} tranche, and (ii) quantifies the value of
not curtailing it as an \emph{avoided expected loss} term that is treated analogously to a reliability constraint. In its minimal form,
the ledger introduces a cyber loss functional
\[
C_{\mathrm{cyb}}^{\pi}
\coloneqq
\mathbb{E}\!\left[\sum_{t=0}^{H}\delta^t\,
\mathcal{L}_{\mathrm{cyb}}\!\left(\,P_D^{\pi}(t),\ \mathcal{A}(t)\,\right)\right],
\]
where $P_D^{\pi}(t)$ is the (policy-dependent) detection probability and $\mathcal{A}(t)$ is an exogenous adversary/activity state.\footnote{You
do \emph{not} need to claim a fully specified threat model; it is sufficient to (a) declare what $P_D$ proxy you measure (telemetry completeness,
sampling latency, classifier confidence, etc.), and (b) define $\mathcal{L}_{\mathrm{cyb}}$ as an institutionally chosen loss mapping (bounded,
monotone decreasing in $P_D$). The interface then treats HIPMoS curtailment as an inadmissible action unless explicitly priced and approved.}

\paragraph{How it binds the interface.}
HIPMoS appears in two places:
(i) as a high-stiffness tranche contribution to $\kappa_{\mathrm{stiff}}$ (curtailment is infeasible absent explicit override), and
(ii) inside the governance admissibility operator $\pi_{\mathrm{lic/cyber}}$, which forbids coupling actions that violate segmentation rules.

\paragraph{Why this is a deliverable (not a vibe).}
The ledger produces a number that planners can use: a shadow value of always-on cyber compute under the same discounting and
risk-accounting conventions used for reliability.\footnote{This prevents a common failure mode: cyber claims living in a separate
qualitative silo, while the economic planning objective silently assumes they are costless or always satisfiable.}

% ---------------------------------------------------------
\subsection{Deliverable C: Auditable Tranche Contracts (VPP-grade, baseline/call/penalty semantics)}
\label{subsec:deliverable_contracts}

\paragraph{Object.}
A contract-spec mapping that turns flexible-tranche behavior into an \emph{auditable control product}:
baseline $B_t$, call signal $c_t$, obligation $R_t$, performance metric $\Pi_t$, and penalty schedule
are encoded by $\pi_{\mathrm{tariff}}$ and thereby restrict the admissible control set $\mathcal{U}(z_t)$
(Section~3; contract mapping block).\footnote{The key shift is that tariffs are treated as \emph{control admissibility constraints}
and cashflow operators, not as after-the-fact settlement decorations.}

\paragraph{Deliverable form (clean, non-table).}
For each program type (ISO DR, capacity-like call option, bilateral reliability hedge), the interface outputs a short “term sheet”:
\begin{itemize}
  \item \textbf{Measurement primitive:} $B_t(\cdot)$ definition, telemetry granularity, and M\&V rule.
  \item \textbf{Control primitive:} admissible action family $u_{f,t}\in\mathcal{U}_f(z_t)$ during calls, including ramp/duration limits.
  \item \textbf{Settlement primitive:} $\phi_t^{+}(\Pi_t)$ and $\phi_t^{-}(\Pi_t)$, explicitly tied to compliance and exceptions.
  \item \textbf{Deliverability primitive:} whether the product counts only when $\|\nu_t\|>0$ (binding constraint set) and how that is certified.
\end{itemize}

\paragraph{Why INL cares.}
This turns “flexibility” into a sellable instrument without violating nuclear governance constraints: the product is
\emph{flexible tranche only}, with explicit carve-outs for stiff/safety workloads and segmentation limits.

% ---------------------------------------------------------
\subsection{Deliverable D: Physics-Aware Interconnection and Queue-Value Control}
\label{subsec:deliverable_interconnection}

\paragraph{Object.}
A co-optimized interface that prevents the ``efficiency paradox'' mode in which improvements in $\delta_{\mathrm{sys}}$ and sprint capacity $\sigma$
increase peak coincidence and thus integration/reliability cost faster than they increase delivered goodput. The deliverable is a sensitivity surface:
\[
(\delta_{\mathrm{sys}},\kappa_{\mathrm{stiff}},\sigma,\tau,\SMRVec,\GridVec)\ \mapsto\ 
\big(\Delta C_{\mathrm{Int}},\Delta C_{\mathrm{Rel}},\ASCDE_{\mathrm{AI}}\big),
\]
with explicit sign conditions for whether SMR coupling decreases, is neutral to, or increases scarcity-tail withdrawals.\footnote{In queue terms:
this is the difference between “nameplate MW” and “deliverable MW in the relevant tail season,” and between “site capacity” and “energization probability”
via $S(t)$. The interface makes those distinctions non-optional.}

\paragraph{Queue-facing outputs.}
INL can attach to any candidate delivery path:
(i) a survival-weighted energization model $S(t)$,
(ii) a deliverability semantics (operator $\mathcal{K}_t$ or multiplier weight $\omega_{\ell,t}$),
and (iii) the implied distribution of Compute-ASCDE under Monte Carlo.\footnote{This is the minimal apparatus needed to avoid optimizing against
a deterministic COD date that is false in expectation.}

% ---------------------------------------------------------
\subsection{Deliverable E: Radiological Data Sovereignty via Islanding Semantics}
\label{subsec:deliverable_islanding}

\paragraph{Object.}
A formal islanding capability semantics: a topology control (binary) that is admissible only when
$\mathcal{I}_{\mathrm{island}}=1$ and when governance constraints permit. In island mode, the campus can set $P_{\mathrm{grid}}(t)=0$
and guarantee energy to critical radiological sensing while the grid is unstable.\footnote{Crucially, islanding is treated as a topology transition
with constraints (sync windows, minimum duration, black-start assumptions if invoked), rather than as a continuous knob. This prevents “paper resilience.”}

\paragraph{What is delivered.}
A policy-safe partition:
(i) which sensing/control workloads are guaranteed in island mode,
(ii) which workloads are shed first (flex tranche),
and (iii) what telemetry leaves the island (data-plane) under $\pi_{\mathrm{lic/cyber}}$.

\newpage

% =========================================================
% 8. Limitations and Next Data Hooks
% =========================================================
\section{Limitations and Next Data Hooks}
\label{sec:limitations_hooks}

This paper is an interface and regime map; it does not assert empirical regime boundaries without site- and market-specific calibration.
Accordingly, limitations are stated as \emph{identifiability limits} and \emph{external-validity limits}, and the ``next hooks'' are stated
as the minimal data required to close each limitation.

% ---------------------------------------------------------
\subsection{Model limitations (what is not identified by construction)}
\label{subsec:limitations_model}

\begin{itemize}
  \item \textbf{Tail definition risk.} The scarcity proxy $W_t$ and tail quantiles $\{q_s\}$ are modeling choices; different proxies can shift which hours are labeled
  tail events and therefore shift estimated $\Gamma_{s,q_s}(\pi)$.\footnote{The discipline is: declare $W_t$, declare $q_s$ by season, report sensitivity.
  The interface is stable; the empirical classification must be justified for the jurisdiction.}

  \item \textbf{First-order adequacy linearization.} MRV insertion uses a first-order approximation linking incremental withdrawals to $\Delta\EUE$.
  In highly non-linear scarcity regimes (e.g., near hard adequacy cliffs), higher-order terms may matter.\footnote{This is why MRV is treated as an oracle
  from an adequacy simulator whenever possible; the linearization is an explanation layer and a computational accelerator, not a metaphysical claim.}

  \item \textbf{Deliverability operator availability.} Full constraint geometry $(H_t,\bar f_t)$ and/or multipliers $\nu_t$ may not be observable to the campus
  (and may be proprietary to the ISO/TO). When unavailable, one must use proxy projections $D_\ell(t)$ or coarse constraint classifications.\footnote{The interface remains valid;
  uncertainty increases and must be carried explicitly in Monte Carlo as a wider prior over $\omega_{\ell,t}$ (or $D_\ell(t)$).}

  \item \textbf{Stiffness identification requires excitation.} Without designed curtailment variation under comparable regimes, $\kappa_{\mathrm{stiff}}$ cannot be
  learned; it must be bounded via policy, safety constraints, or conservative priors.\footnote{Put bluntly: if you never curtail, you cannot empirically learn the curtailment cost.
  The interface forces this honesty by separating Tier-1 vs Tier-2 identifiability.}

  \item \textbf{Oracle fidelity and verification scope.} Any DeepONet/virtual-sensing oracle is a surrogate; its validity is constrained by training distribution,
  sensor calibration, and latency assumptions. Formal verification proves logic properties of the kernel, not truth of the physics model.\footnote{Verification answers:
  “If the oracle and sensors are correct, does the dispatch logic ever authorize an unsafe sprint?” It does not answer: “Is the oracle always correct?”}
\end{itemize}

% ---------------------------------------------------------
\subsection{Institutional and regulatory limitations (admissibility is not optional)}
\label{subsec:limitations_institutional}

\begin{itemize}
  \item \textbf{Governance constraints can dominate economics.} $\pi_{\mathrm{lic/cyber}}$ may forbid certain controls even if they are economically optimal.
  The interface treats this as a hard restriction on $\Pi_{\mathrm{adm}}$, not as a soft preference.\footnote{This is the right failure mode: infeasible policies do not appear
  in the solution set.}

  \item \textbf{Tariff/program rules are jurisdiction-specific.} The mapping $\pi_{\mathrm{tariff}}$ must be instantiated for the ISO/utility program (baseline rules,
  call triggers, penalty asymmetry). Mis-specification can invert the sign of value.\footnote{This is exactly why Section~3 binds tariffs to admissible controls:
  the optimization must solve the contract actually offered, not the one the modeler wishes existed.}

  \item \textbf{Confidentiality and auditability tension.} Some workloads (e.g., security) cannot expose fine telemetry; however, settlement requires M\&V.
  The interface supports aggregate-envelope verification, but the chosen M\&V primitive must be agreed ex ante.\footnote{This is where cryptographic commitments or
  enclave attestation can enter as a governance layer, but that is outside the scope of the core valuation interface.}
\end{itemize}

% ---------------------------------------------------------
\subsection{Next data hooks (minimal set to close the above uncertainties)}
\label{subsec:next_data_hooks}

The decisive next inputs are organized by which uncertainty they collapse:

\paragraph{Hook 1: Workload tranche taxonomy and switching penalties.}
Empirical tranche proportions and measured $C_{\mathrm{switch}}$ distributions by workload class (HIPMoS, sensing, training, post-processing),
including designed excitation traces sufficient to identify $\kappa_{\mathrm{stiff}}$ under regime conditioning.\footnote{The non-negotiable element is excitation:
at least a small controlled curtailment experiment under a stable regime so stiffness is not purely asserted.}

\paragraph{Hook 2: Scarcity season labeling and MRV oracle.}
Seasonal scarcity-hour frequency and a jurisdiction-appropriate MRV/eMRV oracle (planning simulator outputs or finite-difference study access),
including the chosen proxy $W_t$ and quantile set $\{q_s\}$.

\paragraph{Hook 3: Queue and survival weights.}
Queue-delay distributions and energization survival weights $S(t)$ for candidate delivery paths (including milestone censoring and restudy risk).

\paragraph{Hook 4: Interface geometry or proxy projections.}
Either (i) access to binding interface/thermal constraints (PTDF/interface model and/or multipliers $\nu_t$), or (ii) a defensible proxy $D_\ell(t)$
with uncertainty bounds wide enough to cover plausible constraint-set variation.

\paragraph{Hook 5: SMR coupling feasibility priors.}
Availability process parameters (forced outage + maintenance windows), minimum generation $u_{\mathrm{SMR}}^{\min}$, ramp bounds $r_{\mathrm{SMR}}$,
islanding feasibility $\mathcal{I}_{\mathrm{island}}$ (and transition constraints), heat rejection envelope $Q_{\mathrm{rej}}^{\max}$ and its seasonal dependence,
and governance admissibility constraints $\pi_{\mathrm{lic/cyber}}$.

\paragraph{Minimal validation experiment (synthetic-to-site ladder).}
A minimal validation ladder can be executed before full site integration:
(i) synthetic workload traces sweeping $(\kappa_{\mathrm{stiff}},\sigma,\tau)$ under multiple $\SMRVec$ configurations,
(ii) Monte Carlo propagation over $(\RubinVec,\GridVec,\SMRVec)$ primitives with declared priors,
and (iii) evaluation of the sign and magnitude of $(\Delta C_{\mathrm{Int}},\Delta C_{\mathrm{Rel}})$ relative to a grid-only baseline,
with explicit reporting of tail amplification $\Gamma_{s,q_s}(\pi)$ and the MRV-weighted penalty contribution.\footnote{The ladder is designed to prevent
a common research failure: jumping from a compelling interface to unearned empirical boundary claims. The interface is usable immediately; the regime map becomes
empirical only after these hooks are populated.}

% =========================================================
% Human–AI Collaboration Acknowledgment + Code/Materials Link
% =========================================================
\section*{Human--AI Collaboration and Materials}
\label{sec:human_ai_ack}

This manuscript is the product of a human--AI research collaboration. The human author (Justin Candler) set the conceptual frame,
defined the valuation objective and planner-interface requirements, selected the modeling primitives, and directed the iterative
refinement of assumptions, definitions, and proofs. The AI system served as a technical research assistant: it helped synthesize
author-provided sources into formal derivations, generated candidate LaTeX formulations, and supported consistency checking across
definitions, symbols, and cross-references. All substantive modeling choices, scope constraints, and final interpretations were
reviewed and approved by the author.

For readers who want the broader reliability/economic scaffolding and related workstreams, supplementary materials and ongoing
development notes are maintained in the author's UEVF repository on GitHub:
\begin{center}
\href{https://github.com/Nousentllc}{\texttt{github.com/Nousentllc}}
\end{center}


\newpage
\appendix

% =========================================================
% Appendix A: Notation, Domains, Units, Random vs Control
% =========================================================
\section{Notation and Units}
\label{app:notation}

This appendix defines every symbol used by the interface, including (i) domain, (ii) units, and (iii) whether the quantity is a control decision, exogenous input, or random variable under scenario uncertainty.\footnote{A recurring failure mode in ``compute + grid'' manuscripts is unit ambiguity and hidden stochasticity. This appendix is the guardrail that makes later Monte Carlo, robust optimization, and empirical calibration possible without rewriting the theory.}

\subsection{Index sets, probability space, and time}
Let $t\in\{0,1,\dots,H\}$ index discrete time periods (hours, days, or representative slices). Let $(\Omega,\mathcal{F},\mathbb{P})$ be the probability space capturing uncertainty in queue outcomes, scarcity processes, outage realizations, tariff regimes, and technology survival.\footnote{If you later adopt a deterministic planning model, interpret $\Omega$ as a singleton; all expectations reduce to identity. The stochastic form is strictly more general and is required for defensible regime probability claims.}

\subsection{Core variables and derived quantities}

\begin{longtable}{@{}p{0.22\linewidth}p{0.18\linewidth}p{0.12\linewidth}p{0.12\linewidth}p{0.30\linewidth}@{}}
\toprule
\textbf{Symbol} & \textbf{Name} & \textbf{Domain} & \textbf{Units} & \textbf{Type / Interpretation} \\
\midrule
\endhead

$P_{\text{campus}}(t)$ & Campus real power & $\mathbb{R}_{\ge 0}$ & MW & State variable induced by controls; includes stiff and flexible tranches. \\
$P_s, P_f$ & Tranche nameplates & $\mathbb{R}_{>0}$ & MW & Design parameters (can be decision variables in sizing variants). \\
$u_s(t),u_f(t)$ & Utilization controls & $[0,1]$ & -- & Control variables (dispatch/curtailment). \\
$E_{\text{fac}}(t)$ & Facility energy & $\mathbb{R}_{\ge 0}$ & MWh & Fully-loaded energy (IT + parasitics). \\
$T_g(t,\omega)$ & Goodput & $\mathbb{R}_{\ge 0}$ & tokens & Scenario-dependent delivered useful tokens. \\
$\eta_{\text{sys}}(t)$ & System efficiency & $\mathbb{R}_{\ge 0}$ & tokens/J & Tokens per facility joule; planner-relevant efficiency. \\
$\delta$ & Discount factor & $(0,1]$ & -- & Time value of money (or planner discount). \\
$S(t,\omega)$ & Survival weight & $[0,1]$ & -- & Energization/availability/survival probability weight. \\
$t_{\text{queue}}$ & Effective queue lead time & $\mathbb{R}_{\ge 0}$ & years & Includes studies, upgrades, construction, commissioning. \\
$t_{\text{silicon}}$ & Effective silicon economic life & $\mathbb{R}_{>0}$ & years & Depreciation/obsolescence horizon for installed compute generation. \\
$\tau$ & Intertemporal mismatch & $\mathbb{R}_{\ge 0}$ & -- & $\tau:=t_{\text{queue}}/t_{\text{silicon}}$; stranded-asset risk statistic. \\
$\VOLL(t)$ & Value of Lost Load & $\mathbb{R}_{>0}$ & \$/MWh & Institutional reliability valuation lever.\footnote{Different institutions embed this value via different instruments: scarcity pricing, capacity charges, or procurement rules. The interface requires an explicit mapping, not a universal constant.} \\
$\Delta\EUE(t,\omega)$ & Incremental expected unserved energy & $\mathbb{R}$ & MWh & Reliability externality induced by the campus relative to baseline. \\
$C_{\mathrm{Res}}(t,\omega)$ & Resource cost & $\mathbb{R}_{\ge 0}$ & \$ & Campus capex/opex + energy procurement. \\
$C_{\mathrm{Int}}(t,\omega)$ & Integration cost & $\mathbb{R}_{\ge 0}$ & \$ & Interconnection, upgrades, deliverability constraints, peak-driven reinforcement. \\
$C_{\mathrm{Rel}}(t,\omega)$ & Reliability cost & $\mathbb{R}$ & \$ & Typically $\VOLL\cdot\Delta\EUE$; may be negative if net system benefit. \\
$C_{\text{switch}}(t,\omega)$ & Switching penalty & $\mathbb{R}_{\ge 0}$ & \$ & Checkpointing/restart, SLA degradation, quality loss, coordination cost. \\
$\kappa_{\text{stiff}}(t,\omega)$ & Stiffness ratio & $\mathbb{R}_{\ge 0}$ & -- & $\kappa_{\text{stiff}}:=\dfrac{C_{\text{switch}}}{\VOLL \cdot P \cdot \Delta t}$; economic feasibility of curtailment. \\
$\sigma$ & Sprint factor & $\mathbb{R}_{\ge 1}$ & -- & Temporal densification: max intensity relative to mean.\footnote{The underlying engineering drivers resemble roofline-like bottlenecks where memory and interconnect constraints govern achievable throughput at given power, but the planner-level point is temporal behavior and peak coincidence, not FLOPs/W.} \\
$\epsilon$ & Rebound elasticity & $\mathbb{R}_{\ge 0}$ & -- & Jevons-style rebound: demand expansion from lower cost/token. \\
$D$ & Deliverability factor & $[0,1]$ & -- & Effective deliverable import/export feasibility; congestion/thermal/voltage constraints. \\
$\pi_{\text{tariff}}$ & Tariff rule vector & -- & -- & Encodes compensation/penalty structure for curtailment and export/import rules. \\
\bottomrule
\end{longtable}

\subsection{SMR coupling variables}
\begin{longtable}{@{}p{0.22\linewidth}p{0.18\linewidth}p{0.12\linewidth}p{0.12\linewidth}p{0.30\linewidth}@{}}
\toprule
\textbf{Symbol} & \textbf{Name} & \textbf{Domain} & \textbf{Units} & \textbf{Type / Interpretation} \\
\midrule
\endhead

$P_{\text{SMR}}$ & SMR capacity & $\mathbb{R}_{>0}$ & MW & Electrical output capacity available to campus boundary. \\
$a_{\text{SMR}}(\omega)$ & Availability process & $[0,1]$ & -- & Forced outage / maintenance schedule; scenario-dependent. \\
$u^{\min}_{\text{SMR}}$ & Minimum stable generation & $[0,1]$ & -- & Must-run fraction; can force output through scarcity windows. \\
$r_{\text{SMR}}$ & Ramp constraint & $\mathbb{R}_{\ge 0}$ & MW/h & Limits dispatch flexibility (if dispatchable). \\
$\mathcal{I}_{\text{island}}$ & Islanding indicator & $\{0,1\}$ & -- & Whether campus can island as microgrid boundary.\footnote{If $\mathcal{I}_{\text{island}}=0$, the ``SMR as timing fix'' case weakens.} \\
$Q^{\max}_{\text{heat}}$ & Heat rejection constraint & $\mathbb{R}_{>0}$ & MW$_\text{th}$ & Cooling boundary; couples to ambient and water rights constraints. \\
$\pi_{\text{license/cyber}}$ & Governance feasibility & -- & -- & Constraints on automation, segmentation, update procedures in regulated environments. \\
\bottomrule
\end{longtable}

\subsection{Adversarial Checking: The Zero-Trust Breach Scenario}
To satisfy the "Research Partnership" verification standards, we subject the KKT procurement model to a \textit{Cyber-Physical Adversarial Test}.

\begin{enumerate}
    \item \textbf{Scenario (Signal Spoofing):} An attacker compromises the Layer 1 dynamic price signal $\pi_t$, artificially suppressing it during a grid scarcity event to prevent autonomous curtailment.
    \item \textbf{Reliability Response:} We verify that the Layer 2 \textit{Reliability Signal} $\delta_t$ (driven by physical EUE thresholds) overrides economic signals, triggering a mandatory "Stiff Tranche" preservation sequence.
    \item \textbf{Verification Metric:} We calculate the \textit{Breach Recovery ASCDE}:
    \begin{equation}
    \ASCDE^{\text{breach}} = \dfrac{C_{\text{Res}} + C_{\text{Int}} + \VOLL \cdot \Delta\EUE^{\text{spoofed}}}{\sum \text{Reliable MWh}}
    \end{equation}
    The architecture is deemed resilient if $\ASCDE^{\text{breach}} \le \ASCDE^{\text{baseline}} \cdot 1.15$ under a 4-hour recovery window.
\end{enumerate}

\subsection{The UEVF Uncertainty Ledger (Iteration v2.2)}
We explicitly track aleatory and epistemic uncertainties that impact the ASCDE valuation.

\begin{longtable}{p{0.25\linewidth} p{0.20\linewidth} p{0.45\linewidth}}
\toprule
\textbf{Uncertainty Factor} & \textbf{UEVF Class} & \textbf{Mitigation / Mapping} \\
\midrule
AI-Powered Malware & Epistemic & Implement Bhowmik’s Zero-Trust AI-NPP framework; de-rate $S(t,\omega)$ based on cyber-risk scoring. \\
SMR Licensing Lag & Epistemic & Monitor the $\tau$ statistic ($\tau := t_{\text{queue}}/t_{\text{silicon}}$); de-rate capacity if $\tau > 2.0$. \\
Dunkelflaute Duration & Aleatory & Apply "Winter Wall" Importance Sampling (Section 7.6) to stress test duration wall $D(t)$. \\
VOLL Volatility & Epistemic & Periodically recalibrate $\VOLL(t)$ based on "Goodput" $T_g$ value shifts in the campus. \\
\bottomrule
\end{longtable}

\subsection{Refined SMR Coupling: Thermal-Hydraulic Feedback}
\begin{longtable}{@{}p{0.22\linewidth}p{0.18\linewidth}p{0.12\linewidth}p{0.12\linewidth}p{0.30\linewidth}@{}}
\toprule
\textbf{Symbol} & \textbf{Name} & \textbf{Domain} & \textbf{Units} & \textbf{Type / Interpretation} \\
\midrule
\endhead

$Q_{\text{core}}(\omega)$ & Core thermal power & $\mathbb{R}_{>0}$ & MW$_\text{th}$ & Primary heat source; coupled to $P_{\text{SMR}}$ via $\eta_{\text{carnot}}$. \\
$\Delta T_{\text{loop}}$ & Loop differential & $\mathbb{R}_{\ge 0}$ & K & Governs ramp constraint $r_{\text{SMR}}$ via material stress limits. \\
$\pi_{\text{cyber-ZT}}$ & Zero-Trust Score & $[0,1]$ & -- & Quantitative measure of cyber-posture compliance; affects $S(t,\omega)$. \\
\bottomrule
\end{longtable}

\newpage

% =========================================================
% Appendix B: Reliability Externality Mapping Options
% =========================================================
\section{Reliability Mapping Choices for \texorpdfstring{$C_{\mathrm{Rel}}$}{C\_Rel}}
\label{app:reliability-mapping}

This appendix enumerates admissible mappings from campus net load to reliability externality. The paper is market-design agnostic, but \emph{not} mapping-agnostic: the chosen mapping determines identifiability and what ``reliability-complete'' means in practice.\footnote{You can treat this appendix as the ``adapter layer'' between the interface and a specific ISO/utility planning stack. It is also where reviewers will attack you if you are vague.}

\subsection{EUE/VOLL functional (canonical welfare mapping)}
Define incremental expected unserved energy induced by campus:
\begin{equation}
\Delta\EUE(t,\omega) := \EUE_{\text{with campus}}(t,\omega)-\EUE_{\text{baseline}}(t,\omega).
\end{equation}
Then
\begin{equation}
C_{\mathrm{Rel}}(t,\omega) := \VOLL(t)\cdot \Delta\EUE(t,\omega).
\end{equation}
This mapping is policy-transparent and supports negative $C_{\mathrm{Rel}}$ when flexible load curtails during scarcity.\footnote{Negative $C_{\mathrm{Rel}}$ is not ``free money.'' It is a statement that the campus control policy reduces expected unserved energy relative to baseline during scarcity hours, net of switching costs.}

\subsection{Scarcity price proxy (market-observable approximation)}
If a region has scarcity pricing (or an observable high-price tail), define a scarcity shadow price process $\lambda_{\text{scarcity}}(t,\omega)$ and map reliability cost to campus net load during scarcity:
\begin{equation}
C_{\mathrm{Rel}}(t,\omega) \approx \lambda_{\text{scarcity}}(t,\omega)\cdot P_{\text{campus}}(t,\omega)\cdot \Delta t,
\end{equation}
optionally adjusted by a deliverability factor $D$ and/or by a coincidence weight that emphasizes top-$N$ scarcity hours.\footnote{This is an approximation: it assumes scarcity prices are an adequate proxy for marginal reliability value. Use when EUE outputs are unavailable but market data exist.}

\subsection{ELCC-style reduced form (capacity accreditation mapping)}
Define an effective load carrying capability mapping for controllable load:
\begin{equation}
\ELCC_{\text{campus}} := \Psi\!\left(\text{curtailment policy},\; \kappa_{\text{stiff}},\; \sigma,\; \lambda_{\text{scarcity}},\; D\right),
\end{equation}
and represent reliability value via capacity-equivalent charges or credits:
\begin{equation}
C_{\mathrm{Rel}}(t,\omega) \approx \pi_{\text{cap}}(t)\cdot \left(P_{\text{uncurt}} - \ELCC_{\text{campus}}\right),
\end{equation}
where $\pi_{\text{cap}}$ is a capacity price or planning reserve monetization.\footnote{This is convenient when the institution already thinks in ``accredited MW'' terms. The conceptual integrity requirement is that $\Psi(\cdot)$ must be explicitly tied to scarcity coincidence and curtailment feasibility, not assumed.}

\subsection{Selection guidance and reviewer-proofing}
\begin{itemize}
  \item Use B1 when you can access adequacy outputs or planning models (best theoretical clarity).
  \item Use B2 when you have high-quality price tail data and want an empirical proxy.
  \item Use B3 when you must integrate with accreditation/capacity constructs.
\end{itemize}
The manuscript should state which mapping is used in any empirical section, and treat others as robustness checks.\footnote{A dissertation-grade standard is: show at least two mappings and report whether your regime classification is stable. If results flip, that is not a failure; it is an identified sensitivity.}

\newpage

% =========================================================
% Appendix C: Optimization Forms (Stochastic, Robust, and Bilevel)
% =========================================================
\section{Optimization Forms and Equivalence Classes}
\label{app:optimization}

This appendix makes the optimization problem explicit in forms that map to real planning toolchains: (i) stochastic program for Monte Carlo, (ii) robust counterpart for worst-case $\tau$ and scarcity, and (iii) bilevel formulation when tariffs or governance rules act as constraints rather than prices.

\subsection{Stochastic control + sizing (single-level)}
Let decision variables include sizing $(P_s,P_f)$ and control policies $\{u_s(t,\omega),u_f(t,\omega)\}_{t,\omega}$. A canonical formulation is:
\begin{align}
\min_{P_s,P_f,u_s,u_f} \quad & \ASCDE_{AI} \\
\text{s.t.}\quad
& P_{\text{campus}}(t,\omega)=P_s u_s(t,\omega)+P_f u_f(t,\omega), \\
& P_{\text{campus}}(t,\omega)\le P_{\text{SMR}}(t,\omega)+P_{\text{grid}}(t,\omega), \\
& P_{\text{SMR}}(t,\omega)\in[u^{\min}_{\text{SMR}}P_{\text{SMR}},\,P_{\text{SMR}}], \quad \dot{P}_{\text{SMR}}(t,\omega)\le r_{\text{SMR}}, \\
& u_s(t,\omega)\ge \underline{u}_s(\kappa_{\text{stiff},s}), \\
& u_f(t,\omega)\in\mathcal{U}_f\!\left(\mathcal{S}(t,\omega),\kappa_{\text{stiff},f},\pi_{\text{tariff}}\right), \\
& P_{\text{grid}}(t,\omega)\in \mathcal{P}_{\text{grid}}(t;\,D,\pi_{\text{tariff}}), \\
& T_g(t,\omega)=\Phi\!\left(\text{tokens}(t,\omega),\text{quality}(t,\omega),\text{SLA}(t,\omega)\right).
\end{align}
Here $\mathcal{U}_f(\cdot)$ encodes contractual curtailment rules and penalty structure.\footnote{A practical approach: define $\mathcal{U}_f$ as a soft constraint via penalty term $C_{\text{switch}}$ and a hard constraint only during declared scarcity hours. This is often how real demand response contracts behave.}

\subsection{Robust counterpart (worst-case mismatch and scarcity)}
If planners need worst-case guarantees, define an uncertainty set $\mathcal{W}$ for $(\tau,\lambda_{\text{scarcity}},a_{\text{SMR}})$ and optimize:
\begin{equation}
\min_{P_s,P_f,\pi} \; \max_{\omega\in\mathcal{W}} \ASCDE_{AI}(\omega),
\end{equation}
where $\pi$ denotes policy/control parameters (e.g., curtailment thresholds) rather than scenario-by-scenario decisions.\footnote{This is appropriate when governance constraints restrict adaptive control, or when regulatory commitments require robustness to queue delays and outage schedules.}

\subsection{Bilevel: tariffs and governance as constraints}
In regulated contexts, $\pi_{\text{tariff}}$ and $\pi_{\text{license/cyber}}$ may not be continuous prices; they may be feasibility constraints determined externally. Represent this as a bilevel form:
\begin{align}
\min_{\text{campus decisions}} \quad & \ASCDE_{AI} \\
\text{s.t.}\quad & \text{campus feasibility constraints}, \\
& \pi_{\text{tariff}},\pi_{\text{license/cyber}}\in\arg\min_{\text{institution}} \;\; \mathcal{L}(\text{system risk},\text{compliance},\text{rate impacts}),
\end{align}
where the lower-level objective $\mathcal{L}$ captures institutional objectives. This makes the value hinge explicit: your result depends on which institutional priorities are binding.\footnote{This is often the only honest way to represent regulated ``no export,'' segmentation, or manual-override requirements: they are not prices, they are hard constraints.}

\begin{proof}
Let the auxiliary function be $F(\lambda) = \min_{\GridVec \in \Omega} \{ C_{\text{sys}}(\GridVec) - \lambda \cdot T_g(\GridVec) \}$.
\begin{enumerate}
    \item \textbf{Convexity:} $F(\lambda)$ is the pointwise minimum of affine functions in $\lambda$, ensuring concavity and a unique root.
    \item \textbf{Update Step:} The Newton update $\lambda_{k+1} = \frac{C_{\text{sys}}(\GridVec_k)}{T_g(\GridVec_k)}$ corresponds to selecting the specific grid-state $\GridVec_k$ that minimizes the auxiliary cost at the current price estimate.
    \item \textbf{Convergence:} Since $T_g > 0$ for all operational states (assuming HIPMoS ``Always-On'' constraints), the sequence $\lambda_k$ converges superlinearly to the optimal $\ASCDE^*$.
\end{enumerate}
\end{proof}

\newpage

% =========================================================
% Appendix D: Control Theoretic Stability Proofs
% =========================================================
\section{Lyapunov Stability of the SMR-AI Loop}
\label{app:stability}

We prove that the DeepONet-augmented control law defined in Section 6.3 guarantees asymptotic stability of the reactor core temperature $T_c$, even under aggressive AI sprint dynamics.

\subsection{System Dynamics}
Let $x = [T_c, T_{coolant}]^T$ be the state vector. The coupled dynamics are:
\begin{equation}
    \dot{x} = A x + B u + D P_{\text{AI}}(t)
\end{equation}
Where $P_{\text{AI}}(t)$ is the stochastic compute load acting as a disturbance. The DeepONet controller applies a feedback $u = -K_{DO}(x) \cdot x$.

\subsection{Lyapunov Candidate}
We propose a quadratic Lyapunov function representing the system's total thermal energy deviation:
\begin{equation}
    V(x) = x^T P x, \quad P = P^T > 0
\end{equation}



\subsection{Stability Proof}
\begin{proof}
Differentiation along the system trajectory yields:
\begin{equation}
    \dot{V}(x) = \dot{x}^T P x + x^T P \dot{x}
\end{equation}
Substituting the control law $u = -K_{DO}(x)x$:
\begin{equation}
    \dot{V}(x) = x^T (A^T P + P A - 2 P B K_{DO}(x)) x + 2 x^T P D P_{\text{AI}}
\end{equation}
By the \textit{Sprint-Lag Inequality} (Section 6.3), the DeepONet ensures that $P_{\text{AI}}$ is bounded such that the dissipation term dominates the disturbance:
\begin{equation}
    \lambda_{\min}(Q) \|x\|^2 > 2 \|x\| \|P D\| P_{\text{AI}}^{\max}
\end{equation}
Where $Q = -(A^T P + P A - 2 P B K_{DO})$. Since $\dot{V}(x) < 0$ for all $\|x\| > \delta$, the system is Input-to-State Stable (ISS) with region of attraction $\Omega$ defined by the SMR's scram setpoints.\footnote{This implies that even if the AI model enters a runaway hallucination loop (divergent $P_{\text{AI}}$), the DeepONet cut-out will force the system back to the thermal equilibrium manifold before the reactor safety logic trips.}
\end{proof}\textbf{}


\newpage

% =========================================================
% Appendix E: Identification and Calibration (Telemetry + Queue Data)
% =========================================================
\section{Identification Strategy and Calibration Plan}
\label{app:identification}

This appendix specifies how to estimate key interface parameters from measurable data streams. The goal is not to claim calibrated values in the framework paper; it is to show the model is empirically falsifiable and the parameters are identifiable in principle.\footnote{Reviewers will ask: ``How do you measure stiffness?'' ``How do you measure sprint?'' ``How do you know $\tau$ isn't hand-wavy?'' This appendix is the answer.}

\subsection{Measuring \texorpdfstring{$\tau$}{tau} (queue vs silicon life)}
\paragraph{Queue time $t_{\text{queue}}$.}
Define $t_{\text{queue}}$ as the random time from application/commitment to energization at required capacity. Empirically, this is observable as a distribution from (i) interconnection study dates, (ii) upgrade in-service dates, (iii) commissioning dates.\footnote{Where public queue datasets exist, they can provide priors for $t_{\text{queue}}$ by region/technology. LBNL's \emph{Queued Up} series is a canonical summary source \citep{lbnl2024queuedup}.}

\paragraph{Silicon life $t_{\text{silicon}}$.}
Define $t_{\text{silicon}}$ as the effective economic life under depreciation/obsolescence. This is measurable from internal depreciation schedules, replacement cadence, and performance-per-dollar trajectories. The interface requires only that $t_{\text{silicon}}$ be stated and sensitivity-tested (e.g., 18--36 months).

\subsection{Measuring sprint factor \textit{Sigma} from power telemetry}
Given high-resolution campus power telemetry, define intensity series
\(
I(t)=P_{\text{campus}}(t)/\overline{P}_{\text{campus}}
\)
and estimate:
\begin{equation}
\hat{\sigma} := \frac{\max_t I(t)}{\frac{1}{H}\sum_{t} I(t)}.
\end{equation}
Alternative robust measures include top-$p$ quantile intensity ratio (e.g., $q_{0.99}(I)/\mathbb{E}[I]$) to reduce sensitivity to single spikes.\footnote{In practice, ``sprint'' is operationally constrained by memory/interconnect bottlenecks. Roofline-style reasoning explains why achieved throughput saturates under memory bandwidth constraints \citep{williams2009roofline}; the planner-level move is to treat the resulting temporal shape as the decision-relevant object.}

\subsection{Measuring stiffness via interruption experiments (estimating \texorpdfstring{$C_{\text{switch}}$}{C\_switch})}

\paragraph{Definition.}
Stiffness hinges on the marginal penalty of interruption. Empirically estimate $C_{\text{switch}}$ by controlled curtailment experiments:
\begin{itemize}
  \item Induce a planned curtailment of a workload class for duration $\Delta t$.
  \item Measure restart time, checkpoint overhead, quality degradation, SLA penalties, and lost opportunity cost.
  \item Monetize into \$ using internal revenue proxy or contract penalty schedule.
\end{itemize}
Then compute
\begin{equation}
\hat{\kappa}_{\text{stiff}} = \frac{\hat{C}_{\text{switch}}}{\VOLL\cdot P\cdot \Delta t}.
\end{equation}
If $\hat{\kappa}_{\text{stiff}}\ll 1$ for a class, it is economically curtailable under scarcity pricing; if $\gg 1$, treat it as stiff.

\paragraph{Why this is regime-critical.}
This ratio is the mechanical hinge separating Regime A (stress reduction) from Regime C (sprint coincidence). It is also auditable and contractable: you can attach a measured $\hat{\kappa}$ distribution to a curtailment contract.

\subsection{Measuring rebound elasticity \texorpdfstring{$\epsilon$}{epsilon}}

Rebound can be estimated by observing how delivered tokens respond to marginal cost-per-token reductions (e.g., via efficiency improvements or contract price changes). A reduced-form log-log model is:
\begin{equation}
\log T_g = \alpha - \epsilon \log c_{\text{token}} + \text{controls} + \varepsilon,
\end{equation}
where $c_{\text{token}}$ is realized cost per delivered token and controls include demand-side drivers.\footnote{Rebound is debated and context-dependent; the goal is not to declare a single number but to justify why it belongs as a sensitivity lever \citep{sorrell2009jevons}.}

\subsection{INL anchoring: why HIPMoS and sensing calibrate tranche taxonomy}
HIPMoS-style always-on cyber detection is inherently stiff due to operational security and compliance requirements \citep{talukder2023zerotrustnpp}. Radiological sensing tasks can be stiff in safety-monitoring mode and flexible in batch investigation mode \citep{galib2021nai_ml_radioisotopes}. These provide anchored examples where ``flexibility'' is not assumed but argued from operational necessity.

\newpage

% ---------------------------------------------------------
% =========================================================
% APPENDICES (Formal back-end for Rubin/Grid/SMR vectors)
% =========================================================

% ---------------------------------------------------------
\section{Rubin Vector: sufficient-statistic reduction, bottleneck bounds, \& identifiability}
\label{app:rubin_vector}

This appendix formalizes why the Rubin vector is a planner-sufficient compression of a high-dimensional compute stack. The core claim is a \emph{sufficient-statistic / invariance-class} statement: once the Rubin primitives are fixed (together with exogenous grid and coupling boundary vectors), all remaining micro-detail lies in an objective-indifference class for Compute-ASCDE.

\subsection{Model and objective invariance classes}

Let $\Theta$ be the full parameter space describing micro-architecture, facility parasitics, workload composition, and control logic. Let $(\Omega,\mathcal{F},\mathbb{P})$ encode scarcity regimes, outages, queue milestones, and measurement noise. The induced stochastic outputs are generated by
\[
\mathcal{M}_\Theta:\ \theta \mapsto \big\{P_{\mathrm{campus}}(t,\omega),\ T_g(t,\omega),\ C_{\mathrm{Res}}(t,\omega),\ C_{\mathrm{Int}}(t,\omega),\ \Delta\EUE(t,\omega)\big\}_{t=0}^{H}.
\]
A planner interface is a measurable map $g:\Theta\to\mathbb{R}^d$ defining
\[
X := g(\theta) = \big(\RubinVec,\ \GridVec,\ \SMRVec\big),
\]
such that the planning objective is invariant under changes in $\theta$ that preserve $X$:
\[
\ASCDE_{AI}(\theta)=\ASCDE_{AI}(g(\theta)).
\]

\begin{definition}[Objective invariance class]\label{def:ascde_equiv}
Define an equivalence relation $\sim_{\ASCDE}$ on $\Theta$ by
\[
\theta_1 \sim_{\ASCDE} \theta_2
\quad \Longleftrightarrow \quad
\ASCDE_{AI}(\theta_1)=\ASCDE_{AI}(\theta_2)
\]
under the same institutional rules, discounting, and baseline conventions. Each equivalence class is an objective-indifference set for the planner.
\end{definition}

\subsection{Rubin primitives and the “API” claim}

Define the Rubin vector (endogenous primitives) as
\[
\RubinVec_{t} := \Big\{\delta_{\mathrm{sys},t},\ \kappa_{\mathrm{stiff},t},\ \sigma_{t},\ \mu_{\mathrm{mem},t},\ \kappa_{\mathrm{net},t}\Big\}.
\]

\begin{assumption}[Tail-dominance and peak-sizing regularity]\label{assump:tail_peak}
Assume:
\begin{enumerate}[label=(A\arabic*)]
\item \textbf{Goodput separability:} $T_g(t,\omega)=\Psi\!\big(\eta_{\mathrm{sys}}(t,\omega),u(t,\omega)\big)$ where $u$ is the tranche policy and $\eta_{\mathrm{sys}}$ is tokens per facility joule.
\item \textbf{Peak-sized integration:} $C_{\mathrm{Int}}$ is governed by upper-tail statistics of the campus/grid-facing withdrawal (reinforcement and deliverability bind at peaks).
\item \textbf{Tail-dominant adequacy:} $\Delta\EUE$ is dominated by scarcity-tail events and depends primarily on conditional coincidence of grid-facing withdrawal with scarcity states.
\end{enumerate}
\end{assumption}

\begin{proposition}[Planner-sufficient Rubin primitives]\label{prop:rubin_sufficient}
Under Assumption~\ref{assump:tail_peak}, there exists a finite-dimensional Rubin representation such that for any $\theta_1,\theta_2\in\Theta$:
\[
\RubinVec(\theta_1)=\RubinVec(\theta_2)
\quad\Longrightarrow\quad
\theta_1 \sim_{\ASCDE} \theta_2,
\]
up to objective-irrelevant reparameterizations (i.e., micro-detail that does not move the planner objective once peak-sizing and tail-risk dominance are acknowledged).
\end{proposition}

\begin{proof}[Sketch with explicit channels]
(A1) implies micro-architectural and facility detail enters the objective only through realized efficiency $\eta_{\mathrm{sys}}$ and the control-response surface induced by tranche policy; $\delta_{\mathrm{sys},t}$ indexes regime-relative movement in $\eta_{\mathrm{sys}}$.

(A2) implies integration and upgrade exposure depends primarily on upper-tail behavior of grid-facing withdrawal; this tail is governed by temporal densification ($\sigma_t$) and curtailment feasibility ($\kappa_{\mathrm{stiff},t}$).

(A3) implies $\Delta\EUE$ is determined by conditional behavior in scarcity-tail regimes; that conditional behavior is mediated by stiffness and coincidence statistics, and bounded by bottleneck-induced nonlinearities (restart/rollback/collective stalls). The latter are captured by memory and interconnect primitives $(\mu_{\mathrm{mem},t},\kappa_{\mathrm{net},t})$, which close the objective-relevant bottleneck channel and stabilize estimation.
Thus, fixing the Rubin primitives fixes all endogenous objective-relevant channels, yielding objective invariance. \qedhere
\end{proof}

\subsection{Roofline-consistent bounds for tokens (planner-usable)}

Let $B_{\mathrm{eff}}(t,\omega)$ denote effective bandwidth at the binding memory/interconnect boundary and let $\mathcal{I}(t,\omega)$ denote effective operational intensity. A roofline-style bound for goodput rate is
\[
\dot T_g(t,\omega)\ \le\ \min\Big\{\dot T_{\mathrm{compute}}(t,\omega),\ \mathcal{I}(t,\omega)\,B_{\mathrm{eff}}(t,\omega)\Big\}.
\]
Define planner proxies:
\[
\mu_{\mathrm{mem}}(t) := \frac{\text{achieved throughput}(t)}{\mathcal{I}(t)\,B_{\mathrm{eff}}(t)}\in(0,1],
\qquad
\kappa_{\mathrm{net}}(t) := \frac{T_{\mathrm{comm}}(t)}{T_{\mathrm{step}}(t)}\in[0,1).
\]
These proxies are sufficient to (i) upper-bound realized throughput, and (ii) detect when $\delta_{\mathrm{sys},t}$ estimation is contaminated by memory/collective bottlenecks rather than compute scaling.

\subsection{Identifiability tiers (what is learned vs assumed)}

\paragraph{Tier 1 (direct).}
$\sigma_t$ and $\eta_{\mathrm{sys}}(t)$ (hence $\delta_{\mathrm{sys},t}$) from telemetry; $(\mu_{\mathrm{mem},t},\kappa_{\mathrm{net},t})$ from profiler/collective diagnostics.

\paragraph{Tier 2 (requires excitation).}
$\kappa_{\mathrm{stiff},t}$ requires designed curtailment/throttle variation under known regimes; without excitation, ``inflexible workload'' is observationally equivalent to ``policy never attempted flexibility.''

\paragraph{Tier 3 (structural priors).}
Grid/coupling feasibility objects live in $\GridVec_t$ and $\SMRVec_t$ and are typically estimated via external studies, milestone jumps, or audited program rules.

\subsection{A formal sufficiency theorem (invariance under objective-relevant channels)}

Let $\mathcal{T}_g(\theta)$ denote the induced goodput process and let $\mathcal{C}(\theta)$ denote the full cost/reliability numerator of Compute-ASCDE (resource, integration, and reliability terms). Let $\mathcal{J}(\theta)$ denote the planning objective (ratio form) or equivalently the Dinkelbach auxiliary objective evaluated at its root.

\begin{definition}[Objective-relevant channel factorization]\label{def:channel_factorization}
We say the system admits an objective-relevant factorization if there exist measurable maps
\[
\mathcal{A}:\Theta\to\mathcal{A}\mathrm{-space},\qquad
\mathcal{B}:\Theta\to\mathcal{B}\mathrm{-space},
\]
such that for all $\theta\in\Theta$,
\[
\mathcal{T}_g(\theta)=\mathcal{T}_g\big(\mathcal{A}(\theta)\big),
\qquad
\mathcal{C}(\theta)=\mathcal{C}\big(\mathcal{B}(\theta)\big),
\]
and $\mathcal{J}(\theta)$ depends on $\theta$ only through $(\mathcal{A}(\theta),\mathcal{B}(\theta))$.
\end{definition}

\begin{assumption}[Rubin primitives span objective-relevant channels]\label{assump:rubin_spans_channels}
Under Assumption~\ref{assump:tail_peak}, the channel maps can be chosen so that:
\begin{enumerate}[label=(R\arabic*)]
\item $\mathcal{A}(\theta)$ is spanned by $(\delta_{\mathrm{sys}},\mu_{\mathrm{mem}},\kappa_{\mathrm{net}})$ through a regime-conditioned throughput surface.
\item $\mathcal{B}(\theta)$ is spanned by $(\kappa_{\mathrm{stiff}},\sigma)$ through peak/tail statistics of grid-facing withdrawal and induced curtailment response.
\item All remaining coordinates in $\theta$ affect $\mathcal{J}$ only through reparameterizations that leave these primitives unchanged.
\end{enumerate}
\end{assumption}

\begin{theorem}[Planner-sufficient Rubin vector as an invariance-class representative]\label{thm:rubin_sufficiency}
If Assumption~\ref{assump:rubin_spans_channels} holds, then there exists a measurable map
\[
g_R:\Theta\to\mathbb{R}^5,\qquad g_R(\theta)=\RubinVec(\theta),
\]
such that for any $\theta_1,\theta_2\in\Theta$,
\[
\RubinVec(\theta_1)=\RubinVec(\theta_2)\quad\Longrightarrow\quad
\mathcal{J}(\theta_1)=\mathcal{J}(\theta_2),
\]
i.e., $\RubinVec$ indexes the objective invariance classes with respect to endogenous design and policy degrees of freedom.
\end{theorem}

\begin{proof}[Proof sketch (measurability + channel closure)]
By Definition~\ref{def:channel_factorization}, $\mathcal{J}$ factors through $(\mathcal{A},\mathcal{B})$. By Assumption~\ref{assump:rubin_spans_channels}, both $\mathcal{A}$ and $\mathcal{B}$ are measurable functions of $\RubinVec$. Hence $\mathcal{J}$ is a measurable function of $\RubinVec$ alone. Equality of $\RubinVec$ therefore implies equality of $\mathcal{J}$. \qedhere
\end{proof}

\paragraph{A scale-free sprint functional (recommended).}
To avoid dependence on absolute normalization and to improve estimability under noise, define for any regime index set $\mathcal{T}\subseteq\{0,\dots,H\}$:
\[
\sigma(\mathcal{T}) \coloneqq 
\frac{\mathrm{Quantile}_{q_\sigma}\!\left(P_{\mathrm{grid}}(t)\,:\,t\in\mathcal{T}\right)}
{\mathbb{E}\!\left[P_{\mathrm{grid}}(t)\mid t\in\mathcal{T}\right]},
\qquad q_\sigma\in(0,1),
\]
which replaces $\mathrm{ess\,sup}$ with a robust high-quantile estimator.

\subsection{Estimator pathology: regime mixing and identifiability conditions}

\begin{lemma}[Regime mixing biases $\widehat{\eta}_{\mathrm{sys}}$ and hence $\widehat{\delta}_{\mathrm{sys}}$]\label{lem:regime_mixing_bias}
Suppose observed telemetry aggregates multiple latent operational regimes $r\in\mathcal{R}$ with regime indicators $\mathbf{1}\{R_t=r\}$ and regime-specific efficiencies $\eta_{\mathrm{sys}}^{(r)}$. Then the window estimator
\[
\widehat{\eta}_{\mathrm{sys}}(t;W)=
\frac{\sum_{k=t-W+1}^{t} T_g(k)}{\sum_{k=t-W+1}^{t} E_{\mathrm{fac}}(k)}
\]
is a convex mixture of regime efficiencies weighted by energy shares, not a regime-invariant parameter. If the regime composition differs between baseline and comparison windows, $\widehat{\delta}_{\mathrm{sys}}$ conflates efficiency shift with composition shift.
\end{lemma}

\begin{assumption}[Persistent excitation for stiffness identification]\label{assump:persistent_excitation}
There exists an interval set $\mathcal{T}_{\mathrm{exc}}$ and an adequacy-relevant regime set $\mathcal{W}$ such that
\[
\mathrm{Var}\!\left(u_{f,t}\ \middle|\ t\in\mathcal{T}_{\mathrm{exc}},\ W_t\in \mathcal{W}\right) > 0.
\]
\end{assumption}

\begin{proposition}[Identifiability of $\kappa_{\mathrm{stiff}}$ up to an internal value prior]\label{prop:kappa_identifiability}
Assume (i) the tranche response model links observed $(u_{f,t},T_g(t))$ to an empirically recoverable switching-loss statistic $\Delta T_g(t)$, (ii) Assumption~\ref{assump:persistent_excitation} holds, and (iii) $\VOLL(t)$ and $P_s$ are fixed by policy/contract. Then
\[
\kappa_{\mathrm{stiff}}(t)=\frac{C_{\mathrm{switch}}(t)}{\VOLL(t)\,P_s\,\Delta t}
\]
is identifiable in distribution \emph{up to} the internal token-value (or SLA-loss) prior used to map $\Delta T_g(t)$ into $C_{\mathrm{switch}}(t)$. Without excitation, $\kappa_{\mathrm{stiff}}$ is not identifiable.
\end{proposition}

\newpage

% ---------------------------------------------------------
\section{Grid Vector: seasonal tail events, deliverability geometry, and MRV as a Dinkelbach shadow price}
\label{app:grid_vector}

This appendix formalizes the \emph{exogenous} grid/scarcity components of the planner interface and the associated
\emph{reliability translation layer} that converts campus policies into (i) seasonal tail-coincident withdrawals and (ii)
a shadow-price penalty via MRV/eMRV inside the Dinkelbach auxiliary program. Two semantics are enforced:

\begin{enumerate}
  \item \textbf{Coincidence is policy-conditional and seasonal:} it is a tail statistic conditioned on
  $\mathcal{E}^{(s)}_{t,q_s}$, not an annual correlation.
  \item \textbf{Deliverability is constraint geometry:} it is a property of the active feasible set (and its multipliers),
  not a free scalar.
\end{enumerate}

% ---------------------------------------------------------
\subsection{Seasonal tail events (no winter/summer laundering)}
\label{subsec:app_seasonal_tail}

Let $s\in\mathcal{S}$ index seasons (e.g., $\{\mathrm{summer},\mathrm{winter}\}$). Let $W_t(\omega)\ge 0$ be a scarcity/adequacy
weight proxy (e.g., scarcity state indicator, LOLP proxy, or an adequacy shadow price from a planning simulator). For each season
$s$ and tail quantile $q_s\in(0,1)$ define the season-conditional tail threshold
\[
w_{s,q_s}\ \coloneqq\ \inf\Big\{w:\ \mathbb{P}(W_t\le w \mid t\in s)\ge q_s\Big\},
\]
and define the seasonal tail event:
\begin{equation}\label{eq:seasonal_tail_event}
\mathcal{E}^{(s)}_{t,q_s}\ \coloneqq\ \{t\in s\}\cap \{W_t \ge w_{s,q_s}\}.
\end{equation}
Allowing different $q_s$ by season is not cosmetic: it prevents aggregation across seasons with different adequacy physics
(winter vs summer) from laundering coincidence and mispricing reliability externalities.

% ---------------------------------------------------------
\subsection{Coincidence as a policy-conditional \emph{tail amplification} statistic}
\label{subsec:app_tail_amp}

Let $\pi$ denote the tranche policy generating controls $u^{\pi}(t)$ and hence grid-facing withdrawal at the POI,
$P_{\mathrm{grid}}^{\pi}(t)$. For each season $s$, define the season-normalized intensity:
\begin{equation}\label{eq:intensity_def_app}
I^{\pi}(t)\ \coloneqq\ 
\frac{P_{\mathrm{grid}}^{\pi}(t)}{\mathbb{E}\!\left[P_{\mathrm{grid}}^{\pi}(t)\mid t\in s\right]},
\qquad t\in s,
\end{equation}
so that $\mathbb{E}[I^{\pi}(t)\mid t\in s]=1$ by construction (removes dependence on arbitrary normalizations).

\paragraph{Tail coincidence / tail amplification.}
Define the tail-conditional coincidence statistic:
\begin{equation}\label{eq:gamma_def_app}
\Gamma_{s,q_s}(\pi)\ \coloneqq\ \mathbb{E}\!\left[I^{\pi}(t)\ \middle|\ \mathcal{E}^{(s)}_{t,q_s}\right].
\end{equation}
Equivalently, $\Gamma_{s,q_s}(\pi)$ is a tail amplification ratio:
\begin{equation}\label{eq:tail_amp_ratio_app}
\Gamma_{s,q_s}(\pi)\ =\
\frac{\mathbb{E}\!\left[P_{\mathrm{grid}}^{\pi}(t)\ \middle|\ \mathcal{E}^{(s)}_{t,q_s}\right]}
{\mathbb{E}\!\left[P_{\mathrm{grid}}^{\pi}(t)\mid t\in s\right]}.
\end{equation}
Thus $\Gamma_{s,q_s}(\pi)>1$ indicates that policy $\pi$ concentrates withdrawals \emph{specifically in the adequacy tail} of season $s$,
even if annual MWh is unchanged.

\paragraph{Baseline-referenced distortion (recommended).}
Given a baseline $\pi^{(0)}$, define incremental tail distortion:
\begin{equation}\label{eq:delta_gamma_app}
\Delta\Gamma_{s,q_s}(\pi;\pi^{(0)})\ \coloneqq\ \Gamma_{s,q_s}(\pi)-\Gamma_{s,q_s}(\pi^{(0)}).
\end{equation}
This isolates the reliability-relevant effect when comparing policies that preserve season-level mean withdrawal.

% ---------------------------------------------------------
\subsection{Deliverability as feasible-set geometry (operator form)}
\label{subsec:app_deliverability_operator}

Let $\ell$ be the campus bus/interface and let $p(t)$ be the vector of nodal injections/withdrawals. Under a DC/PTDF representation,
flows satisfy $f(t)=H(t)\,p(t)$ with limits $\lvert f(t)\rvert\le \bar f(t)$. Define the time-dependent feasible polytope:
\[
\mathcal{P}(t)\ \coloneqq\ \left\{p:\ -\bar f(t)\le H(t)p\le \bar f(t),\ \text{plus interface/contingency surrogates}\right\}.
\]
If the campus withdrawal implied by control $u(t)$ is $\Delta p(u(t))=-L(u(t))e_{\ell}$, define the deliverability operator:
\begin{equation}\label{eq:Kt_operator_app}
\mathcal{K}(t;u(t))\ \coloneqq\ \mathbf{1}\!\left\{p^{(0)}(t)+\Delta p(u(t))\in\mathcal{P}(t)\right\}.
\end{equation}
A scalar deliverability factor $D_{\ell}(t)$ (if used) is a \emph{projection statistic} of $\mathcal{P}(t)$; the primitive object is the
constraint geometry itself (encoded by $H(t)$ and $\bar f(t)$).

% ---------------------------------------------------------
\subsection{Binding-constraint semantics via multipliers (deliverability is active-set dependent)}
\label{subsec:app_binding_multipliers}

In an OPF / interface-constrained dispatch formulation, binding constraints admit Lagrange multipliers. Let $\nu(t)\ge 0$ denote the
vector of multipliers associated with the \emph{active} thermal/interface constraint set at time $t$ (after reduction to the active set).
The semantics ``deliverability matters when constraints bind'' is captured by:
\begin{equation}\label{eq:binding_indicator_app}
\mathbf{1}\{\mathcal{K}(t;u(t))=1\}\ \leadsto\ \mathbf{1}\{\|\nu(t)\|>0\}.
\end{equation}
This is not an algebraic identity; it is the planner-level statement that marginal MW at $\ell$ has system value when it relaxes
active constraint geometry.

Accordingly, define an operator-weighted effective reliability value:
\begin{equation}\label{eq:emrv_weighted_app}
\mathrm{eMRV}_{\ell}(t)\ \coloneqq\ \mathrm{MRV}_{\ell}(t)\,\omega_{\ell}(t),
\qquad \omega_{\ell}(t)\in[0,1],
\end{equation}
where $\omega_{\ell}(t)=\omega(\nu(t),H(t),\ell)$ summarizes how strongly a marginal MW at bus $\ell$ relaxes the active constraint set.\footnote{
This is the rigorous underpinning of ``deliverability'': it is a property of the active set and network geometry, not a free scalar.
If preferred for communication, replace $\omega_{\ell}(t)$ by a projection statistic $D_{\ell}(t)$ computed from $\mathcal{P}(t)$;
the mathematics remains the same.}

% ---------------------------------------------------------
\subsection{MRV/eMRV and insertion into the Dinkelbach auxiliary program}
\label{subsec:app_mrv_dinkelbach}

Let $\EUE(t)$ denote expected unserved energy and define the incremental impact of policy $\pi$ relative to a baseline $\pi^{(0)}$ as
$\Delta\EUE^{\pi}(t)$. The reliability cost is $C_{\mathrm{Rel}}(t)=\VOLL(t)\,\Delta\EUE^{\pi}(t)$.

Define MRV at $\ell$ as the marginal value of deliverable firm capacity:
\[
\mathrm{MRV}_{\ell}(t)\ \coloneqq\ -\frac{\partial \EUE_{\ell}(t)}{\partial \mathrm{Cap}_{\ell}(t)}\cdot \VOLL_z\ \ge\ 0.
\]
The effective MRV (deliverability-adjusted) is $\mathrm{eMRV}_{\ell}(t)$ from \eqref{eq:emrv_weighted_app}.

Now write the Dinkelbach auxiliary problem in ``system cost minus $\lambda$-goodput'' form:
\begin{equation}\label{eq:dinkelbach_with_mrv_app}
\min_{\pi\in\Pi_{\mathrm{adm}}}\ 
\mathbb{E}\!\left[\sum_{t=0}^{H} \delta^t\Big(
C_{\mathrm{Res}}^{\pi}(t)+C_{\mathrm{Int}}^{\pi}(t)+\VOLL(t)\,\Delta\EUE^{\pi}(t)
\Big)\right]
\ -\ 
\lambda\ \mathbb{E}\!\left[\sum_{t=0}^{H} \delta^t\,S(t)\,T_g^{\pi}(t)\right].
\end{equation}

\paragraph{Tail-linearized adequacy insertion (shadow-price form).}
A first-order adequacy linearization prices \emph{tail-coincident} withdrawals:
\begin{equation}\label{eq:rel_linearized_tail_app}
\VOLL(t)\,\Delta\EUE^{\pi}(t)\ \approx\ 
\mathrm{eMRV}_{\ell}(t)\,
\mathbf{1}\!\left\{\mathcal{E}^{(s)}_{t,q_s}\right\}\,
\Big(P_{\mathrm{grid}}^{\pi}(t)-P_{\mathrm{grid}}^{\pi^{(0)}}(t)\Big),
\qquad t\in s.
\end{equation}
Substituting \eqref{eq:rel_linearized_tail_app} into \eqref{eq:dinkelbach_with_mrv_app} makes explicit that reliability enters
only through \emph{seasonal-tail} withdrawals and deliverability-adjusted shadow pricing.

\paragraph{Explicit $\Gamma$ penalty (seasonal decomposition).}
Taking expectations and decomposing by season yields:
\begin{equation}\label{eq:rel_penalty_decomposed_app}
\mathbb{E}\!\left[\sum_{t=0}^{H} \delta^t\,\VOLL(t)\,\Delta\EUE^{\pi}(t)\right]
\ \approx\
\sum_{s\in\mathcal{S}}\ \sum_{t\in s}
\delta^t\,\mathrm{eMRV}_{\ell}(t)\,
\mathbb{E}\!\left[
\mathbf{1}\!\left\{\mathcal{E}^{(s)}_{t,q_s}\right\}
\Big(P_{\mathrm{grid}}^{\pi}(t)-P_{\mathrm{grid}}^{\pi^{(0)}}(t)\Big)
\right].
\end{equation}
If $\mathrm{eMRV}_{\ell}(t)$ is approximately constant within tail events of season $s$ (standard planning approximation), then for
fixed season-level mean withdrawals $\mathbb{E}[P_{\mathrm{grid}}^{\pi}(t)\mid t\in s]$ the penalty is monotone in
$\Delta\Gamma_{s,q_s}(\pi;\pi^{(0)})$ from \eqref{eq:delta_gamma_app}; i.e., coincidence becomes a priced distortion term in the
Dinkelbach auxiliary objective.

% ---------------------------------------------------------
\subsection{Calibration protocol (standardized planner-facing algorithm)}
\label{subsec:app_grid_calibration}

\begin{quote}\small
\textbf{Interface Calibration Algorithm (Grid Vector).}
\emph{Inputs:} telemetry $P_{\mathrm{grid}}(t)$; scarcity proxy $W_t$; season partition $\mathcal{S}$ and quantiles $\{q_s\}$;
network feasibility object $\mathcal{P}(t)$ (or $\mathcal{K}(t;\cdot)$), and if available OPF multipliers $\nu(t)$;
adequacy simulator (or MRV oracle); queue/censoring data for $S(t)$.

\emph{Step 1 (Tail sets):} compute $\widehat{w}_{s,q_s}$ and the empirical tail sets $\widehat{\mathcal{E}}^{(s)}_{t,q_s}$ via \eqref{eq:seasonal_tail_event}.

\emph{Step 2 (Tail amplification):} estimate $\widehat{\Gamma}_{s,q_s}(\pi)$ via \eqref{eq:gamma_def_app} using the season-normalization \eqref{eq:intensity_def_app},
and compute $\widehat{\Delta\Gamma}_{s,q_s}(\pi;\pi^{(0)})$ via \eqref{eq:delta_gamma_app}.

\emph{Step 3 (Deliverability weighting):} compute MRV by finite difference under common random numbers (baseline vs perturbed deliverable capacity);
construct $\widehat{\mathrm{eMRV}}_{\ell}(t)$ either via a projection statistic $D_{\ell}(t)$ from $\mathcal{P}(t)$ or via $\omega_{\ell}(t)$ from $(H(t),\nu(t),\ell)$.

\emph{Uncertainty:} bootstrap $\Gamma$ within seasons; propagate MRV/eMRV uncertainty using CRN variance reduction; sample primitive posteriors and re-solve
\eqref{eq:dinkelbach_with_mrv_app} in Monte Carlo.

\emph{Outputs:} distributions for Compute-ASCDE, diagnostics for seasonal tail amplification $\Gamma_{s,q_s}(\pi)$, and reliability shadow-price penalties
\eqref{eq:rel_penalty_decomposed_app} under admissible policies.
\end{quote}

\newpage

% ---------------------------------------------------------
\section{SMR Vector: constrained availability, boundary-condition feasibility, and tail-risk coupling}
\label{app:smr_vector}

This appendix formalizes the SMR vector as a \emph{boundary-condition state} that (i) restricts feasible campus power
trajectories and admissible controls, (ii) propagates availability uncertainty into Monte Carlo planning, and (iii) couples
thermo-physical and governance constraints into the seasonal-tail coincidence and reliability penalty channels used in
Section~3 and Appendix~\ref{app:grid_vector}. The objective is to make the SMR coupling \emph{auditable}: every claimed
flexibility or reliability benefit must correspond to an explicit feasible-set inclusion under uncertainty.

% ---------------------------------------------------------
\subsection{State definition and semantics}
\label{subsec:app_smr_state}

Define the SMR boundary-condition vector
\begin{equation}\label{eq:smr_vector_def_app}
\SMRVec_{t} \ \coloneqq\
\left\{
P^{\max}_{\mathrm{SMR}},\
a_{\mathrm{SMR},t},\
u^{\min}_{\mathrm{SMR}},\
r_{\mathrm{SMR}},\
\mathcal{I}_{\mathrm{island}},\
Q^{\max}_{\mathrm{rej}},\
\pi_{\mathrm{lic/cyber}}
\right\}.
\end{equation}
Here $P^{\max}_{\mathrm{SMR}}$ is net electrical nameplate available to the campus bus (optionally net of parasitics),
$a_{\mathrm{SMR},t}\in\{0,1\}$ is availability, $u^{\min}_{\mathrm{SMR}}\in[0,1]$ is minimum stable generation fraction,
$r_{\mathrm{SMR}}$ is ramp capability, $\mathcal{I}_{\mathrm{island}}\in\{0,1\}$ is islanding capability,
$Q^{\max}_{\mathrm{rej}}$ is heat-rejection capacity, and $\pi_{\mathrm{lic/cyber}}$ is a governance operator restricting
admissible automation and control policies.

\paragraph{Boundary-condition principle.}
The SMR vector is not a technology description; it is the smallest set of variables required to define a time-indexed
feasible set $\mathcal{F}^{\mathrm{SMR}}_{t}$ such that any claimed policy $\pi$ satisfies
\[
\big(P_{\mathrm{SMR},t},P^{\mathrm{grid}}_{t},u^{\pi}_{t}\big)\in \mathcal{F}^{\mathrm{SMR}}_{t}
\quad\text{for all } t,
\quad \text{and for almost all }\omega.
\]

% ---------------------------------------------------------
\subsection{Availability uncertainty: regime switching with scheduled maintenance optionality}
\label{subsec:app_smr_availability}

Let $a_{\mathrm{SMR},t}\in\{0,1\}$ denote online/offline status. A minimal prior is the two-state Markov model
\begin{equation}\label{eq:smr_markov_app}
\mathbb{P}\!\left(a_{\mathrm{SMR},t+1}=1 \mid a_{\mathrm{SMR},t}=1\right)=1-p_{\mathrm{out}},
\qquad
\mathbb{P}\!\left(a_{\mathrm{SMR},t+1}=1 \mid a_{\mathrm{SMR},t}=0\right)=p_{\mathrm{rec}}.
\end{equation}
This is sufficient for Monte Carlo propagation and for defining seasonal-tail coincidence under correlated outages.

\paragraph{Scheduled outage decomposition (recommended when applicable).}
If refueling/maintenance windows are planned, separate controllable schedule from forced outages:
\begin{equation}\label{eq:smr_sched_decomp_app}
a_{\mathrm{SMR},t} \ =\ \mathbf{1}\{t\notin \mathcal{M}\}\,\tilde a_{\mathrm{SMR},t},
\end{equation}
where $\mathcal{M}$ is a deterministic or scenario-set maintenance window and $\tilde a_{\mathrm{SMR},t}$ is a forced-outage process.
This prevents conflating \emph{policy choice} (schedule) with \emph{stochastic reliability} (forced outages).

\paragraph{Tail correlation note.}
If outage probabilities increase in extreme weather (common in adequacy tails), replace \eqref{eq:smr_markov_app} with a
state-dependent transition model
\[
p_{\mathrm{out}}=p_{\mathrm{out}}(W_{t},\vartheta_{t}),
\]
where $W_{t}$ is the scarcity proxy and $\vartheta_{t}$ is ambient/environmental state. This is the correct way to encode
``SMR availability degrades exactly when the grid is stressed.''

% ---------------------------------------------------------
\subsection{Coupling topology and power balance at the POI}
\label{subsec:app_smr_balance}

Let $P_{\mathrm{SMR},t}$ denote SMR gross electrical output at time $t$. Let $P^{\mathrm{SMR}\rightarrow \mathrm{camp}}_{t}$
be SMR power delivered to the campus bus (net of auxiliary loads if modeled), and let $P^{\mathrm{grid}}_{t}$ be grid import
at the POI. Let $L_{t}(u_{t})$ be campus electrical demand induced by tranche controls $u_{t}$ (with any on-site generation
other than SMR embedded in $L_{t}$ or explicitly modeled). The system-facing withdrawal is $P^{\mathrm{grid}}_{t}$ and obeys
\begin{equation}\label{eq:smr_campus_balance_app}
L_{t}(u_{t}) \ =\ P^{\mathrm{SMR}\rightarrow \mathrm{camp}}_{t} + P^{\mathrm{grid}}_{t}
\qquad \text{(plus storage terms if explicitly modeled)}.
\end{equation}
Reliability externalities in Appendix~\ref{app:grid_vector} attach to $P^{\mathrm{grid}}_{t}$, not directly to $L_{t}$.
Thus SMR coupling changes $\Delta\EUE$ primarily by reshaping the distribution of \emph{grid-facing} withdrawals in seasonal tails.

% ---------------------------------------------------------
\subsection{Feasibility constraints as a time-indexed polytope}
\label{subsec:app_smr_feasible_set}

Fix an interval length $\Delta t>0$. Define the SMR feasibility set as the intersection of electrical, thermal, and topology
constraints. The core electrical constraints are:

\paragraph{Availability-gated capacity and minimum stable generation.}
\begin{align}
0 \le P_{\mathrm{SMR},t} &\le a_{\mathrm{SMR},t}\,P^{\max}_{\mathrm{SMR}},
\label{eq:smr_capacity_app}\\
a_{\mathrm{SMR},t}=1\ \Rightarrow\
u^{\min}_{\mathrm{SMR}}\,P^{\max}_{\mathrm{SMR}} \le P_{\mathrm{SMR},t} &\le P^{\max}_{\mathrm{SMR}}.
\label{eq:smr_mingen_app}
\end{align}
Minimum generation becomes binding precisely when the campus attempts deep curtailment in low-demand hours; without a sink
(export, storage, controllable thermal), SMR coupling can \emph{reduce} feasible load flexibility.

\paragraph{Ramping / cycling constraint.}
\begin{equation}\label{eq:smr_ramp_app}
\left|P_{\mathrm{SMR},t}-P_{\mathrm{SMR},t-1}\right| \le r_{\mathrm{SMR}}\,\Delta t.
\end{equation}
This constraint is planner-relevant because it limits how fast the system can respond to scarcity calls, and it bounds the
feasible rate-of-change of $P^{\mathrm{grid}}_{t}$ induced by tranche controls.

\paragraph{Heat rejection constraint (abstract thermodynamic closure).}
Let $Q_{\mathrm{rej},t}$ denote required heat rejection. Impose
\begin{align}
0 \le Q_{\mathrm{rej},t} &\le Q^{\max}_{\mathrm{rej}},
\label{eq:heat_cap_app}\\
Q_{\mathrm{rej},t} &= \mathcal{H}\!\left(P_{\mathrm{SMR},t},\vartheta_{t}\right),
\label{eq:heat_map_app}
\end{align}
where $\vartheta_{t}$ encodes ambient/cooling state. This allows hot-weather scarcity seasons to bind SMR output through
\eqref{eq:heat_cap_app}--\eqref{eq:heat_map_app}, creating a direct coupling between seasonal tail events
$\mathcal{E}^{(s)}_{t,q_s}$ and feasible $P_{\mathrm{SMR},t}$.

\paragraph{Islanding as a topology constraint.}
Let $b_{t}\in\{0,1\}$ indicate islanded mode. Enforce
\begin{equation}\label{eq:islanding_logic_app}
b_{t}\le \mathcal{I}_{\mathrm{island}},
\qquad
b_{t}=1 \Rightarrow P^{\mathrm{grid}}_{t}=0,
\end{equation}
plus any transition constraints (black-start, synchronization, minimum island duration) if modeled. Treating islanding as
binary prevents the common modeling error of assuming continuous, costless, instantaneous microgrid transitions.

\paragraph{SMR feasibility polytope.}
Collecting the above, define
\[
\mathcal{F}^{\mathrm{SMR}}_{t}(\omega)
\ \coloneqq\
\left\{
(P_{\mathrm{SMR},t},P^{\mathrm{grid}}_{t},Q_{\mathrm{rej},t},b_{t})\ \text{s.t.}\
\eqref{eq:smr_campus_balance_app},
\eqref{eq:smr_capacity_app}--\eqref{eq:islanding_logic_app},
\text{and any site-specific limits}
\right\}.
\]
This is the object that must be satisfied for every $\omega$ in simulation.

% ---------------------------------------------------------
\subsection{Governance/licensing/cyber as an admissibility operator}
\label{subsec:app_smr_governance}

Model licensing/cyber/segmentation constraints as an operator restricting admissible policies:
\begin{equation}\label{eq:pi_lic_cyber_app}
\pi_{\mathrm{lic/cyber}}:\ \Pi \to \{0,1\},
\qquad
\Pi_{\mathrm{adm}} \ \coloneqq\ \{\pi\in\Pi:\ \pi_{\mathrm{lic/cyber}}(\pi)=1\}.
\end{equation}
In the combined interface, the planner solves over policies $\pi\in\Pi_{\mathrm{adm}}$ such that the induced trajectories
remain feasible:
\[
\big(P_{\mathrm{SMR},t}^{\pi},P^{\mathrm{grid},\pi}_{t},Q^{\pi}_{\mathrm{rej},t},b^{\pi}_{t}\big)
\in \mathcal{F}^{\mathrm{SMR}}_{t}(\omega)
\quad\text{for all }t,\ \text{a.s.}
\]
Typical restrictions encoded by $\pi_{\mathrm{lic/cyber}}$ include (i) human-in-the-loop setpoint changes, (ii) constraints
on telemetry/control-plane connectivity between campus and nuclear domains, (iii) response-time/latency limits from
authentication or approval steps, and (iv) restrictions on automation frequency.

% ---------------------------------------------------------
\subsection{Tail-risk coupling: how \texorpdfstring{$\SMRVec_{t}$}{SMRVec} reshapes coincidence and reliability penalties}
\label{subsec:app_smr_tail_coupling}

The SMR vector affects adequacy externalities through two objective-relevant channels:

\paragraph{(C1) Grid-withdrawal reshaping in seasonal tail events.}
By \eqref{eq:smr_campus_balance_app}, feasible $P_{\mathrm{SMR},t}$ reduces $P^{\mathrm{grid}}_{t}$ in states where the SMR is available
and unconstrained. Therefore the policy-conditional tail amplification statistic in Appendix~\ref{app:grid_vector},
\[
\Gamma_{s,q_s}(\pi)=\mathbb{E}\!\left[I_t^{\pi}\mid \mathcal{E}^{(s)}_{t,q_s}\right],
\]
is jointly determined by tranche controls \emph{and} by the feasible SMR output set $\mathcal{F}^{\mathrm{SMR}}_{t}$, especially when
\eqref{eq:smr_ramp_app} or \eqref{eq:heat_cap_app} bind during tail events.

\paragraph{(C2) Control-feasibility reshaping via binding constraints and admissibility.}
Minimum generation \eqref{eq:smr_mingen_app}, ramping \eqref{eq:smr_ramp_app}, islanding logic \eqref{eq:islanding_logic_app}, and
admissibility \eqref{eq:pi_lic_cyber_app} restrict which $\pi$ are feasible and therefore which coincidence profiles are attainable.
This is the rigorous content of the statement “SMR coupling is a boundary condition”: it modifies the feasible policy set and thereby
changes the reliability penalty term that enters the Dinkelbach auxiliary objective in Appendix~\ref{app:grid_vector}.

% ---------------------------------------------------------
\subsection{Calibration and Monte Carlo propagation (standardized protocol)}
\label{subsec:app_smr_calibration}

\begin{quote}\small
\textbf{SMR Coupling Calibration Protocol (planner-facing).}
\emph{Inputs:} nameplate $P^{\max}_{\mathrm{SMR}}$; minimum generation $u^{\min}_{\mathrm{SMR}}$; ramp $r_{\mathrm{SMR}}$; islanding flag
$\mathcal{I}_{\mathrm{island}}$; site thermal limit $Q^{\max}_{\mathrm{rej}}$ and ambient state $\vartheta_{t}$; availability data (or priors)
for $(p_{\mathrm{out}},p_{\mathrm{rec}})$ and maintenance windows $\mathcal{M}$; governance admissibility rules $\pi_{\mathrm{lic/cyber}}$.

\emph{Estimators:} fit availability model \eqref{eq:smr_markov_app} or its state-dependent extension; validate ramp/min-gen constraints against
operational specs; calibrate $\mathcal{H}(\cdot)$ in \eqref{eq:heat_map_app} at a fidelity consistent with planning timescales.

\emph{Uncertainty:} represent $(p_{\mathrm{out}},p_{\mathrm{rec}})$ and thermal-headroom parameters as distributions; sample them in Monte Carlo and
propagate through feasibility $\mathcal{F}^{\mathrm{SMR}}_{t}(\omega)$ to obtain distributions of $P^{\mathrm{grid}}_{t}$ in seasonal tails.

\emph{Outputs:} (i) distributions of feasible $P^{\mathrm{grid}}_{t}$ under admissible policies, (ii) induced $\Gamma_{s,q_s}(\pi)$ profiles, and
(iii) the resulting reliability penalties via MRV/eMRV as in Appendix~\ref{app:grid_vector}.
\end{quote}

% ---------------------------------------------------------
\subsection{Bindingness and tail-effect sign: when SMR coupling reduces (or increases) adequacy-tail withdrawals}
\label{subsec:app_smr_bindingness}

This subsection formalizes a planner-critical question: under what conditions does SMR coupling \emph{strictly reduce}
grid-facing withdrawals in seasonal adequacy-tail events (thereby reducing $\Gamma_{s,q_s}(\pi)$ and the MRV-weighted
reliability penalty), and when can coupling be neutral or even adverse (e.g., minimum-generation forcing exports or
residual grid import in tails)?

\subsubsection{Preliminaries: conditional tail metrics and an “effective tail import” functional}

Fix a season $s\in\mathcal{S}$ and tail level $q_s\in(0,1)$. Let $\mathcal{E}^{(s)}_{t,q_s}$ be the seasonal tail event defined in
\eqref{eq:seasonal_tail_event} of Appendix~\ref{app:grid_vector}. Define the \emph{tail-import functional} under policy $\pi$:
\begin{equation}\label{eq:tail_import_functional}
\mathcal{T}_{s,q_s}(\pi)
\ \coloneqq\
\mathbb{E}\!\left[P^{\mathrm{grid},\pi}_{t}\ \big|\ \mathcal{E}^{(s)}_{t,q_s}\right],
\end{equation}
and recall the tail amplification statistic
\[
\Gamma_{s,q_s}(\pi)
=
\frac{\mathbb{E}\!\left[P^{\mathrm{grid},\pi}_{t}\mid \mathcal{E}^{(s)}_{t,q_s}\right]}
{\mathbb{E}\!\left[P^{\mathrm{grid},\pi}_{t}\mid t\in s\right]}
=
\frac{\mathcal{T}_{s,q_s}(\pi)}{\mathbb{E}[P^{\mathrm{grid},\pi}_{t}\mid t\in s]}.
\]
Thus controlling $\Gamma_{s,q_s}(\pi)$ amounts to controlling $\mathcal{T}_{s,q_s}(\pi)$ relative to seasonal mean import.\footnote{
We use conditional expectations rather than maxima to avoid pathological dependence on single-hour telemetry outliers and to match
adequacy externalities, which are typically evaluated in expectation (EUE/LOLE proxies).}

\subsubsection{A feasible-sink decomposition for minimum generation}

Introduce an explicit \emph{non-grid sink} term $X_t^{\pi}\ge 0$ (aggregating export capability, storage charging headroom,
or controllable thermal/industrial load that can absorb minimum generation). Write the campus balance as
\begin{equation}\label{eq:smr_balance_with_sink}
L_t(u_t^{\pi})
\ =\
P^{\mathrm{SMR}\rightarrow \mathrm{camp},\pi}_{t}
\ +\
P^{\mathrm{grid},\pi}_{t}
\ -\
X_t^{\pi},
\end{equation}
where $X_t^{\pi}>0$ represents “where the excess goes” when $P_{\mathrm{SMR},t}$ exceeds instantaneous electrical demand net of
grid import constraints.\footnote{
This decomposition is the cleanest way to avoid “paper flexibility.” If minimum generation binds and $X_t^{\pi}$ is structurally
zero (no export, no storage charging, no dump load), the model must force either (i) infeasibility or (ii) undesired grid injections,
which changes the system-facing state and can invalidate naive tail-benefit claims.}

Under minimum generation \eqref{eq:smr_mingen_app} of Appendix~\ref{app:smr_vector}, when $a_{\mathrm{SMR},t}=1$ we have
\[
P_{\mathrm{SMR},t}^{\pi}\ \ge\ u^{\min}_{\mathrm{SMR}} P^{\max}_{\mathrm{SMR}}.
\]
If the site cannot create $X_t^\pi$ in low-load conditions, SMR coupling can become \emph{anti-flexible} in tails (forcing net
grid interaction rather than relaxing it).

\subsubsection{Definition: tail-bindingness probability}

Define the set of \emph{tail-binding constraints} for SMR output as
\[
\mathcal{B}^{\mathrm{SMR}}_{t}(\omega)
\ :=\
\left\{
\eqref{eq:smr_ramp_app}\ \text{binding} \;\;\text{or}\;\;
\eqref{eq:heat_cap_app}\ \text{binding} \;\;\text{or}\;\;
a_{\mathrm{SMR},t}=0
\right\}.
\]
Define the \emph{tail-bindingness probability}:
\begin{equation}\label{eq:tail_bindingness_prob}
\beta_{s,q_s}(\pi)
\ \coloneqq\
\mathbb{P}\!\left(\mathcal{B}^{\mathrm{SMR}}_{t}\ \big|\ \mathcal{E}^{(s)}_{t,q_s}\right).
\end{equation}
Interpretation: $\beta_{s,q_s}(\pi)$ is the probability that the SMR is unavailable or constrained \emph{precisely when the grid is in
the adequacy tail}. Low $\beta_{s,q_s}$ is a necessary condition for large tail benefits from coupling.

\subsubsection{Lemma: pointwise dominance condition for tail-import reduction}

Let $\pi^{(0)}$ be the baseline policy without SMR coupling (or with $P^{\mathrm{SMR}\rightarrow \mathrm{camp}}_t\equiv 0$), and let $\pi$
be a policy with SMR coupling and feasible sink $X_t^\pi$. Suppose for all $t$ and almost all $\omega$ in the seasonal tail event,
\begin{equation}\label{eq:dominance_condition}
\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\,P^{\mathrm{SMR}\rightarrow \mathrm{camp},\pi}_{t}
\ \ge\
\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\,X_t^\pi
\quad\text{and}\quad
\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\,P^{\mathrm{SMR}\rightarrow \mathrm{camp},\pi}_{t}\ge 0.
\end{equation}
Then
\begin{equation}\label{eq:tail_import_monotone}
\mathcal{T}_{s,q_s}(\pi)
\ \le\
\mathcal{T}_{s,q_s}(\pi^{(0)}),
\end{equation}
with strict inequality if \eqref{eq:dominance_condition} is strict on a set of positive probability measure.\footnote{
Condition \eqref{eq:dominance_condition} is a rigorous statement that “SMR output in the tail goes to offset grid imports rather
than being dumped or exported.” If $X_t^\pi$ dominates (no sink or wrong sink), tail imports need not decrease.}

\begin{proof}[Proof (one-line dominance via balance)]
From \eqref{eq:smr_balance_with_sink},
\[
P^{\mathrm{grid},\pi}_{t}
=
L_t(u_t^{\pi})
-
P^{\mathrm{SMR}\rightarrow \mathrm{camp},\pi}_{t}
+
X_t^{\pi}.
\]
In the baseline $\pi^{(0)}$ with zero delivered SMR power, we have
\(
P^{\mathrm{grid},\pi^{(0)}}_{t}
=
L_t(u_t^{\pi^{(0)}})
+
X_t^{\pi^{(0)}}.
\)
Assuming the comparison holds at fixed campus demand trajectory in the tail (or comparing policies that match $L_t$ in the tail),
condition \eqref{eq:dominance_condition} implies
\(
\mathbf{1}\{\mathcal{E}\}P^{\mathrm{grid},\pi}_{t}\le \mathbf{1}\{\mathcal{E}\}P^{\mathrm{grid},\pi^{(0)}}_{t}
\)
a.s.; taking conditional expectations yields \eqref{eq:tail_import_monotone}. \qedhere
\end{proof}

\subsubsection{Proposition: a sharp sufficient condition using tail-bindingness}

Assume (i) in seasonal tails, delivered SMR power is lower bounded by a positive random variable when unconstrained,
\[
P^{\mathrm{SMR}\rightarrow \mathrm{camp},\pi}_{t}
\ \ge\
\underline{P}\cdot \mathbf{1}\{\neg \mathcal{B}^{\mathrm{SMR}}_{t}\}
\quad \text{on }\mathcal{E}^{(s)}_{t,q_s},
\]
(ii) the tail sink is bounded above by $\overline{X}$ on $\mathcal{E}^{(s)}_{t,q_s}$, and (iii) campus tail demand is comparable
across the two policies. Then an explicit bound holds:
\begin{equation}\label{eq:tail_import_bound_beta}
\mathcal{T}_{s,q_s}(\pi)
\ \le\
\mathcal{T}_{s,q_s}(\pi^{(0)})
-
\underline{P}\cdot\big(1-\beta_{s,q_s}(\pi)\big)
+\overline{X}.
\end{equation}
Thus coupling produces a net tail-import reduction whenever
\[
\underline{P}\cdot\big(1-\beta_{s,q_s}(\pi)\big)>\overline{X}.
\]
\footnote{
This inequality makes the planner hinge explicit: you want (a) nontrivial SMR deliverable power in the seasonal tail, and (b) low
probability of bindingness in that same tail. Meanwhile, any “dumping” or exporting represented by $\overline{X}$ directly erodes tail benefit.}

\begin{proof}[Proof sketch]
On $\mathcal{E}^{(s)}_{t,q_s}$, substitute the lower bound on delivered SMR power and upper bound on sink into
\eqref{eq:smr_balance_with_sink}, take conditional expectations, and note that
\(
\mathbb{E}[\mathbf{1}\{\neg\mathcal{B}^{\mathrm{SMR}}_{t}\}\mid \mathcal{E}]=1-\beta_{s,q_s}(\pi).
\)
\qedhere
\end{proof}

\subsubsection{Corollary: sign conditions for the effect on \texorpdfstring{$\Gamma_{s,q_s}(\pi)$}{Gamma}}

If the seasonal mean import $\mathbb{E}[P^{\mathrm{grid},\pi}_{t}\mid t\in s]$ is approximately unchanged by SMR coupling (a common
first-order approximation when coupling mainly reshapes tail hours), then any decrease in $\mathcal{T}_{s,q_s}(\pi)$ decreases
$\Gamma_{s,q_s}(\pi)$ proportionally. If coupling also reduces seasonal mean import, then $\Gamma$ can remain unchanged even as the
tail is reduced; therefore planners should always report both $\mathcal{T}_{s,q_s}(\pi)$ and $\Gamma_{s,q_s}(\pi)$.\footnote{
This is an “interface truthfulness” rule: $\Gamma$ is a ratio. Reducing both numerator and denominator can mask a real absolute tail
improvement. Conversely, reducing the denominator alone can inflate $\Gamma$ without worsening the tail. Report both.}

\subsubsection{Integration with the MRV-weighted reliability penalty}

Recall from Appendix~\ref{app:grid_vector} the linearized reliability penalty term
\[
\mathbb{E}\!\left[\sum_{t}\delta^{t}\,\VOLL(t)\Delta\EUE^{\pi}_{t}\right]
\approx
\sum_{s\in\mathcal{S}}\sum_{t\in s}
\delta^{t}\,\mathrm{eMRV}_{\ell,t}\,
\mathbb{E}\!\left[\mathbf{1}\{\mathcal{E}^{(s)}_{t,q_s}\}\Big(P^{\mathrm{grid},\pi}_{t}-P^{\mathrm{grid},(0)}_{t}\Big)\right].
\]
Under the dominance condition of Lemma~\eqref{eq:tail_import_monotone} (or the bound \eqref{eq:tail_import_bound_beta}),
SMR coupling weakly reduces the MRV-weighted penalty. In particular, if $\mathrm{eMRV}_{\ell,t}$ is approximately constant over
tail events for fixed season $s$, then the change in reliability penalty is monotone in the change in $\mathcal{T}_{s,q_s}(\pi)$:
\[
\Delta \text{Penalty}^{(s)}(\pi)
\ \propto\
\mathcal{T}_{s,q_s}(\pi)-\mathcal{T}_{s,q_s}(\pi^{(0)}).
\]
This justifies using $\beta_{s,q_s}(\pi)$ and sink capacity as a first-line screening diagnostic for whether SMR coupling can
improve adequacy-tail externalities under a given siting and governance regime.\footnote{
Operationally: if your availability is weak in the winter tail, or your heat rejection binds in the summer tail, you may still
have a valuable energy supply asset, but you should not claim a “reliability-tail coincidence” benefit without showing low
$\beta_{s,q_s}(\pi)$ in the relevant season.}

\newpage

% =========================================================
% APPENDIX CLUSTER: ORACLE + FORMAL VERIFICATION + FRACTIONAL OPTIMIZATION
% =========================================================

% ---------------------------------------------------------
\section{Thermal Oracle Appendix: DeepONet sprint feasibility and conservative caps}
\label{app:thermal_oracle}

This appendix formalizes the \emph{thermal feasibility oracle} used to cap compute sprinting in the SMR--compute coupling.
It defines a state-dependent constraint $\sigma(t)\le \sigma_{\max}(t)$ that is intended to be inserted into the SMR feasible set
$\mathcal{F}^{\mathrm{SMR}}_t$ (Appendix~\ref{app:smr_vector}) and therefore restrict admissible policies $\Pi_{\mathrm{adm}}$.

\subsection{Operator learning problem (history-to-state map)}
Let $u_{\mathrm{rod}}(\tau)$ denote reactor control input history (e.g., rod positions / supervisory control actions) and let
$P_{\mathrm{AI}}(\tau)$ denote compute load history. Define the (unknown) nonlinear operator
\[
\mathcal{G}:\ (u_{\mathrm{rod}},P_{\mathrm{AI}})\ \mapsto\ T_{\mathrm{out}}(\cdot),
\]
mapping histories to the outlet temperature trajectory. A Deep Operator Network (DeepONet) approximates $\mathcal{G}$ via
branch/trunk decomposition:
\[
\widehat{T}_{\mathrm{out}}(t)\ \approx\ \sum_{k=1}^{p} b_k\!\left(u_{\mathrm{rod}}(t_1{:}t_m),P_{\mathrm{AI}}(t_1{:}t_m)\right)\,\tau_k(t).
\]
\footnote{Planner role: this surrogate is not an engineering replacement for safety analysis; it is an interface tool that provides a
fast, conservative feasibility query at dispatch cadence. Conservative use requires buffers that absorb oracle error.}

\subsection{Sprint cap definition (conservative forward-horizon constraint)}
Let $P_{\mathrm{AI}}(t)=\sigma(t)\,P_{\mathrm{base}}(t)$ on sprint windows, with $\sigma(t)\in[1,\sigma_{\mathrm{peak}}]$.
Define thermal headroom $\Delta T_{\mathrm{safe}}(t)\coloneqq T_{\mathrm{scram}}-\widehat{T}_{\mathrm{out}}(t)$.
For lag horizon $\tau_{\mathrm{lag}}>0$ and safety buffer $\epsilon>0$, define the conservative sprint cap:
\begin{equation}\label{eq:sigma_max_oracle}
\sigma_{\max}(t)\ \coloneqq\ 
\sup\Big\{\sigma\in[1,\sigma_{\mathrm{peak}}]:\ \widehat{T}^{(\sigma)}_{\mathrm{out}}(t{+}\tau)\le T_{\mathrm{scram}}-\epsilon,\ \forall \tau\in[0,\tau_{\mathrm{lag}}]\Big\}.
\end{equation}
The planner-enforced constraint is:
\begin{equation}\label{eq:sprint_cap_constraint}
\sigma(t)\ \le\ \sigma_{\max}(t).
\end{equation}
\footnote{$\epsilon$ should be set using calibration bands (e.g., a high-quantile error envelope) so that oracle misprediction does not create
feasibility violations. This is the correct place to encode conservatism: in the cap definition.}

\subsection{Energy-form sprint-lag inequality (impulse constraint)}
For sub-second sprints, an energetic form is often more stable than pointwise ramp constraints:
\begin{equation}\label{eq:sprint_lag_energy_form}
\int_{t}^{t+\Delta t_{\mathrm{sprint}}} \dot{P}_{\mathrm{AI}}(\tau)\,d\tau
\ \le\
C_{\mathrm{th}}\cdot \Big(T_{\mathrm{scram}}-\widehat{T}_{\mathrm{out}}(t)\Big),
\end{equation}
where $C_{\mathrm{th}}$ is an effective thermal capacitance proxy.
\footnote{This is the correct feasibility object for time-scale mismatch: it bounds the energy impulse delivered into the thermal system over the sprint
horizon, rather than constraining MW pointwise at a slower dispatch interval.}

\subsection{Insertion into the SMR feasible set}
Appendix~\ref{app:smr_vector} defines $\mathcal{F}^{\mathrm{SMR}}_t$ via capacity, ramp, islanding, and heat rejection constraints.
The oracle constraints \eqref{eq:sprint_cap_constraint}--\eqref{eq:sprint_lag_energy_form} are appended as additional feasibility restrictions:
\[
\mathcal{F}^{\mathrm{SMR}}_t\ \leftarrow\ \mathcal{F}^{\mathrm{SMR}}_t\ \cap\ \{\sigma(t)\le\sigma_{\max}(t)\}\ \cap\ \{\text{\eqref{eq:sprint_lag_energy_form} holds}\}.
\]
This makes sprint control a formally auditable boundary condition rather than a narrative operating guideline.

% ---------------------------------------------------------
\section{Formal verification appendix: safety lockout under economic sprint requests}
\label{app:formal_verification}

This appendix encodes the required safety invariant: \emph{an economic signal cannot authorize sprinting when thermal feasibility is false}.
The purpose is not to replace licensing review; it is to prevent design drift in the control software as economic logic evolves.

\subsection{LTL safety property}
Let \texttt{SprintReq} be the event that an economic layer requests sprint, \texttt{ThermSafe} be the predicate that the oracle feasibility conditions
(e.g., \eqref{eq:sprint_cap_constraint} and buffers) are satisfied, and \texttt{SprintAuth} be the authorization output to the actuator.
The critical property is:
\begin{equation}\label{eq:ltl_safety}
\phi_{\mathrm{safe}}\ \coloneqq\ \Box\Big((\texttt{SprintReq}\ \wedge\ \neg\texttt{ThermSafe})\ \Rightarrow\ \neg\texttt{SprintAuth}\Big).
\end{equation}
\footnote{This property is intentionally one-way: it forbids unsafe authorization but does not require sprinting when safe. The latter would be an
economic/dispatch objective, not a safety invariant.}

\subsection{PROMELA kernel (lockout logic skeleton)}
\begin{algorithm}[H]
\caption{Sprint Safety Kernel (PROMELA skeleton)}
\begin{lstlisting}[language=C, basicstyle=\small\ttfamily]
mtype = { IDLE, SPRINT, COOLING };
bool req_sprint;
bool therm_safe;   /* derived from oracle caps + buffers */
mtype state = IDLE;

active proctype SprintGuard() {
  do
  :: atomic {
       if
       :: (req_sprint && therm_safe) ->
            state = SPRINT;
            /* optional: assert local invariants used by the oracle interface */
       :: (req_sprint && !therm_safe) ->
            state = IDLE;   /* VETO */
       :: else ->
            state = IDLE;
       fi
     }
  od
}
\end{lstlisting}
\end{algorithm}
\footnote{The implementation should derive \texttt{therm\_safe} from the same conservative feasibility logic used in
Appendix~\ref{app:thermal_oracle} (including buffers). Verifying a different predicate than what dispatch uses defeats the point.}

% ---------------------------------------------------------
\section{Fractional optimization appendix: Dinkelbach convergence for Compute-ASCDE}
\label{app:dinkelbach_convergence}

This appendix provides a clean convergence statement for the fractional program underlying Compute-ASCDE when solved via Dinkelbach iteration.
It is written to be cited once from the main text, avoiding repeated derivations.

\subsection{Setup}
Let $\mathcal{X}$ denote the feasible policy/design set (including admissibility constraints), and define the fractional objective
\[
\min_{x\in\mathcal{X}}\ \frac{C(x)}{G(x)},
\qquad
C(x)\ge 0,\quad G(x)>0,
\]
where $C(x)$ is the discounted numerator (resource + integration + reliability costs) and $G(x)$ is discounted goodput.
Define the Dinkelbach auxiliary function:
\[
F(\lambda)\ \coloneqq\ \min_{x\in\mathcal{X}}\ \big(C(x)-\lambda G(x)\big).
\]

\subsection{Convergence theorem (standard form)}
\begin{theorem}\label{thm:dinkelbach}
Assume $\mathcal{X}$ is nonempty and compact, $C$ is continuous, and $G$ is continuous and strictly positive on $\mathcal{X}$.
Let $\lambda^{\star}=\min_{x\in\mathcal{X}} C(x)/G(x)$. Then:
\begin{enumerate}
  \item $F(\lambda)$ is continuous and strictly decreasing, with unique root at $\lambda^{\star}$ satisfying $F(\lambda^{\star})=0$.
  \item The iteration $\lambda_{k+1}\coloneqq C(x_k)/G(x_k)$ where $x_k\in\arg\min_{x\in\mathcal{X}} (C(x)-\lambda_k G(x))$
  converges to $\lambda^{\star}$.
\end{enumerate}
\end{theorem}

\begin{proof}
For each fixed $x$, $C(x)-\lambda G(x)$ is affine and strictly decreasing in $\lambda$ because $G(x)>0$.
Taking the pointwise minimum over $x\in\mathcal{X}$ preserves continuity and monotonic decrease, hence $F$ is continuous and strictly decreasing.
Let $x^{\star}\in\arg\min C(x)/G(x)$ and set $\lambda^{\star}=C(x^{\star})/G(x^{\star})$. Then
$C(x^{\star})-\lambda^{\star}G(x^{\star})=0$ implies $F(\lambda^{\star})\le 0$.
Conversely, for any $\lambda<\lambda^{\star}$, $C(x)-\lambda G(x)>0$ for all $x$, hence $F(\lambda)>0$; similarly for $\lambda>\lambda^{\star}$,
$F(\lambda)<0$. Thus $F(\lambda^{\star})=0$ and the root is unique.

For the iteration, define $x_k\in\arg\min (C-\lambda_k G)$. Then
$F(\lambda_k)=C(x_k)-\lambda_k G(x_k)$.
The update $\lambda_{k+1}=C(x_k)/G(x_k)$ yields $F(\lambda_k)=G(x_k)(\lambda_{k+1}-\lambda_k)$.
Since $G(x_k)>0$, the sign of $F(\lambda_k)$ equals the sign of $\lambda_{k+1}-\lambda_k$, implying monotone convergence toward the unique root.
Standard Dinkelbach arguments complete the proof. \qedhere
\end{proof}

\subsection{How MRV insertion fits the theorem}
Appendix~\ref{app:grid_vector} shows that reliability can be written (or linearized) as a shadow-priced penalty in the numerator $C(x)$ via MRV/eMRV.
This does not change the validity of Theorem~\ref{thm:dinkelbachequ}; it only changes the structure of $C(x)$ (the subproblem solver and gradients),
provided continuity and positivity conditions are preserved.


\newpage

% =========================================================
% Appendix K: Zero-Knowledge Proofs for Compute Tranches
% =========================================================
\section{Zero-Knowledge Audit of Stiff Tranches}
\label{app:zkp}

To claim the ``Stiff Tranche'' reliability credit without revealing sensitive nuclear security algorithms (HIPMoS), the campus must generate a zk-SNARK proof $\pi_{zk}$.

\subsection{The Statement}
The campus proves it performed computation $C$ (HIPMoS inspection) on private input $w$ (network packets) resulting in public output $y$ (threat score), consuming energy $E$.
\begin{equation}
    \mathcal{R} = \{ (y, E); w \mid C(y, w) = 1 \land \text{Energy}(C) \approx E \}
\end{equation}

\subsection{The Protocol}
We utilize a PLONK-based proving scheme for arithmetic circuit satisfiability:
\begin{enumerate}
    \item \textbf{Arithmetization:} The HIPMoS control flow is compiled into a Polynomial Commitment Scheme (PCS).
    \item \textbf{Energy Binding:} The energy consumption $E$ is cryptographically committed as a public input signal to the circuit's ``Gas Meter'' gate.
    \item \textbf{Verification:} The Utility verifier $V$ checks $\text{Verify}(\pi_{zk}, y, E)$ in $O(1)$ time.
\end{enumerate}

\begin{corollary}[Fraud Resistance]
If the campus attempts to mine cryptocurrency instead of running HIPMoS (an ``Energy Laundering'' attack), the circuit constraints $C$ will not be satisfied by the random nonce inputs of the mining algorithm. The probability of forging a proof $\pi'_{zk}$ is negligible ($< 2^{-128}$).\footnote{This is the mathematical bedrock of the ``Audit'' deliverable in Section 7. It allows INL to pay for reliability without demanding to inspect the proprietary weights of the AI models running on the campus.}
\end{corollary}

\newpage
% =========================================================
% Bibliography
% =========================================================
\printbibliography
\end{document}
